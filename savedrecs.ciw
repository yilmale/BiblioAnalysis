FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Kanuck, S
AF Kanuck, Sean
TI Humor, Ethics, and Dignity: Being Human in the Age of Artificial
   Intelligence
SO ETHICS & INTERNATIONAL AFFAIRS
LA English
DT Article
DE humor; ethics; dignity; human rights; artificial intelligence; Philippa
   Foot; law; philosophy; driverless cars; lethal autonomous weapons
AB The growing adoption of artificial intelligence (AI) raises questions about what comparative advantage, if any, human beings will have over machines in the future. This essay explores what it means to be human and how those unique characteristics relate to the digital age. Humor and ethics both rely upon higher-level cognition that accounts for unstructured and unrelated data. That capability is also vital to decision-making processes-such as jurisprudence and voting systems. Since machine learning algorithms lack the ability to understand context or nuance, reliance on them could lead to undesired results for society. By way of example, two case studies are used to illustrate the legal and moral considerations regarding the software algorithms used by driverless cars and lethal autonomous weapons systems. Social values must be encoded or introduced into training data sets if AI applications are to be expected to produce results similar to a "human in the loop." There is a choice to be made, then, about whether we impose limitations on these new technologies in favor of maintaining human control, or whether we seek to replicate ethical reasoning and lateral thinking in the systems we create. The answer will have profound effects not only on how we interact with AI but also on how we interact with one another and perceive ourselves.
C1 [Kanuck, Sean] Stanford Univ, Hoover Inst, Stanford, CA 94305 USA.
   [Kanuck, Sean] Stanford Univ, Ctr Int Secur & Cooperat, Stanford, CA 94305 USA.
   [Kanuck, Sean] Off Director Natl Intelligence, Cyber Issues, Washington, DC USA.
   [Kanuck, Sean] Global Commiss Stabil Cyberspace, Res Advisory Grp, The Hague, Netherlands.
   [Kanuck, Sean] Int Inst Strateg Studies, Cyber Space & Future Conflict, London, England.
RP Kanuck, S (reprint author), Stanford Univ, Hoover Inst, Stanford, CA 94305 USA.; Kanuck, S (reprint author), Stanford Univ, Ctr Int Secur & Cooperat, Stanford, CA 94305 USA.; Kanuck, S (reprint author), Int Inst Strateg Studies, Cyber Space & Future Conflict, London, England.
EM sean@kanuck.com
CR [Anonymous], 2018, ECONOMIST
   [Anonymous], 2014, BBC NEWS
   Arrow Kenneth J., 2012, SOCIAL CHOICE INDIVI
   Brown  Sophie, 2014, CNN BUSINESS    1001
   Forte D. F., 1985, CLEVELAND STATE LAW, V34, P47
   Harvard Law School Library, WORDS JUST ROOF GARD
   Hoffman  David, 1999, WASHINGTON POST
   International Committee of the Red Cross, 2015, WHAT IS IHL
   Lessig L, 1999, CODE OTHER LAWS CYBE
   Liberatore  Stacey, 2016, DAILY MAIL
   Morreall  John, 2016, STANFORD ENCY PHIL 4
   Stone  Zara, 2017, FORBES
   Taylor  Michael, 2016, CAR AND DRIVER
   THOMSON JJ, 1985, YALE LAW J, V94, P1395, DOI 10.2307/796133
   United States Department of Justice, 2018, FORM CEO VOLKSW AG C
   UNWeb TV, 2018, UN WEB TV       0827
NR 16
TC 0
Z9 0
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0892-6794
EI 1747-7093
J9 ETHICS INT AFF
JI Ethics Int. Aff.
PD SPR
PY 2019
VL 33
IS 1
BP 3
EP 12
AR PII S0892679418000928
DI 10.1017/S0892679418000928
PG 10
WC Ethics; International Relations; Political Science
SC Social Sciences - Other Topics; International Relations; Government &
   Law
GA HO1IU
UT WOS:000460659600001
DA 2019-03-21
ER

PT J
AU Richardson, K
AF Richardson, Kathleen
TI Rethinking the I-You relation through dialogical philosophy in the
   Ethics of AI and robotics
SO AI & SOCIETY
LA English
DT Editorial Material
C1 [Richardson, Kathleen] De Montfort Univ, Ctr Comp & Social Responsibil, Leicester LE1 9BH, Leics, England.
RP Richardson, K (reprint author), De Montfort Univ, Ctr Comp & Social Responsibil, Leicester LE1 9BH, Leics, England.
EM kathleen.richardson@dmu.ac.uk
NR 0
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0951-5666
EI 1435-5655
J9 AI SOC
JI AI Soc.
PD MAR
PY 2019
VL 34
IS 1
SI SI
BP 1
EP 2
DI 10.1007/s00146-017-0703-x
PG 2
WC Computer Science, Artificial Intelligence
SC Computer Science
GA HJ9RG
UT WOS:000457536000001
OA Bronze
DA 2019-03-21
ER

PT J
AU Danaher, J
AF Danaher, John
TI The rise of the robots and the crisis of moral patiency
SO AI & SOCIETY
LA English
DT Article
DE Robotics; Artificial intelligence; Technological unemployment;
   Algocracy; Moral agents; Moral patients
AB This paper adds another argument to the rising tide of panic about robots and AI. The argument is intended to have broad civilization-level significance, but to involve less fanciful speculation about the likely future intelligence of machines than is common among many AI-doomsayers. The argument claims that the rise of the robots will create a crisis of moral patiency. That is to say, it will reduce the ability and willingness of humans to act in the world as responsible moral agents, and thereby reduce them to moral patients. Since that ability and willingness is central to the value system in modern liberal democratic states, the crisis of moral patiency has a broad civilization-level significance: it threatens something that is foundational to and presupposed in much contemporary moral and political discourse. I defend this argument in three parts. I start with a brief analysis of an analogous argument made (or implied) in pop culture. Though those arguments turn out to be hyperbolic and satirical, they do prove instructive as they illustrates a way in which the rise of robots could impact upon civilization, even when the robots themselves are neither malicious nor powerful enough to bring about our doom. I then introduce the argument from the crisis of moral patiency, defend its main premises and address objections.
C1 [Danaher, John] NUI Galway, Sch Law, Univ Rd, Galway, Ireland.
RP Danaher, J (reprint author), NUI Galway, Sch Law, Univ Rd, Galway, Ireland.
EM johndanaher1984@gmail.com
CR Avent R, 2016, THE WEALTH OF HUMANS
   Bhuta N, 2016, AUTONOMOUS WEAPONS S
   Bostrom N., 2014, SUPERINTELLIGENCE PA
   Brynjolfsson E, 2014, 2 MACHINE AGE
   Calo R, 2016, ROBOT LAW
   Carr N, 2014, THE GLASS CAGE
   Danaher J, 2017, CRIM LAW PHILOS, V11, P71, DOI 10.1007/s11572-014-9362-x
   Danaher John, 2014, J EVOLUTION TECHNOLO, V24, P113
   Dormehl L., 2014, FORMULA ALGORITHMS S
   Floridi L., 1999, Ethics and Information Technology, V1, P37
   Ford M., 2015, RISE ROBOTS
   Frey C. B., 2013, FUTURE EMPLOYMENT SU
   Griggs B, 2014, CNN
   Gunkel D, 2011, THE MACHINE QUESTION
   Hajdin M., 1994, BOUNDARIES MORAL DIS
   Peter F, 2008, EPISTEME-J INDIV SOC, V5, P33, DOI 10.3366/E1742360008000221
   Susskind R, 2015, FUTURE PROFESSIONS
   Van de Voort M, 2015, ETHICS INF TECHNOL, V17, P41, DOI 10.1007/s10676-015-9360-2
NR 18
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0951-5666
EI 1435-5655
J9 AI SOC
JI AI Soc.
PD MAR
PY 2019
VL 34
IS 1
SI SI
BP 129
EP 136
DI 10.1007/s00146-017-0773-9
PG 8
WC Computer Science, Artificial Intelligence
SC Computer Science
GA HJ9RG
UT WOS:000457536000016
DA 2019-03-21
ER

PT J
AU Cunneen, M
   Mullins, M
   Murphy, F
   Gaines, S
AF Cunneen, Martin
   Mullins, Martin
   Murphy, Finbarr
   Gaines, Sean
TI Artificial Driving Intelligence and Moral Agency: Examining the Decision
   Ontology of Unavoidable Road Traffic Accidents through the Prism of the
   Trolley Dilemma
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
ID RESPONSIBILITY
AB The question of the capacity of artificial intelligence to make moral decisions has been a key focus of investigation in robotics for decades. This question has now become pertinent to automated vehicle technologies, as a question of understanding the capacity of artificial driving intelligence to respond to unavoidable road traffic accidents. Artificial driving intelligence will make a calculated decision that could equate to deciding who lives and who dies. In calculating such important decisions, does the driving intelligence require moral intelligence and a capacity to make informed moral decisions? Artificial driving intelligence will be determined by at very least, state laws, driving codes, and codes of conduct relating to driving behaviour and safety. Does it also need to be informed by ethical theories, human values, and human rights frameworks? If so, how can this be achieved and how can we ensure there are no moral biases in the moral decision-making algorithms? The question of moral capacity is complex and has become the ethical focal point of this technology. Research has centred on applying Philippa Foot's famous trolley dilemma. We claim that before applications attempt to focus on moral theories, there is a necessary precedent to utilise the trolley dilemma as an ontological experiment. The trolley dilemma is succinct in identifying important ontological differences between human driving intelligence and artificial driving intelligence. In this paper, we argue that when the trolley dilemma is focused upon ontology, it has the potential to become an important elucidatory tool. It can act as a prism through which one can perceive different ontological aspects of driving intelligence and assess response decisions to unavoidable road traffic accidents. The identification of the ontological differences is integral to understanding the underlying variances that support human and artificial driving decisions. Ontologically differentiating between these two contexts allows for a more complete interrogation of the moral decision-making capacity of the artificial driving intelligence.
C1 [Cunneen, Martin; Mullins, Martin; Murphy, Finbarr] Univ Limerick, Dept Accounting & Finance, Limerick, Ireland.
   [Gaines, Sean] Vicomtech IK4, Int Projects, San Sebastian, Spain.
   [Gaines, Sean] Vi DAS Consortia, San Sebastian, Spain.
RP Cunneen, M (reprint author), Univ Limerick, Dept Accounting & Finance, Limerick, Ireland.
EM martin.cunneen@ul.ie
FU  [690772]
FX This work was supported by the Horizon 2020 [690772].
CR Anderson James M., 2014, AUTONOMOUS VEHICLE T
   ANSCOMBE GEM, 1958, PHILOSOPHY, V33, P1, DOI 10.1017/S0031819100037943
   Asveld L., 2009, ETHICTECHNOLOGICAL
   Bentham J., 1843, WORKS J BENTHAM, V8
   Biletzki A., 2013, MEANING USE DIGITAL
   Bonnefon J.F., 2015, AUTONOMOUS VEHICLES
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654
   Brooks R., 1996, P AAAI 96, P1340
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Cheng H, 2011, AUTONOMOUS INTELLIGE
   Chopra S, 2011, LEGAL THEORY FOR AUTONOMOUS ARTIFICIAL AGENTS, P5
   Coeckelbergh M, 2016, APPL ARTIF INTELL, V30, P748, DOI 10.1080/08839514.2016.1229759
   Dogan E., 2016, ETHICS DESIGN AUTOMA
   Foot P., 1978, VIRTUES VICES, P19
   Gerdes J., 2015, AUTONOMES FAHREN, P87
   Goodall NJ, 2016, APPL ARTIF INTELL, V30, P810, DOI 10.1080/08839514.2016.1229922
   Goodall NJ, 2014, TRANSPORT RES REC, P58, DOI 10.3141/2424-07
   Hermitte T., 2012, REV ACCIDENT CAUSATI
   Hevelke A, 2015, SCI ENG ETHICS, V21, P619, DOI 10.1007/s11948-014-9565-5
   Jing Wang, 2011, Advances in Spatial and Temporal Databases. Proceedings 12th International Symposium (SSTD 2011), P21, DOI 10.1007/978-3-642-22922-0_3
   Joyce R., 2003, MYTH MORALITY
   Kant I., 1783, GROUNDWORK METAPHYSI
   Kumfer W. J., 2016, P HUM FACT ERG SOC A, V60, P1844, DOI 10.1177/1541931213601421
   Lin P., 2013, ETHICS SAVING LIVES
   Lin P., 2015, AUTONOMES FAHREN, P69
   Malle BF, 2014, FRONT ARTIF INTEL AP, V273, P189, DOI 10.3233/978-1-61499-480-0-189
   Maurer M., 2016, AUTONOMOUS DRIVING T
   McCarthy J., 1955, AI MAG, V27, P12
   McCarthy J., 1996, WHAT HAS COMMON PHIL
   Meiring GAM, 2015, SENSORS-BASEL, V15, P30653, DOI 10.3390/s151229822
   Millar J., 2016, MOMENTOUS ADV ARTIFI
   Millar J., 2014, P WE ROB
   Nyholm S, 2016, ETHICAL THEORY MORAL, V19, P1275, DOI 10.1007/s10677-016-9745-2
   Rose B., 2016, MYTH AUTONOMOUS VEHI
   Selman B, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1340
   Sunstein CR, 2005, BEHAV BRAIN SCI, V28, P531
   THOMSON JJ, 1985, YALE LAW J, V94, P1395, DOI 10.2307/796133
   Trappl R., 2016, APPL ARTIF INTELL, V30
   Van Den Beukel A. P., 2016, IEEE INT VEH S P IV
   Van Suntum U, 1984, Z VERKEHRSWISS, V55
   Wallach W., 2008, MORAL MACHINES TEACH
   Young S., 2016, MORAL ALGORITHM SET
NR 42
TC 0
Z9 0
U1 1
U2 1
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD FEB 23
PY 2019
VL 33
IS 3
BP 267
EP 293
DI 10.1080/08839514.2018.1560124
PG 27
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA HM6KJ
UT WOS:000459582900003
DA 2019-03-21
ER

PT J
AU Nijssen, SRR
   Muller, BCN
   van Baaren, RB
   Paulus, M
AF Nijssen, Sari R. R.
   Mueller, Barbara C. N.
   van Baaren, Rick B.
   Paulus, Markus
TI SAVING THE ROBOT OR THE HUMAN? ROBOTS WHO FEEL DESERVE MORAL CARE
SO SOCIAL COGNITION
LA English
DT Article
DE anthropomorphism; morality; human-robot interaction
ID INDIVIDUAL-DIFFERENCES; MIND; RESPONSES; AGENTS; GAZE
AB Robots are becoming an integral part of society, yet our moral stance toward these non-living objects is unclear. In two experiments, we investigated whether anthropomorphic appearance and anthropomorphic attributions modulated people's utilitarian decision making about robotic agents. In Study 1, participants were presented with moral dilemmas in which the to-be-sacrificed agent was either a human, a human-like robot, or a machine-like robot. These victims were described in either neutral or anthropomorphic priming stories. Study 2 teased apart anthropomorphic attributions of agency and affect. Results indicate that although robot-like robots were sacrificed significantly more often than humans and human-like robots, the effect of humanized priming was the same for all three agent types (Study 1), and this effect was mainly due to the attribution of affective states rather than agency (Study 2). That is, when people attribute affective states to robots, they are less likely to sacrifice them in order to save humans.
C1 [Nijssen, Sari R. R.; Mueller, Barbara C. N.; van Baaren, Rick B.] Radboud Univ Nijmegen, Behav Sci Inst, Nijmegen, Netherlands.
   [Paulus, Markus] Ludwig Maximilians Univ Munchen, Munich, Germany.
RP Nijssen, SRR (reprint author), Radboud Univ Nijmegen, Behav Sci Inst, POB 9104, NL-6500 HE Nijmegen, Netherlands.
EM S.Nijssen@psych.ru.nl
FU Jacobs Foundation [2014-1155]
FX We would like to thank Xin Gao for his assistance with programming the
   experiments and data collection. This research was funded by Jacobs
   Foundation Grant 2014-1155.
CR Arita A, 2005, COGNITION, V95, pB49, DOI 10.1016/j.cognition.2004.08.001
   Bartels DM, 2011, COGNITION, V121, P154, DOI 10.1016/j.cognition.2011.05.010
   Bentham Jeremy, 1948, INTRO PRINCIPLES MOR
   Bisio A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106172
   Carpenter J, 2013, HDB RES TECHNOSELF I, P609, DOI 10.4018/978-1-4666-2211-1
   Colby A., 1987, MEASUREMENT MORAL JU, V2
   Decety Jean, 2004, Behav Cogn Neurosci Rev, V3, P71, DOI 10.1177/1534582304267187
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Ferrari F, 2016, INT J SOC ROBOT, V8, P287, DOI 10.1007/s12369-016-0338-y
   Gazzola V, 2007, NEUROIMAGE, V35, P1674, DOI 10.1016/j.neuroimage.2007.02.003
   Gleichgerrcht E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060418
   Gray HM, 2007, SCIENCE, V315, P619, DOI 10.1126/science.1134475
   Gray K, 2012, COGNITION, V125, P125, DOI 10.1016/j.cognition.2012.06.007
   Greene J, 2002, TRENDS COGN SCI, V6, P517, DOI 10.1016/S1364-6613(02)02011-9
   Greene JD, 2004, NEURON, V44, P389, DOI 10.1016/j.neuron.2004.09.027
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872
   Haslam N, 2006, PERS SOC PSYCHOL REV, V10, P252, DOI 10.1207/s15327957pspr1003_4
   Heider F, 1944, AM J PSYCHOL, V57, P243, DOI 10.2307/1416950
   Hume D, 1956, NATURAL HIST RELIG
   Itakura S, 2008, INFANCY, V13, P519, DOI 10.1080/15250000802329503
   JASP Team, 2017, JASP VERS 0 8 1 2 CO
   Johnson S, 1998, DEVELOPMENTAL SCI, V1, P233, DOI 10.1111/1467-7687.00036
   Kant Immanuel, 1964, GROUNDWORK METAPHYSI
   Kwan VSY, 2008, SOC COGNITION, V26, P125, DOI 10.1521/soco.2008.26.2.125
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Liepelt R, 2010, COGNITION, V115, P426, DOI 10.1016/j.cognition.2010.03.003
   Limerick H, 2014, FRONT HUM NEUROSCI, V8, DOI [10.3389/tnhurn.2014.00643, 10.3389/fnhum.2014.00643]
   Majdandzic J, 2016, COGNITION, V157, P24, DOI 10.1016/j.cognition.2016.08.003
   Majdandzic J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047698
   Moore AB, 2008, PSYCHOL SCI, V19, P549, DOI 10.1111/j.1467-9280.2008.02122.x
   Morewedge CK, 2007, J PERS SOC PSYCHOL, V93, P1, DOI 10.1037/0022-3514.93.1.1
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Moriguchi Y, 2010, DEVELOPMENTAL SCI, V13, P62, DOI 10.1111/j.1467-7687.2009.00860.x
   Muller BCN, 2014, SOC COGNITION, V32, P381
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Oberman LM, 2007, NEUROCOMPUTING, V70, P2194, DOI 10.1016/j.neucom.2006.02.024
   Okumura Y, 2013, J EXP CHILD PSYCHOL, V116, P86, DOI 10.1016/j.jecp.2013.02.007
   Paulus M, 2014, PSYCHON B REV, V21, P1139, DOI 10.3758/s13423-014-0598-1
   Pletti C, 2017, BRIT J PSYCHOL, V108, P351, DOI 10.1111/bjop.12205
   Press C, 2005, COGNITIVE BRAIN RES, V25, P632, DOI 10.1016/j.cogbrainres.2005.08.020
   Roese NJ, 2009, PERSPECT PSYCHOL SCI, V4, P429, DOI 10.1111/j.1745-6924.2009.01150.x
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Sherman GD, 2011, EMOT REV, V3, P245, DOI 10.1177/1754073911402396
   Singer P, 1981, THE EXPANDING CIRCLE
   Stenzel A, 2012, J EXP PSYCHOL HUMAN, V38, P1073, DOI 10.1037/a0029493
   Tanibe T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180952
   van Baaren RB, 2004, PSYCHOL SCI, V15, P71, DOI 10.1111/j.0963-7214.2004.01501012.x
   Waytz A, 2014, J EXP SOC PSYCHOL, V52, P113, DOI 10.1016/j.jesp.2014.01.005
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
NR 50
TC 0
Z9 0
U1 2
U2 2
PU GUILFORD PUBLICATIONS INC
PI NEW YORK
PA 370 SEVENTH AVE, SUITE 1200, NEW YORK, NY 10001-1020 USA
SN 0278-016X
J9 SOC COGNITION
JI Soc. Cogn.
PD FEB
PY 2019
VL 37
IS 1
BP 41
EP +
DI 10.1521/soco.2019.37.1.41
PG 18
WC Psychology, Social
SC Psychology
GA HK5XJ
UT WOS:000458042500003
DA 2019-03-21
ER

PT J
AU Torras, C
AF Torras, Carme
TI SOCIAL NETWORKS AND ROBOT COMPANIONS TECHNOLOGY, ETHICS, AND SCIENCE
   FICTION
SO METODE SCIENCE STUDIES JOURNAL
LA English
DT Article
DE social networks; assistive robotics; ethics; science fiction; science
   and humanities
AB Information technologies have become part of our everyday lives and are increasingly acting as intermediaries in our workplaces and personal relationships or even substituting them. This growing interaction with machines poses several questions about which we have no previous experience, nor can we reliably predict how they will influence the evolution of society. This has led to the convergence of technoscience and humanities in an ethical debate that is starting to bear fruit, not only with the setting of regulations and standards, but also with educational initiatives in university teaching, professional improvement, and the conformation of public opinion. Interestingly, science fiction often plays a prominent speculative role in highlighting the pros and cons of potential scenarios.
C1 [Torras, Carme] CSIC UPC, Robot Inst, Barcelona, Spain.
   [Torras, Carme] CSIC UPC, Robot Inst, Res Grp Assist & Collaborat Robot, Barcelona, Spain.
RP Torras, C (reprint author), CSIC UPC, Robot Inst, Barcelona, Spain.; Torras, C (reprint author), CSIC UPC, Robot Inst, Res Grp Assist & Collaborat Robot, Barcelona, Spain.
EM torras@iri.upc.edu
CR Bearne S., 2016, GUARDIAN
   Hunt Elle., 2016, GUARDIAN, V20/8
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Swain C., 2007, P 2007 DIGRA C SIT P, P805
   Torras C., 2017, ENXARXATS
   Torras C., 2018, VESTIGIAL HEART NOVE
   Torras C., 2008, MUTACIO SENTIMENTAL
   Torras C, 2016, EUR REV, V24, P17, DOI 10.1017/S1062798715000393
   Veruggio G, 2016, SPRINGER HANDBOOK OF ROBOTICS, P2135
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   Wu M., 2012, LITHIUM COMMUNITY
NR 11
TC 0
Z9 0
U1 0
U2 0
PU UNIV VALENCIA, BOTANICAL GARDEN UV
PI VALENCIA
PA C/QUART, 80, VALENCIA, 46008, SPAIN
SN 2174-3487
EI 2174-9221
J9 METODE SCI STUD J
JI Metode Sci. Stud. J.
PY 2019
IS 9
BP 163
EP 169
DI 10.7203/metode.9.12479
PG 7
WC History & Philosophy Of Science
SC History & Philosophy of Science
GA HN7QX
UT WOS:000460387700022
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Mayer, T
AF Mayer, Tobias
TI Digital Humanism. An Ethics for the Age of Artificial Intelligence
SO INTERNATIONALE KATHOLISCHE ZEITSCHRIFT COMMUNIO
LA German
DT Book Review
C1 [Mayer, Tobias] Katholisch Theol Fak, Inst Systemat Theol & Eth, Schenkenstr 8-10, A-1010 Vienna, Austria.
RP Mayer, T (reprint author), Katholisch Theol Fak, Inst Systemat Theol & Eth, Schenkenstr 8-10, A-1010 Vienna, Austria.
EM tobias.mayer@univie.ac.at
CR WEIDENFELD N, 2018, DIGITALER HUMANISMUS
NR 1
TC 0
Z9 0
U1 2
U2 2
PU SCHWABENVERLAG AG
PI OSTFILDERN
PA SENEFELDERSTR 12, OSTFILDERN, 73760, GERMANY
SN 1439-6165
J9 INT KATHOL Z COMMUNI
JI Int. Kathol. Z. Communio
PD JAN-FEB
PY 2019
IS 1
BP 108
EP 110
DI 10.14623/com.2019.1.108-110
PG 3
WC Religion
SC Religion
GA HJ9ZL
UT WOS:000457557700011
DA 2019-03-21
ER

PT J
AU Loi, M
   Christen, M
AF Loi, Michele
   Christen, Markus
TI How to Include Ethics in Machine Learning Research
SO ERCIM NEWS
LA English
DT Article
AB The use of machine learning in decision-making has triggered an intense debate about "fair algorithms". Given that fairness intuitions differ and can led to conflicting technical requirements, there is a pressing need to integrate ethical thinking into research and design of machine learning. We outline a framework showing how this can be done.
C1 [Loi, Michele; Christen, Markus] Univ Zurich, DSI Digital Eth Lab, Zurich, Switzerland.
RP Loi, M (reprint author), Univ Zurich, DSI Digital Eth Lab, Zurich, Switzerland.
EM michele.loi@uzh.ch; christen@ethik.uzh.ch
CR Berk R., 2017, ARXIV170309207STAT
   Chouldechova A., 2016, ARXIV161007524CSSTAT
   Kleinberg J., 2016, ARXIV160905807CSSTAT
NR 3
TC 0
Z9 0
U1 3
U2 3
PU EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS
PI SOPHIA ANTIPOLIS CEDEX
PA 2004, ROUTE LUCIOLES, BP 93, SOPHIA ANTIPOLIS CEDEX, 06902, FRANCE
SN 0926-4981
EI 1564-0094
J9 ERCIM NEWS
JI ERCIM News
PD JAN
PY 2019
IS 116
BP 5
EP 5
PG 1
WC Computer Science, Interdisciplinary Applications
SC Computer Science
GA HI8FF
UT WOS:000456690000003
DA 2019-03-21
ER

PT J
AU Savirimuthu, J
AF Savirimuthu, Joseph
TI Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence
SO INTERNATIONAL JOURNAL OF LAW AND INFORMATION TECHNOLOGY
LA English
DT Book Review
C1 [Savirimuthu, Joseph] Univ Liverpool, Liverpool Law Sch, Liverpool, Merseyside, England.
RP Savirimuthu, J (reprint author), Univ Liverpool, Liverpool Law Sch, Liverpool, Merseyside, England.
EM jsaviri@liverpool.ac.uk
CR Baldwin R., 1991, MOD LAW REV, V53, P321
   Basl John, 2014, PHILOS TECHNOLOGY, V27, P79
   Black Julia, 1996, RULES REGULATORS, P214
   Bostrom N., 2014, SUPERINTELLIGENCE PA
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   Clarke Arthur C, 1962, PROFILES FUTURE ENQU, P21
   Good Irwin J., 1965, ADV COMPUT, V6, P31, DOI [10.1016/S0065-2458(08)60418-0, DOI 10.1016/S0065-2458(08)60418-0]
   Gunkel DJ, 2014, PHILOS TECHNOL, V27, P113, DOI DOI 10.1007/S13347-013-0121-Z
   Hawking Stephen, 2014, INDEPENDENT
   Lin P, 2012, INTELL ROBOT AUTON, P1
   LIN P, 2017, ROBOT ETHICS 20 AUTO
   Lukacs Georg, 1971, THEORY NOVEL, P21
   Wakabayashi Daisuke, 2018, NY TIMES, pA1
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 14
TC 0
Z9 0
U1 0
U2 0
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0967-0769
EI 1464-3693
J9 INT J LAW INFORM TEC
JI Int. J. Law Inform. Technol.
PD WIN
PY 2018
VL 26
IS 4
BP 337
EP 346
DI 10.1093/ijlit/eay011
PG 10
WC Law
SC Government & Law
GA HI6IJ
UT WOS:000456557700004
OA Bronze
DA 2019-03-21
ER

PT J
AU Wynsberghe, A
   Donhauser, J
AF van Wynsberghe, Aimee
   Donhauser, Justin
TI The Dawning of the Ethics of Environmental Robots
SO SCIENCE AND ENGINEERING ETHICS
LA English
DT Article
DE Robot ethics; Environmental robotics; Ecological robots; Ethics and
   technology; Environmental engineering
ID SENSOR NETWORKS; HYBRID POPLAR; PHYTOREMEDIATION; FRONTIERS; TRACKING;
   SCIENCE
AB Environmental scientists and engineers have been exploring research and monitoring applications of robotics, as well as exploring ways of integrating robotics into ecosystems to aid in responses to accelerating environmental, climatic, and biodiversity changes. These emerging applications of robots and other autonomous technologies present novel ethical and practical challenges. Yet, the critical applications of robots for environmental research, engineering, protection and remediation have received next to no attention in the ethics of robotics literature to date. This paper seeks to fill that void, and promote the study of environmental robotics. It provides key resources for further critical examination of the issues environmental robots present by explaining and differentiating the sorts of environmental robotics that exist to date and identifying unique conceptual, ethical, and practical issues they present.
C1 [van Wynsberghe, Aimee] Delft Univ Technol, Jaffalaan 5, NL-2628 BX Delft, Netherlands.
   [Donhauser, Justin] Western Univ, Rotman Inst Philosophy, 2150 Stevenson Hall, London, ON N6A 5B8, Canada.
RP Wynsberghe, A (reprint author), Delft Univ Technol, Jaffalaan 5, NL-2628 BX Delft, Netherlands.
EM aimeevanrobot@gmail.com; jdonhaus@uwo.ca
FU Netherlands Organization for Scientific Research (NWO) [275-20-054]
FX This research is supported by the Netherlands Organization for
   Scientific Research (NWO), Project Number 275-20-054.
CR Adams N., 2000, INTRO PHYTOREMEDIATI
   [Anonymous], LIONF PROJ THIS INV
   [Anonymous], 2017, NY TIMES, P24
   [Anonymous], PROGR ROB SWARMS
   [Anonymous], 2000, TOD EC
   [Anonymous], EC ENG PROJ
   Aravind KR, 2017, SPAN J AGRIC RES, V15, DOI 10.5424/sjar/2017151-9573
   Asaro PM, 2006, INT REV INF ETHICS, V6, P9
   ASIMOV I, 1990, ROBOT VISIONS
   Best EPH, 1997, ANN NY ACAD SCI, V829, P179, DOI 10.1111/j.1749-6632.1997.tb48574.x
   Blersch DM, 2010, AUTONOMOUS ALGAL TUR
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316
   Burger AE, 2008, AUK, V125, P253, DOI 10.1525/auk.2008.1408
   Burken JG, 1998, ENVIRON SCI TECHNOL, V32, P3379, DOI 10.1021/es9706817
   Cai TT, 2006, ECOL MODEL, V190, P317, DOI 10.1016/j.ecolmodel.2005.04.022
   Capurro R, 2009, ETHICS AND ROBOTICS, P117
   Chappell J., 1997, PHYTOREMEDIATION TCE
   Choi-Fitzpatrick A., 2014, J INT AFF, V68, P19
   Clark CM, 2013, J FIELD ROBOT, V30, P309, DOI 10.1002/rob.21450
   Clark OG, 1999, ENG APPL ARTIF INTEL, V12, P389, DOI 10.1016/S0952-1976(99)00010-X
   Colyvan M, 2009, ECOL SOC, V14
   Coxworth B., 2015, NEW ATLAS
   Crandall B. C., 1996, NANOTECHNOLOGY MOL S
   Dhariwal A., 2004, IEEE INT C P ROB AUT
   DICKMANN DI, 1983, CULTURE POPLARS E N
   Ditmer MA, 2015, CURR BIOL, V25, P2278, DOI 10.1016/j.cub.2015.07.024
   Donhauser J, 2017, ETHICS POLICY ENV, V20, P263, DOI 10.1080/21550085.2017.1374023
   Donhauser J, 2016, ETHICS ENVIRON, V21, P1, DOI 10.2979/ethicsenviro.21.2.01
   Dunbabin M, 2012, IEEE ROBOT AUTOM MAG, V19, P24, DOI 10.1109/MRA.2011.2181683
   Elliott O, 2017, J CONTEMP WAT RES ED, V160, P144, DOI 10.1111/j.1936-704X.2017.03246.x
   EURANOS, 2006, CAT1TN0606 EURANOS
   Gordon M, 1998, ENVIRON HEALTH PERSP, V106, P1001, DOI 10.2307/3434144
   Green C, 2004, PHYTOREMEDIATION FIE
   Gremillet D., 2012, Open Journal of Ecology, V2, P49, DOI 10.4236/oje.2012.22006
   Hart JK, 2006, EARTH-SCI REV, V78, P177, DOI 10.1016/j.earscirev.2006.05.001
   Hegde M., 2011, 15 INT C MIN SYST CH
   Hodgson JC, 2016, SCI REP-UK, V6, DOI 10.1038/srep22574
   Hughes AM, 2014, BMC HEALTH SERV RES, V14, DOI 10.1186/1472-6963-14-124
   Ivosevic Bojana, 2015, Journal of Ecology and Environment, V38, P113, DOI 10.5141/ecoenv.2015.012
   Kangas P, 2004, ECOLOGICAL ENG PRINC
   Kardel K, 2015, 3D PRINT ADDIT MANUF, V2, P12, DOI 10.1089/3dp.2014.0024
   Koh LP, 2012, TROP CONSERV SCI, V5, P121, DOI 10.1177/194008291200500202
   Lam TL, 2012, SPRINGER TRAC ADV RO, V78, P1, DOI 10.1007/978-3-642-28311-6
   Lampton C., 1993, NANOTECHNOLOGY PLAYH
   Le Maho Y, 2014, NAT METHODS, V11, P1242, DOI [10.1038/NMETH.3173, 10.1038/nmeth.3173]
   Light A., 2017, WHITE HOUSE ABANDONI
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Mission Vision, ROB SERV ENV
   Myers Jack, 1944, JOUR GEN PHYSIOL, V28, P103, DOI 10.1085/jgp.28.2.103
   O'Neill J., 2007, MARKETS DELIBERATION
   Odum HT, 1993, ECOLOGICAL GEN SYSTE
   Parrott L, 1996, ECOCYBORG PROJECT MO
   Peckham SH, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001041
   Petersen JE, 2001, OIKOS, V94, P533, DOI 10.1034/j.1600-0706.2001.940315.x
   Rundel PW, 2009, NEW PHYTOL, V182, P589, DOI 10.1111/j.1469-8137.2009.02811.x
   Rutz C, 2009, BIOL LETTERS, V5, P289, DOI 10.1098/rsbl.2009.0089
   Sharkey N, 2008, SCIENCE, V322, P1800, DOI 10.1126/science.1164582
   Shockley K, 2014, ENVIRON VALUE, V23, P199, DOI 10.3197/096327114X13894344179248
   Siegwart R., 2004, AUTONOMOUS MOBILE RO
   Succuro J. S., 2009, RECENT ADV PLANT BIO, DOI 10. 1007/978-1-4419-0194-1_7.
   Sullins J. P., 2011, PHILOS TECHNOL, V24, P233, DOI DOI 10.1007/S13347-011-0043-6
   Susarla S, 2002, ECOL ENG, V18, P647, DOI 10.1016/S0925-8574(02)00026-5
   Tanaka S, 2007, INT J PHYTOREMEDIAT, V9, P15, DOI 10.1080/15226510601139375
   Todd J., 1991, Ecological engineering for wastewater treatment. Proceedings of the International Conference held at Stensund Folk College, Sweden, March 24-28, 1991., P335
   Todd N. J., 1994, ECOCITIES LIVING MAC
   Townsend J. A., 2014, SPACEOPS 2014 C
   Tripathi R., 2008, DEV PHYSL BIOCH MOL, P175
   UNFCCC, 2015, AD PAR AGREEM
   UNFCCC, 2013, WARS INT MECH LOSS D
   Vangronsveld J, 2009, ENVIRON SCI POLLUT R, V16, P765, DOI 10.1007/s11356-009-0213-6
   Vas E, 2015, BIOL LETTERS, V11, DOI 10.1098/rsbl.2014.0754
   Wadhams P, 2006, GEOPHYS RES LETT, V33, DOI 10.1029/2005GL0251331
   Whitcomb L. L., 2000, IEEE INT C ROB AUT P
   Wynsberghe Aimee van, 2016, HEALTHCARE ROBOTS ET
   Yaghoubi S., 2013, INT J MECH MECHATRON, V13, P1
   Yoerger DR, 2000, INT J ROBOT RES, V19, P1000, DOI 10.1177/02783640022067931
   Yoshida K, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1423
   Zalesny RS, 2005, INT J PHYTOREMEDIAT, V7, P177, DOI 10.1080/16226510500214632
NR 78
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1353-3452
EI 1471-5546
J9 SCI ENG ETHICS
JI Sci. Eng. Ethics
PD DEC
PY 2018
VL 24
IS 6
BP 1777
EP 1800
DI 10.1007/s11948-017-9990-3
PG 24
WC Ethics; Engineering, Multidisciplinary; History & Philosophy Of Science;
   Multidisciplinary Sciences; Philosophy
SC Social Sciences - Other Topics; Engineering; History & Philosophy of
   Science; Science & Technology - Other Topics; Philosophy
GA HC3PT
UT WOS:000451715300007
PM 29058118
OA Other Gold, Green Published
DA 2019-03-21
ER

PT J
AU Dhai, A
AF Dhai, Ames
TI Advances in biotechnology: Human genome editing, artificial intelligence
   and the Fourth Industrial Revolution - the law and ethics should not lag
   behind
SO SOUTH AFRICAN JOURNAL OF BIOETHICS AND LAW
LA English
DT Editorial Material
EM ames.dhai@wits.ac.za
CR [Anonymous], 2018, GEN ED HUM REPR SOC
   Mahomed S, 2018, S AFR J BIOETH LAW, V11, P93, DOI [10.7196/SAJBL.2018.v11i2.664, 10.7196/SAJBL.2018.v11i1.649]
   National Academies of Sciences Engineering and Medicine, 2017, HUM GEN ED SCI ETH G
   Pillay S, 2018, S AFR J BIOETH LAW, V11, P89, DOI 10.7196/SAJBL.2018.v11i2.653
NR 4
TC 0
Z9 0
U1 7
U2 7
PU HEALTH & MEDICAL PUBLISHING GROUP
PI CAPE TOWN
PA PRIVATE BAG X1, PINELANDS, CAPE TOWN, 7430, SOUTH AFRICA
SN 1999-7639
J9 S AFR J BIOETH LAW
JI S. Afr. J. Bioeth. Law
PD NOV
PY 2018
VL 11
IS 2
BP 58
EP 59
DI 10.7196/SAJBL.2018.v11i2.667
PG 2
WC Medical Ethics
SC Medical Ethics
GA HC5ZO
UT WOS:000451881100001
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Maxmen, A
AF Maxmen, Amy
TI A moral map for AI cars
SO NATURE
LA English
DT News Item
CR Awad E, 2018, NATURE, V563, P59, DOI 10.1038/s41586-018-0637-6
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654
NR 2
TC 0
Z9 0
U1 8
U2 8
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 0028-0836
EI 1476-4687
J9 NATURE
JI Nature
PD OCT 25
PY 2018
VL 562
IS 7728
BP 469
EP 470
DI 10.1038/d41586-018-07135-0
PG 2
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GY1HQ
UT WOS:000448277800020
PM 30356197
DA 2019-03-21
ER

PT J
AU Harris, J
AF Harris, John
TI Who Owns My Autonomous Vehicle? Ethics and Responsibility in Artificial
   and Human Intelligence
SO CAMBRIDGE QUARTERLY OF HEALTHCARE ETHICS
LA English
DT Article
DE autonomy; autonomous vehicles; ownership; artificially intelligent
   people
AB This article investigates both the claims made for, and the dangers or opportunities posed by, the development of (allegedly), aspiring or "would-be" autonomous vehicles and other artificially superintelligent machines. It also examines the dilemmas posed by the fact that these individuals might develop ideas above their station. These ideas may also limit or challenge the legitimacy of the proposed management and safety strategies that might be devised to limit the ways in which they might function or malfunction.
C1 [Harris, John] Univ Manchester, Manchester, Lancs, England.
RP Harris, J (reprint author), Univ Manchester, Manchester, Lancs, England.
CR [Anonymous], 2014, BBC NEWS        1202
   [Anonymous], 2018, NEVER LET ME GO
   [Anonymous], 2018, M LUTHER ANTISEMITIS
   Bayern S., 2017, HASTINGS SCI TECHNOL, V9, P135
   Brown AC, 1976, A BODYGUARD OF LIES
   Coke E., 1628, 3 PART I LAWS ENGL 3, P47
   Dworkin G., 1988, THEORY PRACTICE AUTO
   Eliot TS, 1974, COLLECTED POEMS, P4
   Foot P., 1978, VIRTUES VICES, P5
   Glover J., 1970, RESPONSIBILITY
   HARRIS J, 1975, PHILOSOPHY, V50, P81, DOI 10.1017/S0031819100059118
   Harris J., 1980, VIOLENCE RESPONSIBIL
   Harris J., 2016, HOW TO BE GOOD, p[95, 105]
   Harris J., 1985, VALUE LIFE
   Harris J., 2015, REASON PRACTICE BIOE, P16
   Harris J., 1985, THE VALUE OF LIFE, P195
   Harris J, 2013, MED LAW REV, V21, P131, DOI 10.1093/medlaw/fwt002
   Harris J, 2011, CAMB Q HEALTHC ETHIC, V20, P9, DOI 10.1017/S0963180109990570
   Hart HLA, 1968, PUNISHMENT RESPONSIB
   Jones RV, 1979, MOST SECRET WAR, P204
   KAUFMANN T, 2017, LUTHERS JEWS JOURNEY
   Lawrence DR, 2016, CAMB Q HEALTHC ETHIC, V25, P250, DOI 10.1017/S0963180115000559
   Lawrence DR, 2018, BRIDGING GAP SCI SOC
   Luther Martin, 1997, M LUTHER EXCERPTS HI
   Morris D.Z., 2016, FORTUNE
   O'Neill O., 2002, AUTONOMY TRUST BIOET
   Ocker C., 2018, ANTIJUDAISM ANTISEMI, DOI DOI 10.1093/ACREF0RE/9780199340378.001.0001/ACREF0RE-9780199340378-E-312
   Pears DF, 1969, FREEDOM AND THE WILL
   Popper K., 2004, LOGIC SCI DISCOVERY, P19
   Raz Joseph, 1986, MORALITY FREEDOM
   Robert Nozick Feser E., INTERNET ENCY PHILOS
   Rodgers P., 2014, FORBES          0805
   Shakespeare W., 1998, ARDEN SHAKESPEARE
   Shakespeare W., 1914, COMPLETE WORKS W SHA
   Thornton S., 2016, STANFORD ENCY PHILOS
   Waldron J., 2005, AUTONOMY CHALLENGES
NR 36
TC 0
Z9 0
U1 8
U2 9
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0963-1801
EI 1469-2147
J9 CAMB Q HEALTHC ETHIC
JI Camb. Q. Healthc. Ethics
PD OCT
PY 2018
VL 27
IS 4
SI SI
BP 599
EP 609
DI 10.1017/S0963180118000038
PG 11
WC Health Care Sciences & Services; Health Policy & Services; Social
   Sciences, Biomedical
SC Health Care Sciences & Services; Biomedical Social Sciences
GA HJ8XO
UT WOS:000457483600008
PM 30079847
DA 2019-03-21
ER

PT J
AU Trussell, HJ
AF Trussell, H. Joel
TI Why a Special Issue on Machine Ethics
SO PROCEEDINGS OF THE IEEE
LA English
DT Editorial Material
OI Trussell, Henry/0000-0002-8521-2269
CR Anderson M., P IEEE
   Ema A., P IEEE
   Korunovska J., P IEEE
   Minsky M., 1972, PERCEPTRONS INTRO CO
NR 4
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9219
EI 1558-2256
J9 P IEEE
JI Proc. IEEE
PD OCT
PY 2018
VL 106
IS 10
BP 1774
EP 1776
DI 10.1109/JPROC.2018.2868336
PG 3
WC Engineering, Electrical & Electronic
SC Engineering
GA GV6HJ
UT WOS:000446208900001
DA 2019-03-21
ER

PT J
AU Kohli, M
   Geis, R
AF Kohli, Marc
   Geis, Raym
TI Ethics, Artificial Intelligence, and Radiology
SO JOURNAL OF THE AMERICAN COLLEGE OF RADIOLOGY
LA English
DT Editorial Material
ID PREDICTIVE ANALYTICS; BIG DATA; HEALTH
C1 [Kohli, Marc] Univ Calif San Francisco, San Francisco, CA 94143 USA.
   [Geis, Raym] Natl Jewish Hlth, Dept Radiol, 3401 Shore Rd, Ft Collins, CO 80524 USA.
RP Geis, R (reprint author), Natl Jewish Hlth, Dept Radiol, 3401 Shore Rd, Ft Collins, CO 80524 USA.
EM raym.geis@gmail.com
FU Intelerad Medical Systems
FX Dr Geis is an adviser to Philips Healthcare, is a shareholder in Montage
   Healthcare Solutions (purchased by Nuance), has received speaking fees
   from Intelerad Medical Systems, and is an adviser to Innosphere. Dr
   Kohli has no conflicts of interest related to the material discussed in
   this article.
CR Adjekum A, 2017, OMICS, V21, P704, DOI 10.1089/omi.2017.0156
   Ballantyne A, 2018, J MED ETHICS, V44, P392, DOI 10.1136/medethics-2017-104550
   Balthazar P, 2018, J AM COLL RADIOL, V15, P580, DOI 10.1016/j.jacr.2017.11.035
   Carlini N, ARXIV180208232
   Floridi L, 2016, PHILOS T R SOC A, V374
   Future of Life Institute, AI PRINC
   Mikk KA, 2017, JAMA-J AM MED ASSOC, V318, P1433, DOI 10.1001/jama.2017.12145
   Mittelstadt BD, 2016, SCI ENG ETHICS, V22, P303, DOI 10.1007/s11948-015-9652-2
   Song C, ARXIV170907886
NR 9
TC 0
Z9 0
U1 16
U2 20
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 1546-1440
J9 J AM COLL RADIOL
JI J. Am. Coll. Radiol.
PD SEP
PY 2018
VL 15
IS 9
BP 1317
EP 1319
DI 10.1016/j.jacr.2018.05.020
PG 3
WC Radiology, Nuclear Medicine & Medical Imaging
SC Radiology, Nuclear Medicine & Medical Imaging
GA GS9TB
UT WOS:000444068900027
PM 30017625
DA 2019-03-21
ER

PT J
AU Shank, DB
   DeSanti, A
AF Shank, Daniel B.
   DeSanti, Alyssa
TI Attributions of morality and mind to artificial intelligence after real
   world moral violations
SO COMPUTERS IN HUMAN BEHAVIOR
LA English
DT Article
DE Artificial intelligence; Morality; Responsibility; Algorithm;
   Attributions; Perceived mind
ID MECHANICAL TURK; PERCEPTION; COMPUTERS; IMPRESSIONS; ACCOUNTS; AGENTS
AB The media has portrayed certain artificial intelligence (Al) software as committing moral violations such as the Al judge of a human beauty contest being "racist" when it selected predominately light skinned winners. We examine people's attributions of morality for seven such real-world events that were first publicized in the media, experimentally manipulating the occurrence of a violation and the inclusion of information about the Al's algorithm. Both the presence of the moral violation and the information about the Al's algorithm increase participant's reporting of a moral violation occurring in the event. However, even in the violation outcome conditions only 43.5 percent of the participants reported that they were sure that a moral violation occurred. Addressing whether the AI is blamed for the moral violation we found that people attributed increased wrongness to the Al but not to the organization, programmer, or users after a moral violation. In addition to moral wrongness, the Al was attributed moderate levels of awareness, intentionality, justification, and responsibility for the violation outcome. Finally, the inclusion of the algorithm information marginally increased perceptions of the Al having mind, and perceived mind was positively related to attributions of intentionality and wrongness to the Al. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Shank, Daniel B.; DeSanti, Alyssa] Missouri Univ Sci & Technol, Dept Psychol Sci, 500 W 14th St, Rolla, MO 65409 USA.
RP Shank, DB (reprint author), Missouri Univ Sci & Technol, Dept Psychol Sci, 500 W 14th St,H SS Bldg, Rolla, MO 65409 USA.
EM shankd@mst.edu
OI Shank, Daniel/0000-0002-3746-2407
CR Barque-Duran A, 2017, COMPUT HUM BEHAV, V75, P184, DOI 10.1016/j.chb.2017.05.020
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Gailey J. A., 2013, J CRIMINOLOGY, V2013, P1
   Gailey JA, 2008, SOCIOL SPECTRUM, V28, P659, DOI 10.1080/02732170802342958
   Graham J, 2011, J PERS SOC PSYCHOL, V101, P366, DOI 10.1037/a0021847
   Graham J, 2009, J PERS SOC PSYCHOL, V96, P1029, DOI 10.1037/a0015141
   Gray HM, 2007, SCIENCE, V315, P619, DOI 10.1126/science.1134475
   Gray K, 2014, J EXP PSYCHOL GEN, V143, P1600, DOI 10.1037/a0036149
   Gray K, 2012, COGNITION, V125, P125, DOI 10.1016/j.cognition.2012.06.007
   Gray K, 2012, PSYCHOL INQ, V23, P101, DOI 10.1080/1047840X.2012.651387
   Gray K, 2009, J PERS SOC PSYCHOL, V96, P505, DOI 10.1037/a0013748
   Haidt J, 2012, RIGHTEOUS MIND WHY G
   Hitlin S, 2008, MORAL SELVES, EVIL SELVES: THE SOCIAL PSYCHOLOGY OF CONSCIENCE, P1, DOI 10.1057/9780230614949
   Horton JJ, 2011, EXP ECON, V14, P399, DOI 10.1007/s10683-011-9273-9
   Jago A., 2017, ALGORITHMS AUTHENTIC
   LAWLER EJ, 1992, AM SOCIOL REV, V57, P327, DOI 10.2307/2096239
   Lee MK, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1035, DOI 10.1145/2998181.2998230
   Malle BF, 2014, PSYCHOL INQ, V25, P147, DOI 10.1080/1047840X.2014.877340
   Mason W, 2012, BEHAV RES METHODS, V44, P1, DOI 10.3758/s13428-011-0124-6
   Morewedge CK, 2007, J PERS SOC PSYCHOL, V93, P1, DOI 10.1037/0022-3514.93.1.1
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Paolacci G, 2010, JUDGM DECIS MAK, V5, P411
   Presser L, 2004, SOC PROBL, V51, P82, DOI 10.1525/sp.2004.51.1.82
   Reeves B, 1996, MEDIA EQUATION PEOPL
   Ross L, 2010, P 28 INT C HUM FACT, P2863, DOI DOI 10.1145/1753846.1753873
   SCOTT MB, 1968, AM SOCIOL REV, V33, P46, DOI 10.2307/2092239
   Shank DB, 2014, INT J HUM-COMPUT ST, V72, P747, DOI 10.1016/j.ijhcs.2014.05.002
   Shank DB, 2013, COMPUT HUM BEHAV, V29, P715, DOI 10.1016/j.chb.2012.11.006
   Shank DB, 2012, SOCIOL FORUM, V27, P372, DOI 10.1111/j.1573-7861.2012.01322.x
   Shank DB, 2016, AM SOCIOL, V47, P47, DOI DOI 10.1007/S12108-015-9266-9
   Shaver K. G, 1985, ATTRIBUTION BLAME CA
   Waytz A., 2010, MAKING SENSE MAKING, V86, P401
   Waytz A, 2012, PSYCHOL SCI, V23, P77, DOI 10.1177/0956797611423546
   Wegner D. M., 2017, MIND CLUB WHO THINKS
   WEINER B, 1985, PSYCHOL REV, V92, P548, DOI 10.1037/0033-295X.92.4.548
NR 35
TC 0
Z9 0
U1 14
U2 18
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0747-5632
EI 1873-7692
J9 COMPUT HUM BEHAV
JI Comput. Hum. Behav.
PD SEP
PY 2018
VL 86
BP 401
EP 411
DI 10.1016/j.chb.2018.05.014
PG 11
WC Psychology, Multidisciplinary; Psychology, Experimental
SC Psychology
GA GM3AN
UT WOS:000437968500039
DA 2019-03-21
ER

PT J
AU Barcaro, R
   Mazzoleni, M
   Virgili, P
AF Barcaro, Rosangela
   Mazzoleni, Martina
   Virgili, Paolo
TI Ethics of Care and Robot Caregivers
SO PROLEGOMENA
LA English
DT Review
DE Artificial intelligence; bioethics; chronically ill patients; elderly
   people; healthcare ethics; human caregivers; robot caregivers
ID FUTURE
AB Recently there has been a surge of interest in artificial intelligence (A.I.) and its possible developments and applications. Some of them are related to healthcare devices and medical equipment, that can assist physicians in improving their diagnostic skills. Others are conceived to be used in a particular branch of robotics. Until recently, human beings have been applying technological instruments and devices in what we could define as a "passive" aid mode: artefacts being used by human subjects to affect other humans. Recent development of a specific kind of robot designed to take care of chronically ill patients and/or elderly people are challenging previous ideas of caregiving, since these new technological devices can be designed to act autonomously. This development opens an entirely new area of bioethical analysis and the possibility of a transition to a post-human dimension of caregiving. This transition might impact directly the meaning of caring for aging humans and chronically ill patients. This paper will explore new ways of caring for human beings using robotic caregivers in light of ethical problems/questions of respect for human dignity and the feelings of vulnerable people - particularly the elderly - and conclude with a sketch of a proposal concerning their appropriate use in the future of healthcare.
C1 [Barcaro, Rosangela; Mazzoleni, Martina] CNR, Genoa, Italy.
   [Barcaro, Rosangela] Alma Mater Europaea, Humanities, Maribor, Slovenia.
   [Mazzoleni, Martina] CAI, Turin, Italy.
RP Barcaro, R (reprint author), CNR, Genoa, Italy.; Barcaro, R (reprint author), Alma Mater Europaea, Humanities, Maribor, Slovenia.
EM rosangela.barcaro@cnr.it
CR Barnes M, 2015, ETHICS OF CARE: CRITICAL ADVANCES IN INTERNATIONAL PERSPECTIVE, P1, DOI 10.1332/policypress/9781447316510.001.0001
   Bedaf S, 2014, DISABIL REHABIL-ASSI, V9, P445, DOI 10.3109/17483107.2013.840861
   Coeckelbergh M, 2016, AI SOC, V31, P455, DOI 10.1007/s00146-015-0626-3
   Collins S, 2015, CORE OF CARE ETHICS, P1, DOI 10.1057/9781137011459
   de Sio FS, 2016, SCI ENG ETHICS, V22, P1745, DOI 10.1007/s11948-015-9715-4
   Grigoryeva A, 2017, AM SOCIOL REV, V82, P116, DOI 10.1177/0003122416686521
   Held V., 2006, ETHICS CARE PERSONAL
   Kanda T, 2013, HUMAN-ROBOT INTERACTION IN SOCIAL ROBOTICS, P1
   Noddings N., 1984, CARING FEMININE APPR
   Nussbaum M., 2006, FRONTIERS JUSTICE DI
   Saunder-Staudt M, 2017, INTERNET ENCY PHILOS
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   Sorell T, 2014, ETHICS INF TECHNOL, V16, P183, DOI 10.1007/s10676-014-9344-7
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Tong R, 2016, STANFORD ENCY PHILOS
   Turkle S., 2011, ALONE TOGETHER WHY W
NR 16
TC 0
Z9 0
U1 3
U2 3
PU SOC ADVANCEMENT PHILOSOPHY-ZAGREB
PI ZAGREB
PA UNIV ZAGREB-CROATIAN STUDIES, BORONGAJ CAMPUS, BORONGAJSKA CESTA 83D,
   ZAGREB, HR-10000, CROATIA
SN 1333-4395
J9 PROLEGOMENA
JI Prolegomena
PD JUN
PY 2018
VL 17
IS 1
BP 71
EP 80
DI 10.26362/20180204
PG 10
WC Philosophy
SC Philosophy
GA HE3LG
UT WOS:000453256800004
DA 2019-03-21
ER

PT J
AU Andelic, A
AF Andelic, Antea
TI Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence
SO PROLEGOMENA
LA English
DT Book Review
C1 [Andelic, Antea] Ctr Croatian Studies, Borongajska Cesta 83d, Zagreb 10000, Croatia.
RP Andelic, A (reprint author), Ctr Croatian Studies, Borongajska Cesta 83d, Zagreb 10000, Croatia.
EM antea.andelic@gmail.com
CR LIN P, 2017, ROBOT ETHICS 2 0 AUT
NR 1
TC 0
Z9 0
U1 1
U2 1
PU SOC ADVANCEMENT PHILOSOPHY-ZAGREB
PI ZAGREB
PA UNIV ZAGREB-CROATIAN STUDIES, BORONGAJ CAMPUS, BORONGAJSKA CESTA 83D,
   ZAGREB, HR-10000, CROATIA
SN 1333-4395
J9 PROLEGOMENA
JI Prolegomena
PD JUN
PY 2018
VL 17
IS 1
BP 110
EP 114
PG 5
WC Philosophy
SC Philosophy
GA HE3LG
UT WOS:000453256800008
DA 2019-03-21
ER

PT J
AU Waldheuser, A
AF Waldheuser, Andre
TI Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence
SO ETHICAL THEORY AND MORAL PRACTICE
LA English
DT Book Review
C1 [Waldheuser, Andre] Univ Duisburg Essen, Inst Philosophie, Fak Geisteswissensch, Univ Str 12, D-45141 Essen, Germany.
RP Waldheuser, A (reprint author), Univ Duisburg Essen, Inst Philosophie, Fak Geisteswissensch, Univ Str 12, D-45141 Essen, Germany.
CR LIN P, 2017, ROBOT ETHICS 20 AUTO
NR 1
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1386-2820
EI 1572-8447
J9 ETHICAL THEORY MORAL
JI Ethical Theory Moral Pract.
PD JUN
PY 2018
VL 21
IS 3
BP 751
EP 753
DI 10.1007/s10677-018-9909-3
PG 3
WC Philosophy
SC Philosophy
GA GZ3YX
UT WOS:000449326400023
DA 2019-03-21
ER

PT J
AU Coeckelbergh, M
AF Coeckelbergh, Mark
TI Why Care About Robots? Empathy, Moral Standing, and the Language of
   Suffering
SO KAIROS-JOURNAL OF PHILOSOPHY & SCIENCE
LA English
DT Article
DE moral standing; robots; empathy; relations; language; art;
   phenomenology; hermeneutics; Wittgenstein
AB This paper tries to understand the phenomenon that humans are able to empathize with robots and the intuition that there might be something wrong with "abusing" robots by discussing the question regarding the moral standing of robots. After a review of some relevant work in empirical psychology and a discussion of the ethics of empathizing with robots, a philosophical argument concerning the moral standing of robots is made that questions distant and uncritical moral reasoning about entities' properties and that recommends first trying to understand the issue by means of philosophical and artistic work that shows how ethics is always relational and historical, and that highlights the importance of language and appearance in moral reasoning and moral psychology. It is concluded that attention to relationality and to verbal and non-verbal languages of suffering is key to understand the phenomenon under investigation, and that in robot ethics we need less certainty and more caution and patience when it comes to thinking about moral standing.
C1 [Coeckelbergh, Mark] Univ Vienna, Vienna, Austria.
   [Coeckelbergh, Mark] De Montfort Univ, Leicester, Leics, England.
RP Coeckelbergh, M (reprint author), Univ Vienna, Vienna, Austria.; Coeckelbergh, M (reprint author), De Montfort Univ, Leicester, Leics, England.
EM mark.coeckelbergh@univie.ac.at
CR Bryson J., 2010, CLOSE ENGAGEMENTS AR, P63
   Coeckelbergh M, 2012, GROWING MORAL RELATIONS: CRITIQUE OF MORAL STATUS ASCRIPTION, P1, DOI 10.1057/9781137025968
   Coeckelbergh M., 2014, PHILOS TECHNOLOGY, V27, P61, DOI [10.1007/s13347-013-0133-8, DOI 10.1007/S13347-013-0133-8]
   Coeckelbergh M., 2011, PHILOS TECHNOLOGY, V24, P269
   Coeckelbergh M., 2017, USING WORDS THINGS L
   Coeckelbergh M, 2014, J AGR ENVIRON ETHIC, V27, P715, DOI 10.1007/s10806-013-9486-3
   Coeckelbergh M, 2011, AI SOC, V26, P61, DOI 10.1007/s00146-010-0289-z
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P209, DOI 10.1007/s10676-010-9235-5
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P235, DOI 10.1007/s10676-010-9221-y
   Darling Kate, 2012, IEEE SPECTRUM
   Darling Kate, 2017, ROBOT ETHICS S 2 0
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   Gunkel DJ, 2018, ETHICS INF TECHNOL, V20, P87, DOI 10.1007/s10676-017-9442-4
   Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5
   Kant Immanuel, 2012, LECT ANTHR
   Kant Immanuel, 1997, LECT ETHICS
   Rosenthal-von der Putten AM, 2013, INT J SOC ROBOT, V5, P17, DOI 10.1007/s12369-012-0173-8
   Searle J., 1995, CONSTRUCTION SOCIAL
   Suzuki, 2015, NATURE SCI REPORTS
   Whitby Blay, 2008, INTERACTING COMPUTER, V20, P338
   WITTGENSTEIN L, 1953, PHILOS INVESTIGATION
NR 22
TC 0
Z9 0
U1 5
U2 5
PU DE GRUYTER POLAND SP ZOO
PI WARSAW
PA BOGUMILA ZUGA 32A STR., 01-811 WARSAW, POLAND
SN 1647-659X
EI 2182-2824
J9 KAIROS
JI Kairos
PD JUN
PY 2018
VL 20
IS 1
BP 141
EP 158
DI 10.2478/kjps-2018-0007
PG 18
WC Philosophy
SC Philosophy
GA GR2NL
UT WOS:000442412200007
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Boyles, RJM
AF Boyles, Robert James M.
TI A Case for Machine Ethics in Modeling Human-Level Intelligent Agents
SO KRITIKE-AN ONLINE JOURNAL OF PHILOSOPHY
LA English
DT Article
DE machine ethics; artificial moral agents; technological singularity;
   philosophy of artificial intelligence
AB This paper focuses on the research field of machine ethics and how it relates to a technological singularity-a hypothesized, futuristic event where artificial machines will have greater-than-human-level intelligence. One problem related to the singularity centers on the issue of whether human values and norms would survive such an event. To somehow ensure this, a number of artificial intelligence researchers have opted to focus on the development of artificial moral agents, which refers to machines capable of moral reasoning, judgment, and decision-making. To date, different frameworks on how to arrive at these agents have been put forward. However, there seems to be no hard consensus as to which framework would likely yield a positive result. With the body of work that they have contributed in the study of moral agency, philosophers may contribute to the growing literature on artificial moral agency. While doing so, they could also think about how the said concept could affect other important philosophical concepts.
C1 [Boyles, Robert James M.] De La Salle Univ, Dept Philosophy, Manila, Philippines.
RP Boyles, RJM (reprint author), De La Salle Univ, Dept Philosophy, Manila, Philippines.
CR Anderson M., 2011, MACHINE ETHICS
   Aquinas Thomas, 1952, SUMMA THEOLOGICA
   Capek Karel, 2016, R U R
   CARTER MATT, 2007, MINDS COMPUTERS INTR
   Chalmers DJ, 2010, J CONSCIOUSNESS STUD, V17, P7
   Counet Jean-Michael, 2005, MATH DIVINE HIST STU
   Denis Lara, 2012, STANFORD ENCY PHILOS
   Denise Theodore C., 2008, GREAT TRADITIONS ETH
   Eshleman Andrew, 2014, STANFORD ENCY PHILOS
   Garrett Brian, 1998, PERSONAL IDENTITY SE
   Goertzel B, 2007, ARTIF INTELL, V171, P1161, DOI 10.1016/j.artint.2007.10.011
   Good Irving John, 1966, ADV COMPUTERS, V6
   Graesser Art, 1996, P 3 INT WORKSH AG TH
   Greene B., 1999, ELEGANT UNIVERSE SUP
   Hawking S., 1988, BRIEF HIST TIME
   Himma Kenneth Eimar, 2009, ETHICS INFORM TECHNO, V11
   Joaquin J. Joven, 2017, ORGANON F, V24, P2
   Kant I., 1785, GROUNDWORK METAPHYSI, P2002
   Kurzweil R., 2005, SINGULARITY IS NEAR
   Loosemore Richard, 2011, HUMANITY MAGAZI 0307
   Mabaquiao Napoleon, 2012, MIND SCI COMPUTATION
   MCINERNY R, 1987, J MED ETHICS, V13, P31, DOI 10.1136/jme.13.1.31
   Moor James H., 2011, MACHINE ETHICS
   Moravec Hans P., 2002, UNDERSTANDING ARTIFI
   Moser Walter, 1993, SUBSTANCE, V22
   Muehlhauser Luke, 2014, THINK, V36, P13
   Nadeau Joseph Emile, 2006, THINKING ANDROID EPI
   Paipetis SA, 2010, HIST MECH MACH SCI, V9, P1, DOI 10.1007/978-90-481-2514-2
   Penrose Roger, 1991, WORLD TREASURY PHYS
   Pfeifer R, 1999, UNDERSTANDING INTELL
   Shanahan Murray, 2009, STANFORD ENCY PHILOS
   Sullins John, 2009, HDB RES TECHNOETHICS
   Vinge Vernon, 1993, VISION 21 INTERDISCI
   Wallach W., 2009, MORAL MACHINES TEACH
   WITTGENSTEIN L, 1953, PHILOS INVESTIGATION
NR 35
TC 0
Z9 0
U1 16
U2 16
PU UNIV SANTO TOMAS, FAC ARTS & LETTERS
PI MANILA
PA RM 109, MAIN BLDG, ESPANA, MANILA, 1015, PHILIPPINES
SN 1908-7330
J9 KRITIKE
JI Kritike
PD JUN
PY 2018
VL 12
IS 1
BP 182
EP 200
DI 10.25138/12.1.a9
PG 19
WC Philosophy
SC Philosophy
GA GL4RX
UT WOS:000437145100009
OA DOAJ Gold, Green Published
DA 2019-03-21
ER

PT J
AU Calvo, RA
   Peters, D
AF Calvo, Rafael A.
   Peters, Dorian
TI Ethics review for AI surveillance studies
SO NATURE
LA English
DT Letter
C1 [Calvo, Rafael A.; Peters, Dorian] Univ Sydney, Sydney, NSW, Australia.
RP Calvo, RA (reprint author), Univ Sydney, Sydney, NSW, Australia.
EM rafael.calvo@sydney.edu.au
OI Peters, Dorian/0000-0002-4767-4198
NR 0
TC 0
Z9 0
U1 10
U2 27
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 0028-0836
EI 1476-4687
J9 NATURE
JI Nature
PD MAY 3
PY 2018
VL 557
IS 7703
BP 31
EP 31
PG 1
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GE5BW
UT WOS:000431234500016
PM 29713067
DA 2019-03-21
ER

PT J
AU Jones, ML
   Kaufman, E
   Edenberg, E
AF Jones, Meg Leta
   Kaufman, Ellen
   Edenberg, Elizabeth
TI AI and the Ethics of Automating Consent
SO IEEE SECURITY & PRIVACY
LA English
DT Article
ID PRIVACY SELF-MANAGEMENT
AB While supplementing consent with further mechanization, digitization, and intelligence-either through proffering notification on behalf of a consentee or choosing and communicating consent by the consenter-may improve take-it-or-leave-it notice and choice consent regimes, the goal for AI consent should be one of partnership development between parties, built on responsive design and continual consent.
C1 [Jones, Meg Leta] Georgetown Univ, Commun Culture & Technol Dept, Washington, DC 20057 USA.
   [Kaufman, Ellen] Georgetown Univ, Commun Culture & Technol Program, Washington, DC 20057 USA.
   [Edenberg, Elizabeth] Georgetown Univ, Kennedy Inst Eth, Eth Lab, Washington, DC 20057 USA.
RP Jones, ML (reprint author), Georgetown Univ, Commun Culture & Technol Dept, Washington, DC 20057 USA.
EM ma1318@georgetown.edu; ek792@georgetown.edu;
   elizabeth.edenberg@georgetown.edu
FU Georgetown University
FX The authors gratefully acknowledge Georgetown University for its support
   of this project, part of the Digital Consent Project, through the
   Complex Moral Problem grant, as well as the Kennedy Institute of Ethics
   for further intellectual and logistical support.
CR Barocas S, 2014, COMMUN ACM, V57, P31, DOI 10.1145/2668897
   Calo MR, 2012, NOTRE DAME LAW REV, V87, P1027
   Cranor Lorrie Faith, 2012, J TELECOMMUNICATIONS, V10, P273
   Gomer R., P ACM INT JOINT C PE, P653
   Liu B, 2016, 12 S US PRIV SEC SOU, P27
   Miller F, 2010, ETHICS CONSENT THEOR
   Naeini P.E., 2017, 13 S US PRIV SEC SOU, P399
   Norval C, 2017, P WSDM 2017 WORKSH M
   Orekondy T., 2017, P INT C COMP VIS ICC, P1
   Pappachan P, 2017, IEEE INT CON DIS, P193, DOI 10.1109/ICDCSW.2017.52
   Pascalev M, 2017, ETHICS INF TECHNOL, V19, P39, DOI 10.1007/s10676-016-9410-4
   Schaub F, 2015, 11 S US PRIV SEC SOU, P1
   Schermer BW, 2014, ETHICS INF TECHNOL, V16, P171, DOI 10.1007/s10676-014-9343-8
   Solove DJ, 2013, HARVARD LAW REV, V126, P1880
   Wijesekera P, 2017, P IEEE S SECUR PRIV, P1077, DOI 10.1109/SP.2017.51
   Zimmeck S., 2017, P NETW DISTR SYST SE, P1
NR 16
TC 0
Z9 0
U1 18
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1540-7993
EI 1558-4046
J9 IEEE SECUR PRIV
JI IEEE Secur. Priv.
PD MAY-JUN
PY 2018
VL 16
IS 3
BP 64
EP 72
DI 10.1109/MSP.2018.2701155
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
SC Computer Science
GA GK8HL
UT WOS:000436460400011
DA 2019-03-21
ER

PT J
AU Kose, U
AF Kose, Utku
TI Are We Safe Enough in the Future of Artificial Intelligence? A
   Discussion on Machine Ethics and Artificial Intelligence Safety
SO BRAIN-BROAD RESEARCH IN ARTIFICIAL INTELLIGENCE AND NEUROSCIENCE
LA English
DT Article
DE artificial intelligence; machine learning; machine ethics; artificial
   intelligence safety; future of artificial intelligence
ID MORALITY
AB Nowadays, there is a serious anxiety on the existence of dangerous intelligent systems and it is not just a science-fiction idea of evil machines like the ones in well-known Terminator movie or any other movies including intelligent robots - machines threatening the existence of humankind. So, there is a great interest in some alternative research works under the topics of Machine Ethics, Artificial Intelligence Safety and the associated research topics like Future of Artificial Intelligence and Existential Risks. The objective of this study is to provide a general discussion about the expressed research topics and try to find some answers to the question of 'Are we safe enough in the future of Artificial Intelligence?'. In detail, the discussion includes a comprehensive focus on 'dystopic' scenarios, enables interested researchers to think about some 'moral dilemmas' and finally have some ethical outputs that are considerable for developing good intelligent systems. From a general perspective, the discussion taken here is a good opportunity to improve awareness on the mentioned, remarkable research topics associated with not only Artificial Intelligence but also many other natural and social sciences taking role in the humankind.
C1 [Kose, Utku] Suleyman Demirel Univ, Merkez Isparta, Turkey.
RP Kose, U (reprint author), Suleyman Demirel Univ, Merkez Isparta, Turkey.
EM utkukose@sdu.edu.tr
CR Abbeel Pieter, 2011, ENCY MACHINE LEARNIN, P554
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83
   Amodei  D., 2016, ARXIV160606565
   Anderson M., 2011, MACHINE ETHICS
   Anderson M, 2007, AI MAG, V28, P15
   Arnold T., 2017, 3 INT WORKSH AI ETH
   Bostrom N, 2002, J EVOLUTION TECHNOLO, V9, P1
   Bostrom N., 2014, SUPERINTELLIGENCE PA
   Bostrom Nick, 2003, SCI FICTION PHILOS T, P277
   Callaghan V, 2017, FRONT COLLECT, P1, DOI 10.1007/978-3-662-54033-6
   Conitzer V., 2017, AAAI, P4831
   Dewey D., 2014, AAAI SPRING SERIES
   Dubhashi D, 2017, COMMUN ACM, V60, P43, DOI 10.1145/2953876
   Evans O., 2015, NIPS WORKSH BOUND OP, V6
   Evans O., 2016, AAAI, P323
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   Goodfellow I., 2017, ATTACKING MACHINE LE
   Herzfeld N., 2002, OUR IMAGE ARTIFICIAL
   Hibbard B., 2014, ARXIV14111373
   Holland O., 2003, MACHINE CONSCIOUSNES
   Kose U., 2017, ART INT DAT PROC S I, P1
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Lin X, 2017, IEEE INT CONF HIGH
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67
   MIT Technology Review, 2014, DO WE NEED AS LAWS
   Moor J.H., 2009, PHILOS NOW, V17, P12
   Muehlhauser L., 2012, SINGULARITY HYPOSTHE, P101
   Negnevitsky M, 2005, ARTIFICIAL INTELLIGE
   Ng A., 2000, P 17 INT C MACH LEAR, P663, DOI DOI 10.2460/AJVR.67.2.323
   Nicolescu B., 2017, TRANSDISCIPLINARY HI, P155
   Orseau Laurent, 2016, UNC ART INT 32 C UAI, P557
   Pavaloiu A., 2017, J MULTIDISCIPLINARY, V2, P15
   Perdue RT, 2017, SOC NATUR RESOUR, V30, P1026, DOI 10.1080/08941920.2016.1264652
   Powers TM, 2011, IEEE ROBOT AUTOM MAG, V18, P51, DOI [10.1109/MRA.2011.940275, 10.1109/MRA.2010.940152]
   Riedl M. O., 2016, AAAI WORKSH AI ETH S
   Russell S.J., 2003, ARTIFICIAL INTELLIGE, V2
   Russell S, 2015, AI MAG, V36, P105, DOI 10.1609/aimag.v36i4.2577
   Schneider Susan, 2016, SCI FICTION PHILOS T
   Soares N., 2015, WORKSH 29 AAAI C ART
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8
   Vamplew P., 2017, ETHICS INF TECHNOL, P1
   Wallach W., 2008, MORAL MACHINES TEACH
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8
   Yampolskiy R. V., 2013, PHILOS THEORY ARTIFI, P389
NR 45
TC 0
Z9 0
U1 20
U2 28
PU EDUSOFT PUBLISHING
PI BACAU
PA 9 MAI STR 82, BACAU, 600065, ROMANIA
SN 2067-3957
J9 BRAIN-BROAD RES ARTI
JI BRAIN-Broad Res. Artif. Intellect. Neurosci.
PD MAY
PY 2018
VL 9
IS 2
BP 184
EP 197
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA GJ5CF
UT WOS:000435398100016
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU [Anonymous]
AF [Anonymous]
TI European Commission to set up ethics committee on artificial
   intelligence
SO MRS BULLETIN
LA English
DT News Item
NR 0
TC 0
Z9 0
U1 4
U2 8
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0883-7694
EI 1938-1425
J9 MRS BULL
JI MRS Bull.
PD MAY
PY 2018
VL 43
IS 5
BP 326
EP 326
DI 10.1557/mrs.2018.107
PG 1
WC Materials Science, Multidisciplinary; Physics, Applied
SC Materials Science; Physics
GA GF7WH
UT WOS:000432178500009
OA Bronze
DA 2019-03-21
ER

PT J
AU Tavani, HT
AF Tavani, Herman T.
TI Can Social Robots Qualify for Moral Consideration? Reframing the
   Question about Robot Rights
SO INFORMATION
LA English
DT Article
DE robot ethics; robot rights; social robots; moral agents; moral
   consideration; moral patients; Hans Jonas
ID ETHICS
AB A controversial question that has been hotly debated in the emerging field of robot ethics is whether robots should be granted rights. Yet, a review of the recent literature in that field suggests that this seemingly straightforward question is far from clear and unambiguous. For example, those who favor granting rights to robots have not always been clear as to which kinds of robots should (or should not) be eligible; nor have they been consistent with regard to which kinds of rights-civil, legal, moral, etc.-should be granted to qualifying robots. Also, there has been considerable disagreement about which essential criterion, or cluster of criteria, a robot would need to satisfy to be eligible for rights, and there is ongoing disagreement as to whether a robot must satisfy the conditions for (moral) agency to qualify either for rights or (at least some level of) moral consideration. One aim of this paper is to show how the current debate about whether to grant rights to robots would benefit from an analysis and clarification of some key concepts and assumptions underlying that question. My principal objective, however, is to show why we should reframe that question by asking instead whether some kinds of social robots qualify for moral consideration as moral patients. In arguing that the answer to this question is "yes," I draw from some insights in the writings of Hans Jonas to defend my position.
C1 [Tavani, Herman T.] Rivier Univ, Dept Philosophy, Nashua, NH 03060 USA.
RP Tavani, HT (reprint author), Rivier Univ, Dept Philosophy, Nashua, NH 03060 USA.
EM htavani@rivier.edu
CR Anderson M., 2011, MACHINE ETHICS, P1
   Bekey GA, 2012, INTELL ROBOT AUTON, P17
   Blay Michel, 2009, ETHICS AND ROBOTICS, pV
   Breazeal C. L., 2002, DESIGNING SOCIABLE R
   Buechner J, 2015, EVOLUTIONARY ROBOTIC, P39
   Buechner J, 2011, ETHICS INF TECHNOL, V13, P39, DOI 10.1007/s10676-010-9249-z
   Carr L., 2018, WHAT GROUNDS MIGHT W
   Coeckelbergh M, 2012, GROWING MORAL RELATIONS: CRITIQUE OF MORAL STATUS ASCRIPTION, P1, DOI 10.1057/9781137025968
   Coeckelbergh M, 2012, ETHICS INF TECHNOL, V14, P53, DOI 10.1007/s10676-011-9279-1
   Coeckelbergh M, 2009, AI SOC, V24, P181, DOI 10.1007/s00146-009-0208-3
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P209, DOI 10.1007/s10676-010-9235-5
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P235, DOI 10.1007/s10676-010-9221-y
   Darling K, 2016, ROBOT LAW, P213, DOI DOI 10.4337/9781783476732.00017
   Darling K., 2012, EXTENDING LEGAL PROT
   De Laat P. B., 2016, ACM SIGCAS COMPUT SO, V45, P255
   Decker M., 2012, ROBO INFORM ETHICS S, P3
   Dennett DC, 1987, INTENTIONAL STANCE
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   Floridi L., 2001, Ethics and Information Technology, V3, P55, DOI 10.1023/A:1011440125207
   Floridi L., 2002, Ethics and Information Technology, V4, P287, DOI 10.1023/A:1021342422699
   Floridi L., 1999, Ethics and Information Technology, V1, P37
   Floridi L, 2008, HDB INFORM COMPUTER, P3
   Floridi Luciano, 2013, ETHICS INFORM
   Gerdes A., 2015, SIGCAS COMPUTERS SOC, V45, P274, DOI DOI 10.1145/2874239.2874278
   Grodzinsky FS, 2011, ETHICS INF TECHNOL, V13, P17, DOI 10.1007/s10676-010-9255-1
   Grodzinsky F.S, 2018, ROUTLEDGE HDB TRUST
   Gunkel D. J., 2007, THINKING OTHERWISE
   Gunkel D.J., 2017, ETHICS INF TECHNOL, V19, P1, DOI 10.1007/s10676-017-9442-4
   Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
   Himma KE, 2009, ETHICS INF TECHNOL, V11, P19, DOI 10.1007/s10676-008-9167-5
   Hogan K, 2017, ETHICS INF TECHNOL, V19, P29, DOI 10.1007/s10676-017-9418-4
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5
   Jonas H., 1984, IMPERATIVE RESPONSIB
   Jonas H, 2008, MEMOIRS
   Kant Immanuel, 1991, METAPHYSICS MORALS, P462
   LaGrandeur K, 2015, ARTIF INTELL, P97
   Laukyte M, 2017, ETHICS INF TECHNOL, V19, P1, DOI 10.1007/s10676-016-9411-3
   Levinas E., 1969, TOTALITY INFINITY ES
   Levy D, 2009, INT J SOC ROBOT, V1, P209, DOI 10.1007/s12369-009-0022-6
   Lin P, 2012, INTELL ROBOT AUTON, P3
   Michelfelder D. P., 2000, Ethics and Information Technology, V2, P147, DOI 10.1023/A:1010049320893
   Moor J.H., 2009, PHILOS NOW, V17, P12
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80
   Munthe C, 2018, ARTIFICIAL MORAL AGE
   Power T, 2003, TOPOI, V32, P227
   Scheutz M, 2012, INTELL ROBOT AUTON, P205
   Sparrow R, 2011, MACHINE ETHICS, P301
   Sullins J. P., 2011, MACHINE ETHICS, P151
   Taddeo M, 2010, MIND MACH, V20, P243, DOI 10.1007/s11023-010-9201-3
   Taddeo M, 2009, INT J TECHNOL HUM IN, V5, P23, DOI 10.4018/jthi.2009040102
   Tavani H. T., 2015, PHILOS TECHNOL, V28, P75
   Tavani H. T., 2011, MIND MACH, V21, P465
   Tavani H. T, 2005, IMPACT INTERNET OUR, P215
   Tavani H. T., 2012, ROBO INFORM ETHICS S, P89
   Tavani H.T., 2016, ETHICS TECHNOLOGY CO
   Turkle S, 2011, MACHINE ETHICS, P62
   Turkle S., 2011, ALONE TOGETHER WHY W
   Veruggio G, 2012, INTELL ROBOT AUTON, P347
   Wallach W., 2009, MORAL MACHINES TEACH
   Wootson CR, 2017, WASHINGTON POST
NR 60
TC 1
Z9 1
U1 5
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2078-2489
J9 INFORMATION
JI Information
PD APR
PY 2018
VL 9
IS 4
AR 73
DI 10.3390/info9040073
PG 16
WC Computer Science, Information Systems
SC Computer Science
GA GK4QV
UT WOS:000436149200005
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Hauer, T
AF Hauer, Tomas
TI Society and the Second Age of Machines: Algorithms Versus Ethics
SO SOCIETY
LA English
DT Editorial Material
DE Second machine age; Artificial intelligence; Machine ethics; Computer
   functionalism; Moral dilemmas; Ethical problemin robotics
AB The term "Second Machine Age" was used by Erik Brynjolfsson and Andrew McAfee in their book of the same name as an indication of the impact of AI technology on people, society, and the economy. The term seeks to analyse the age we actually live in, its hidden patterns, which jobs and fields of study have a perspective, and which do not. It is about the second industrial revolution that is going on right now, and it changes the world no less radically than the first one, driven by the steam locomotive. Exponential growth of digital technologies, digitization of everything and recombinant innovation is a driving engine and fuel of the Second Machine Age. However, the ethical issues of this change remain unaddressed. Artificial intelligence is currently being dealt with by a great many scientists and philosophers who ask many questions. The most important questions are whether the machines can think, whether we will give them the copyright, which the animals do not have until now, and the question whether AI can has its own ethics. The study focuses on these issues, and uses concrete examples to show our unpreparedness for these topics.
C1 [Hauer, Tomas] VSB Tech Univ Ostrava, Dept Social Sci, 17 November 15-2172, Ostrava, Czech Republic.
RP Hauer, T (reprint author), VSB Tech Univ Ostrava, Dept Social Sci, 17 November 15-2172, Ostrava, Czech Republic.
EM tomas.hauer@vsb.cz
CR Anderson M., 2011, MACHINE ETHICS
   Asimov I., 2008, I ROBOT
   Boddington P., 2017, ARTIFICIAL INTELLIGE
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654
   Brynjolfsson E., 2016, 2 MACHINE AGE WORK P
   CARTER MATT, 2007, MINDS COMPUTERS INTR
   Dreyfus H. L, 1992, WHAT COMPUTERS STILL
   Erbas MD, 2015, ARTIF LIFE, V21, P141, DOI 10.1162/ARTL_a_00164
   Finn E., 2017, WHAT ALGORITHMS WANT
   Kurzweil R., 2005, SINGULARITY IS NEAR
   Li  D., 2007, ARTIFICIAL INTELLIGE
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Minsky M., 1988, SOC OF MIND
   Oliveira A., 2017, DIGITAL MIND SCI IS
   Penrose R., 1996, SHADOWS MIND SEARCH
   Wallach W., 2009, MORAL MACHINES TEACH
   Warwick K., 2011, ARTIFICIAL INTELLIGE
NR 17
TC 1
Z9 1
U1 17
U2 52
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0147-2011
EI 1936-4725
J9 SOCIETY
JI Society
PD APR
PY 2018
VL 55
IS 2
BP 100
EP 106
DI 10.1007/s12115-018-0221-6
PG 7
WC Social Sciences, Interdisciplinary; Sociology
SC Social Sciences - Other Topics; Sociology
GA GC2AE
UT WOS:000429583600001
DA 2019-03-21
ER

PT J
AU Hossain, SQ
AF Hossain, Soaad Q.
TI Ethical and moral concerns regarding artificial intelligence in law and
   medicine
SO UNIVERSITY OF TORONTO JOURNAL OF UNDERGRADUATE LIFE SCIENCES
LA English
DT News Item
C1 [Hossain, Soaad Q.] Univ Toronto, Toronto, ON, Canada.
RP Hossain, SQ (reprint author), Univ Toronto, Toronto, ON, Canada.
NR 0
TC 0
Z9 0
U1 3
U2 3
PU UNIV TORONTO JOURNAL UNDERGRADUATE LIFE SCIENCES
PI TORONTO
PA 1 KINGS COLLEGE CIRCLE, MS5207, TORONTO, ON M5S 1A8, CANADA
SN 1911-8899
J9 UNIV TOR J UNDERGRAD
JI Univ. Tor. Undergrad. Life Sci.
PD SPR
PY 2018
VL 12
IS 1
BP 10
EP 10
PG 1
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA GN6EN
UT WOS:000439168000004
DA 2019-03-21
ER

PT J
AU Amigoni, F
   Schiaffonati, V
AF Amigoni, Francesco
   Schiaffonati, Viola
TI Ethics for Robots as Experimental Technologies Pairing Anticipation with
   Exploration to Evaluate the Social Impact of Robotics
SO IEEE ROBOTICS & AUTOMATION MAGAZINE
LA English
DT Article
C1 [Amigoni, Francesco; Schiaffonati, Viola] Politecn Milan, Artificial Intelligence & Robot Lab, Milan, Italy.
RP Amigoni, F (reprint author), Politecn Milan, Artificial Intelligence & Robot Lab, Milan, Italy.
EM francesco.amigoni@polimi.it; viola.schiaffonati@polimi.it
OI Amigoni, Francesco/0000-0001-8146-6213
CR Ackerman E., 2015, IEEE SPECTR
   Amigoni F, 2016, STUD APPL PHILOS, V27, P585, DOI 10.1007/978-3-319-38983-7_33
   [Anonymous], 2017, IEEE GLOB IN ETH AUT
   Asaro PM, 2006, INT REV INF ETHICS, V6, P9
   Atkeson C., 2016, WHAT HAPPENED DARPA
   Collingridge D, 1980, SOCIAL CONTROL TECHN
   Crawford K, 2016, NATURE, V538, P311, DOI 10.1038/538311a
   DRC-Teams, 2015, WHAT HAPP DARPA ROB
   European Parliament, 2017, EUR PARL RES 16 FEBR
   Executive Office of the President of the United States, 2016, PREP FUT ART INT
   Guizzo E., 2011, IEEE SPECTR
   KROHN W, 1987, SCI TECHNOL HUM VAL, V12, P52, DOI 10.1177/016224398701200206
   Lin P., 2008, ETHICAL SOCIAL IMPLI
   LINDBLOM CE, 1959, PUBLIC ADMIN REV, V19, P79, DOI 10.2307/973677
   Madhavan R., 2016, UNDERSTANDING SOC IM
   van de Poel I, 2016, SCI ENG ETHICS, V22, P667, DOI 10.1007/s11948-015-9724-3
   van Wynsberghe A, 2016, ETHICS INF TECHNOL, V18, P311, DOI 10.1007/s10676-016-9409-x
   Veruggio G., 2008, SPRINGER HDB ROBOTIC, P1499
   Wallach W., 2008, MORAL MACHINES TEACH
   2009, RESCUE ROBOTICS, P1
NR 20
TC 1
Z9 1
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1070-9932
EI 1558-223X
J9 IEEE ROBOT AUTOM MAG
JI IEEE Robot. Autom. Mag.
PD MAR
PY 2018
VL 25
IS 1
BP 30
EP 36
DI 10.1109/MRA.2017.2781543
PG 7
WC Automation & Control Systems; Robotics
SC Automation & Control Systems; Robotics
GA FZ2QW
UT WOS:000427426900008
DA 2019-03-21
ER

PT J
AU Dignum, V
AF Dignum, Virginia
TI Ethics in artificial intelligence: introduction to the special issue
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Editorial Material
C1 [Dignum, Virginia] Delft Univ Technol, Delft Design Values Inst, Jaffalaan 5, NL-2628 BX Delft, Netherlands.
RP Dignum, V (reprint author), Delft Univ Technol, Delft Design Values Inst, Jaffalaan 5, NL-2628 BX Delft, Netherlands.
EM m.v.dignum@tudelft.nl
OI Dignum, Virginia/0000-0001-7409-5813
CR Dignum Virginia, 2017, P 26 INT JOINT C ART, P4698
   Stone P., 2016, ARTIFICIAL INTELLIGE
   TURIEL E, 2002, CULTURE MORALITY SOC
NR 3
TC 4
Z9 4
U1 7
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD MAR
PY 2018
VL 20
IS 1
SI SI
BP 1
EP 3
DI 10.1007/s10676-018-9450-z
PG 3
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA FY3JT
UT WOS:000426716300001
OA Bronze
DA 2019-03-21
ER

PT J
AU Allinson, MD
   Black, P
AF Allinson, Maria Donna
   Black, Patricia
TI Students views of an online ethical decision-support tool
SO CURRENTS IN PHARMACY TEACHING AND LEARNING
LA English
DT Article
DE Values Exchange; Decision-support; Pharmacy education; Ethics
ID EDUCATION
AB Background and purpose: Ethical reasoning is a key skill that must be developed during the undergraduate pharmacy course to prepare students for ethical decision-making in future practice as pharmacy professionals. In this initial study, we sought and documented the views of pharmacy students at a United Kingdom (UK) university on the use of Values Exchange (TM) (Vx), an online ethical decision-support tool.
   Educational activity and setting: Students deliberated on up to three ethical case scenarios every academic year using the tool. A preliminary study using a qualitative methodology was conducted with students nearing the end of their third-year of study to explore their views of the tool. Two focus groups were used to collect the data. Discussions were digitally recorded, anonymised and transcribed verbatim. Data was analysed using the five-stage framework approach.
   Findings: Four main themes emerged from the data: students felt that Values Exchange (TM) enabled them to gain a wider perspective on ethical issues; it promoted reflection; it helped to prepare them for future practice; students liked the online environment.
   Discussion: Vx prompted students to deliberate on many facets of a case, enabled them to consider and challenge the views of their peers, facilitated reflection and promoted greater honesty in responses and inclusivity, all supporting the development of moral reasoning skills.
   Summary: Vx supports the process of ethical decision-making, encouraging a deep approach to learning within a safe virtual environment. Students believed Vx to be an effective tool for developing ethical reasoning skills in preparation for practice.
C1 [Allinson, Maria Donna; Black, Patricia] Keele Univ, Sch Pharm, Hornbeam Bldg, Keele ST5 5BG, Staffs, England.
RP Allinson, MD (reprint author), Keele Univ, Sch Pharm, Hornbeam Bldg, Keele ST5 5BG, Staffs, England.
EM m.d.allinson@keele.ac.uk; p.e.black@keele.ac.uk
CR Beauchamp T. L., 2009, PRINCIPLES BIOMEDICA
   Bertolami Charles N, 2004, J Dent Educ, V68, P414
   Biggs JB, 2011, TEACHING QUALITY LEA
   Boud D, 1985, REFLECTION TURNING E
   Brannick T, 2007, ORGAN RES METHODS, V10, P59, DOI 10.1177/1094428106289253
   Fish D, 1998, DEVELOPING PROFESSIO
   General Pharmaceutical Council, STAND PHARM PROF
   General Pharmaceutical Council, FUT PHARM STAND IN E
   Gillam L., 2012, COMPANION BIOETHICS, P584
   Godbold R, 2013, NURSE EDUC PRACT, V13, P553, DOI 10.1016/j.nepr.2013.02.012
   LATIF DA, 2009, INT J PHARM PRACT, V17, P359, DOI DOI 10.1211/ijpp/17.06.0007
   Lees A., 2012, NZ J PHYSIOTHERAPY, V40, P59
   Mitcham C., 2005, ENCY SCI TECHNOLOGY, P700
   Moon J., 1999, REFLECTION LEARNING
   Pope C, 2000, BMJ-BRIT MED J, V320, P114, DOI 10.1136/bmj.320.7227.114
   Robb G, 2012, MED TEACH, V34, pE743, DOI 10.3109/0142159X.2012.689439
   Royal Pharmaceutical Society, 2017, MED ETH PRACT PROF G
   Schon D. A., 1987, ED REFLECTIVE PRACTI
   Seedhouse D, 2009, ETHICS HEART HEALTHC
   The Quality Assurance Agency for Higher Education, PHARM SUBJ BENCHM ST
   van der Burg S, 2005, SCI ENG ETHICS, V11, P277, DOI 10.1007/s11948-005-0046-8
NR 21
TC 0
Z9 0
U1 1
U2 3
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 1877-1297
EI 1877-1300
J9 CURR PHARM TEACH LEA
JI Curr. Pharm. Teach. Learn.
PD FEB
PY 2018
VL 10
IS 2
BP 226
EP 230
DI 10.1016/j.cptl.2017.10.008
PG 5
WC Education, Scientific Disciplines
SC Education & Educational Research
GA GF1WD
UT WOS:000431725400018
PM 29706280
DA 2019-03-21
ER

PT J
AU Pardo, AMS
AF Seoane Pardo, Antonio Miguel
TI Computational Thinking Between Philosophy and STEM-Programming Decision
   Making Applied to the Behavior of "Moral Machines" in Ethical Values
   Classroom
SO IEEE REVISTA IBEROAMERICANA DE TECNOLOGIAS DEL APRENDIZAJE-IEEE RITA
LA English
DT Article
DE Computational thinking; decision making; game-based learning; ethics;
   logic; moral machines; self-driving car
ID DILEMMA; K-12
AB This paper describes a learning activity on computational thinking in ethics classroom with compulsory secondary school students (14-16 years old). It is based on the assumption that computational thinking (or better "logical thinking") is applicable not only to science, technology, engineering, and mathematics subjects but to any other field in education, and it is particularly suited for decision making in moral dilemmas. This will be carried out through the study of so called "moral machines,"using a game-based learning approach on self-driving vehicles and the need to program such cars to perform certain behavior's under extreme situations. Students will be asked to logically base their reasoning on different ethical approaches and try to develop a schema of decision making that could serve to program a machine to respond to those situations. Students will also have to deal with the uncertainty of reaching solutions that will be debatable and not universally accepted as a part of the difficulty, more ethical than technical, to provide machines with the ability to take decisions where there is no such thing as a "right" versus "wrong" answer, and potentially both (or more) of the possible actions will bring unwanted consequences.
C1 [Seoane Pardo, Antonio Miguel] Univ Salamanca, Area Res Methods & Diag Educ, E-37008 Salamanca, Spain.
   [Seoane Pardo, Antonio Miguel] Univ Salamanca, Res Grp InterAct & eLearning, E-37008 Salamanca, Spain.
RP Pardo, AMS (reprint author), Univ Salamanca, Area Res Methods & Diag Educ, E-37008 Salamanca, Spain.
EM anton.seoane@usal.es
OI Seoane Pardo, Antonio Miguel/0000-0001-8887-3954
FU EU Erasmus + Programme through KA2 Project "TACCLE 3-Coding"
   [2015-1-BE02-KA201-012307]; European Commission
FX This work was supported in part by the EU Erasmus + Programme through
   KA2 Project "TACCLE 3-Coding" under Grant 2015-1-BE02-KA201-012307 and
   in part by the European Commission.
CR Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4
   Anderson M, 2007, AI MAG, V28, P15
   [Anonymous], 2015, LEV SETT REC LEARN O
   [Anonymous], 2015, B OF EST, P6986
   Balanskat A., 2015, TECH REP
   Binkley M, 2012, ASSESSMENT AND TEACHING OF 21ST CENTURY SKILLS, P17, DOI 10.1007/978-94-007-2324-5_2
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654
   Bratman M. E., 1987, INTENTION PLANS PRAC
   Bund  A., 2007, J SCI PRACTICAL COMP, V1, P67
   Caprile M., 2015, IPAEMPL201413 EUR PA, DOI [10.2861/519030, DOI 10.2861/519030]
   CEDEFOP, 2015, EU SKILLS PAN 2014 S
   Cherubini M., 2014, ETHICAL AUTONOMOUS V
   CODDII-AENUI, 2014, C DIR DEC ING INF AS
   Coleman K. G., 2001, Ethics and Information Technology, V3, P247, DOI 10.1023/A:1013805017161
   Cuny J., 2011, TECH REP
   Descartes Rene, 2011, DISCURSO METODO
   European Parliament and Council of the EU, 2006, OFFICIAL J EUROPEA L, V394, P10
   Fleischmann K. R., 2009, P ASIST, V46, P1, DOI DOI 10.1002/MEET.2009.1450460345
   Foo P., 1978, PROBLEM ABORTION DOC
   Garcia-Cases F., 2016, 2016 Global Medical Engineering Physics Exchanges/Pan-American Health Care Exchanges (GMEPE/PAHCE), P1, DOI 10.1109/GMEPE-PAHCE.2016.7504645
   Garcia-Penalvo F. J., 2016, 18 S INT INF ED SIIE, P187
   Garcia-Penalvo F. J., 2016, OVERVIEW MOST RELEVA, DOI [10.5281/zenodo.165123, DOI 10.5281/ZENODO.165123]
   Garcia-Penalvo F. J., 2016, J INFORM TECHNOLOGY, V9, P5
   Goodall NJ, 2014, TRANSPORT RES REC, P58, DOI 10.3141/2424-07
   Greene JD, 2016, SCIENCE, V352, P1514, DOI 10.1126/science.aaf9534
   Grover S, 2013, EDUC RESEARCHER, V42, P38, DOI 10.3102/0013189X12463051
   Justo D., 2016, CADENA SER
   Knigth W., 2015, HELP SELF DRIVING CA
   Lye SY, 2014, COMPUT HUM BEHAV, V41, P51, DOI 10.1016/j.chb.2014.09.012
   Rahwan I., 2016, MORAL MACHINE
   Riek Laurel D., 2014, WE ROBOT, P1
   Salas J., 2016, COMPRARIAS COCHE QUE
   Salganik L.H, 2003, KEY COMPETENCIES SUC
   Scoane-Pardo A. M., 2016, P 4 INT C TECHN EC E, P37
   TACCLE 3 Consortium, 2017, TACCLE 3 COD ER PROJ
   THOMSON JJ, 1985, YALE LAW J, V94, P1395, DOI 10.2307/796133
   Veres SM, 2011, P I MECH ENG I-J SYS, V225, P155, DOI 10.1177/2041304110394727
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x
   Wilson C., 2010, RUNNING EMPTY FAILUR
   Wing J. M., 2011, LINK MAGAZINE, V6, P20
   Wing JM, 2008, PHILOS T R SOC A, V366, P3717, DOI 10.1098/rsta.2008.0118
   Wing JM, 2011, S VIS LANG HUM CEN C, P3, DOI 10.1109/VLHCC.2011.6070404
   Wing JM, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1118178.1118215
   Yadav A, 2017, TECH VOCAT ED TRAIN, V23, P1051, DOI 10.1007/978-3-319-41713-4_49
NR 44
TC 0
Z9 0
U1 14
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1932-8540
J9 IEEE REV IBEROAM TEC
JI IEEE Rev. Iberoam. Tecnol Aprendiz.
PD FEB
PY 2018
VL 13
IS 1
BP 20
EP 29
DI 10.1109/RITA.2018.2809940
PG 10
WC Computer Science, Interdisciplinary Applications
SC Computer Science
GA GB2FO
UT WOS:000428867000005
DA 2019-03-21
ER

PT J
AU Rodriguez, ALT
AF Terrones Rodriguez, Antonio Luis
TI Artificial intelligence and the ethic of responsibility
SO CUESTIONES DE FILOSOFIA
LA Spanish
DT Article
DE Artificial intelligence; ethics; responsibility; risks; technology;
   challenges
AB The artificial intelligence (IA) has set a great advance for humanity in several fields, however, that does not mean that its activity is excluded from the ethical reflection. Humanity is dealing, and it is going to deal in the future, with a number of challenges that will force us to create new ideas to be able to live at the demand of the ages. Among these challenges, we found: labor and economical; human improvement, military and security; and the political and juridical; among others. Then, once the challenges of the IA field are considered, one ethical reference that can serve to deal with those challenges can be the The Imperative of Responsibility of Hans Jonas. The reading of this ethical proposal can offer us the first coordinates to locate ourselves within a new horizon of possibilities for the humanity and serve as a starting point in the commitment that the different and involved knowledges should assume in this new field.
C1 [Terrones Rodriguez, Antonio Luis] Pontificia Univ Catolica Ecuador, Fac Ciencias Filosof Teol, Quito, Ecuador.
RP Rodriguez, ALT (reprint author), Pontificia Univ Catolica Ecuador, Fac Ciencias Filosof Teol, Quito, Ecuador.
EM antonioluis.terrones@gmail.com
CR [Anonymous], HUM BRAIN PROYECT 20
   [Anonymous], 2014, BRAIN RES ADV INN NE
   Arkin Ronald, 2011, GOVERNING LETHAL BEH
   Blue Brain Proyect, 2015, EC POL FED LAUS
   Bostrom N., 2016, SUPERINTELIGENCIA CA
   Bostrom N., 2017, MEJORAMIENTO HUMANO
   Bostrom N, 2008, INT LIBR ETH LAW TEC, V2, P107
   Chamayou Gregoire, 2013, THEORY DRONE
   Dieguez A., 2017, TRANSHUMANISMO BUSQU
   Esquirol J., 2011, FILOSOFOS CONT TECNI
   Federacional Internacional de Robotica, 2017, IMP ROB PROD EMPL JO
   Jonas H., 1995, PRINCIPIO RESPONSABI
   Jonas H., 2001, MAS CERCA PERVERSO F
   Jonas H., 1997, TECNICA MED ETICA PR
   Joque J., 2018, DECONSTRUCTION MACHI
   Kaplan J., 2016, ABSTENERSE HUMANOS G
   Kaplan J., 2016, INTELIGENCIA ARTIFIC
   Kasparov G., 2017, DEEP THINKING MACHIN
   Kurzweil R, 2017, SINGULARIDAD ESTA CE
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Linares J., 2008, ETICA MUNDO TECNOLOG
   McCorduck P., 1991, MAQUINAS QUE PIENSAN
   Moravec H, 1988, HOMBRE TECNOLOGICO F
   Muller V., 2014, FUNDAMENTAL ISSUES A, P51
   Nilsson N, 2001, INTELIGENCIA ARTIFIC
   Ortega A., 2016, IMPARABLE MARCHA ROB
   Rae M., 2013, FIN ENVEJECIMIENTO A
   UNESCO, 2017, REP COMEST ROB ETH
   Villalba Gómez Jairo Andrés, 2016, Divers.: Perspect. Psicol., V12, P137, DOI 10.15332/s1794-9998.2016.0001.10
   Vinge V, 2013, FUEGO ABISMO
   Winner L, 2008, BALLENA REACTOR
NR 31
TC 0
Z9 0
U1 0
U2 0
PU UNIV PEDAGOGICA & TECNOLOGICA COLOMBIA
PI TUNJA
PA AVE CENTRAL NORTE, KM 3 VIA PAIPA, TUNJA, BOYACA 00000, COLOMBIA
SN 0123-5095
J9 CUEST FILOS
JI Cuest. Filos.
PD JAN-JUN
PY 2018
VL 4
IS 22
BP 141
EP 170
DI 10.19053/01235095.v4.n22.2018.8311
PG 30
WC Philosophy
SC Philosophy
GA HJ4BJ
UT WOS:000457118400007
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Arrasate, S
   Duardo-Sanchez, A
   Beriain, ID
   Casabona, CR
   Gonzalez-Diaz, H
AF Arrasate, Sonia
   Duardo-Sanchez, Aliuska
   De Miguel Beriain, Inigo
   Romeo Casabona, Carlos
   Gonzalez-Diaz, Humbert
TI New Experimental and Computational Tools for Drug Discovery: Medicinal
   Chemistry, Personalized Medicine, Ethical & Legal Issues - Part-V
SO CURRENT TOPICS IN MEDICINAL CHEMISTRY
LA English
DT Editorial Material
C1 [Arrasate, Sonia; Gonzalez-Diaz, Humbert] Univ Basque Country UPV EHU, Dept Organ Chem 2, Leioa 48940, Spain.
   [Duardo-Sanchez, Aliuska; De Miguel Beriain, Inigo; Romeo Casabona, Carlos] Univ Basque Country UPV EHU, Dept Publ Law, Law & Human Genome Res Grp, Leioa 48940, Biscay, Spain.
   [De Miguel Beriain, Inigo; Gonzalez-Diaz, Humbert] Basque Fdn Sci, IKERBASQUE, Bilbao 48011, Biscay, Spain.
   [Romeo Casabona, Carlos] Univ Basque Country UPV EHU, Law & Human Genome Res Grp, European Grp Eth Sci & New Technol EGE, Dept Publ Law,European Commiss, Leioa 48940, Biscay, Spain.
RP Gonzalez-Diaz, H (reprint author), Univ Basque Country UPV EHU, Dept Organ Chem 2, Leioa 48940, Spain.; Gonzalez-Diaz, H (reprint author), Basque Fdn Sci, IKERBASQUE, Bilbao 48011, Biscay, Spain.
EM humberto.gonzalezdiaz@ehu.es
OI Duardo-Sanchez, Aliuska/0000-0003-1504-9053
FU MINECO [CTQ2016-74881-P]; Basque Government [IT1045-16, IT1066-16];
   European Commission, Research Executive Agency [788039]
FX We would like to thank Allen B. Reitz, the Editor in Chief, Ambreen
   Irshad, Associate Editor, and all the contributing authors and reviewers
   for their support and contributions to the issue. The authors
   acknowledge grants from MINECO (CTQ2016-74881-P), Basque Government (No.
   IT1045-16, No. IT1066-16), and European Commission, Research Executive
   Agency (788039 - PANELFIT - H2020-SwafS-2016-17/H2020-SwafS-2017-1).
CR Arrasate S, 2018, CURR TOP MED CHEM, V18, P1203, DOI 10.2174/1568026618666180810124031
   Clendenen N, 2018, CURR TOP MED CHEM, V18, P2143, DOI 10.2174/1568026619666181130140937
   Dhiman P, 2018, CURR TOP MED CHEM, V18, P1857, DOI 10.2174/1568026618666181115095204
   Eduardo LD, 2018, CURR TOP MED CHEM, V18, P917, DOI [10.2174/1568026618666180712093914, 10.2174/1568026619666181130141818]
   Sharma K, 2018, CURR TOP MED CHEM, V18, P2174
NR 5
TC 0
Z9 0
U1 1
U2 1
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1568-0266
EI 1873-5294
J9 CURR TOP MED CHEM
JI Curr. Top. Med. Chem.
PY 2018
VL 18
IS 25
BP 2141
EP 2142
DI 10.2174/156802661825190118124556
PG 2
WC Chemistry, Medicinal
SC Pharmacology & Pharmacy
GA HI2LL
UT WOS:000456276600003
PM 30698106
DA 2019-03-21
ER

PT J
AU Daley, K
   Howell, RJ
AF Daley, Ken
   Howell, Robert J.
TI Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence
SO TPM-THE PHILOSOPHERS MAGAZINE
LA English
DT Book Review
C1 [Daley, Ken; Howell, Robert J.] Southern Methodist Univ, Dallas, TX 75275 USA.
RP Daley, K (reprint author), Southern Methodist Univ, Dallas, TX 75275 USA.
CR LIN P, ROBOT ETHICS 2 0 AUT
NR 1
TC 0
Z9 0
U1 2
U2 2
PU PHILOSOPHY DOCUMENTATION CENTER
PI CHARLOTTESVILLE
PA PO BOX 7147, CHARLOTTESVILLE, VA 22906-7147 USA
SN 1354-814X
EI 2048-4674
J9 TPM-PHILOS MAG
JI TPM-Philos. Mag.
PY 2018
IS 82
BP 110
EP 112
DI 10.5840/tpm20188287
PG 3
WC Philosophy
SC Philosophy
GA HC5GV
UT WOS:000451832400023
DA 2019-03-21
ER

PT J
AU Maet, F
AF Maet, Frank
TI Robot at the wheel: About the ethics of technology
SO TIJDSCHRIFT VOOR FILOSOFIE
LA Dutch
DT Book Review
CR EYNIKEL J, 2017, ROBOT AAN HET STUUR
NR 1
TC 0
Z9 0
U1 0
U2 0
PU PEETERS
PI LEUVEN
PA BONDGENOTENLAAN 153, B-3000 LEUVEN, BELGIUM
SN 0040-750X
EI 2031-8952
J9 TIJDSCHR FILOS
JI Tijdschr. Filos.
PY 2018
VL 80
IS 2
BP 406
EP 407
PG 2
WC Philosophy
SC Philosophy
GA HB8RO
UT WOS:000451358500023
DA 2019-03-21
ER

PT J
AU Berg, KT
AF Berg, Kati Tusinski
TI The ethics of artificial intelligence: superintelligence, life 3.0 and
   robot rights
SO JOURNAL OF MEDIA ETHICS
LA English
DT Editorial Material
C1 [Berg, Kati Tusinski] Marquette Univ, Dept Strateg Commun, Diederich Coll Commun, Milwaukee, WI 53233 USA.
RP Berg, KT (reprint author), Marquette Univ, Dept Strateg Commun, Diederich Coll Commun, Milwaukee, WI 53233 USA.
EM kati.berg@marquette.edu
CR Kamenetz A., 2018, KIDS MEET ALEXA YOUR
   Levy D., 2005, ROBOTS UNLIMITED LIF
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8
   Vanian J., 2018, FORTUNE
NR 4
TC 0
Z9 0
U1 20
U2 23
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2373-6992
EI 2373-700X
J9 J MEDIA ETHICS
JI J. Media Ethics
PY 2018
VL 33
IS 3
BP 151
EP 153
DI 10.1080/23736992.2018.1482722
PG 3
WC Communication; Ethics
SC Communication; Social Sciences - Other Topics
GA GO2GP
UT WOS:000439787700006
DA 2019-03-21
ER

PT J
AU Thomson, I
   Grubnic, S
   Georgakopolous, G
AF Thomson, Ian
   Grubnic, Suzana
   Georgakopolous, Georgios
TI Review: Time machines, ethics and sustainable development: accounting
   for inter-generational equity in public sector organizations
SO PUBLIC MONEY & MANAGEMENT
LA English
DT Review
DE Governance; inter-generational equity; sustainable development
ID UK
AB This review paper explores the key challenges associated with effective inter-generational equity accounts in relation to the governance of public sector organizations and sustainable development transformations. Three different approaches to inter-generational equity accounting are evaluated and an outline for future research is provided.
C1 [Thomson, Ian] Univ Birmingham, Accounting & Sustainabil, Birmingham, W Midlands, England.
   [Thomson, Ian] Ctr Social & Environm Accounting Res, Birmingham, W Midlands, England.
   [Grubnic, Suzana] Loughborough Univ Technol, Sch Business & Econ, Management Accounting, Loughborough, Leics, England.
   [Georgakopolous, Georgios] Univ Amsterdam, Amsterdam Business Sch, Accounting Sect, Amsterdam, Netherlands.
RP Thomson, I (reprint author), Univ Birmingham, Accounting & Sustainabil, Birmingham, W Midlands, England.; Thomson, I (reprint author), Ctr Social & Environm Accounting Res, Birmingham, W Midlands, England.
CR Attfield R, 2010, HUM ECOL REV, V17, P102
   AUERBACH AJ, 1994, J ECON PERSPECT, V8, P73, DOI 10.1257/jep.8.1.73
   Bebbington J, 2017, CRIT PERSPECT ACCOUN, V48, P21, DOI 10.1016/j.cpa.2017.06.002
   Bebbington J, 2014, ACCOUNT ORG SOC, V39, P395, DOI 10.1016/j.aos.2014.01.003
   BENGTSON VL, 1993, GERONTOLOGIST, V33, P812
   Cabinet Office, 2017, IMPL SUST DEV GOALS
   Cardarelli R, 2000, ECON J, V110, pF547, DOI 10.1111/1468-0297.00573
   Colquhoun P., 2010, INTERGENERATIONAL EQ
   Dasgupta Partha, 1999, DISCOUNTING INTERGEN
   Dunlop S., 2012, OXFAM HUMANKIND INDE
   Esping-Andersen G, 2002, J EUR SOC POLICY, V12, P5, DOI 10.1177/0952872002012001560
   Gagne A., 2016, INDEX INTERGENERATIO
   Gray R, 2010, ACCOUNT ORG SOC, V35, P47, DOI 10.1016/j.aos.2009.04.006
   Kohli M., 2006, HDB AGING SOCIAL SCI, P456
   Kohli M., 2008, PENSION REFORM EUROP, P196
   Kotlikoff L., 1991, TAX POLICY EC, V5, P55
   Lisenkovaa K., 2015, SUSTAINABILITY SCOTT
   Lyon R., 2016, ACT I C REIM FUT MEL
   Lyons O., 1994, AM INDIAN ENV ECOLOG
   Norton Bryan, 1999, FAIRNESS FUTURITY
   PALLOT J, 1991, ACCOUNT ORG SOC, V16, P201, DOI 10.1016/0361-3682(91)90014-6
   Piachaud D., 2016, THINK PIECE INTERGEN
   Povah C., 2017, GUARDIAN
   PRESTON SH, 1984, DEMOGRAPHY, V21, P435, DOI 10.2307/2060909
   Rawls J., 1972, A THEORYOF JUSTICE
   Robinson M., 1998, FISCAL STUDIES, V19, P447, DOI DOI 10.1111/j.1475-5890.1998.tb00295.x
   Roemer J, 2007, INTERGENERATIONAL EQ
   Russell SL, 2009, ACCOUNT FORUM, V33, P225, DOI 10.1016/j.accfor.2008.07.008
   Stout Lynn A., 2015, SEATTLE U L REV, V38, P685
   Thomson I, 2014, ACCOUNT ORG SOC, V39, P453, DOI 10.1016/j.aos.2014.02.003
   UN-United Nations [homepage on the Internet], 2015, 2030 AG SUST DEV
   Weiss E.B, 1992, AM U INT LAW REV, V8, P19
   Willetts D., 2010, PINCH BABY BOOMERS T
   Williamson J.B., 2003, J SOCIOLOGY SOCIAL W, V30, P3
   Williamson JB, 2011, INT J AGEING LATER L, V6, P33, DOI DOI 10.3384/ijal.1652-8670.116133
   Work and Pensions Committee, 2017, INT FAIRN REP SESS 2
NR 36
TC 1
Z9 1
U1 2
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0954-0962
EI 1467-9302
J9 PUBLIC MONEY MANAGE
JI Public Money Manage.
PY 2018
VL 38
IS 5
BP 379
EP 388
DI 10.1080/09540962.2018.1477677
PG 10
WC Public Administration
SC Public Administration
GA GI2JF
UT WOS:000434195500010
DA 2019-03-21
ER

PT J
AU Bantry-White, E
AF Bantry-White, Eleanor
TI Supporting ethical use of electronic monitoring for people living with
   dementia: Social work's role in assessment, decision-making, and review
SO JOURNAL OF GERONTOLOGICAL SOCIAL WORK
LA English
DT Review
DE Dementia/dementia care; assistive technology/technology; social work
   practice; health care decision-making; person-centered care
ID ALZHEIMERS-DISEASE; NONPHARMACOLOGICAL INTERVENTIONS; PSYCHOLOGICAL
   SYMPTOMS; WANDERING BEHAVIOR; TRACKING PATIENTS; ELDERLY-PEOPLE; GETTING
   LOST; SURVEILLANCE; TECHNOLOGY; COMMUNITY
AB Walking outdoors supports health and well-being, but some people living with dementia are at increased risk of getting lost and of harm while missing. Electronic monitoring can potentially play an important preventative role by enabling the person's location to be continuously monitored by caregivers. However, there are considerable ethical concerns arising from electronic monitoring. This paper explores these thematically, drawing attention to its implications for autonomy and liberty; privacy; dignity; the rights and needs of caregivers and families; beneficence and nonmaleficence. Following from this, key questions for consideration in social work assessment are identified. The ethical issues necessitate assessment of the person's unique circumstances and preferences and that of their caregivers, and careful ethical deliberation in decision-making. Social work can play an important role in facilitating inclusive assessment and decision-making, leading to consensus on intervening with electronic monitoring. The need for the ongoing review following implementation is discussed to track whether decisions need modification in light of the experience of usage. In conclusion, while legislative instruments and professional codes of ethics frame social work practice responses, there is need for a nuanced debate about ethical use of electronic monitoring and specific guidance to inform assessment, decision-making, and review.
C1 [Bantry-White, Eleanor] Univ Coll Cork, Sch Appl Social Studies, Cork, Ireland.
RP Bantry-White, E (reprint author), Univ Coll Cork, Natl Univ Ireland, Appl Social Studies, Donovans Rd, Cork, Cork, Ireland.
EM e.bantrywhite@ucc.ie
CR Algase D. L., 2007, EVIDENCE BASED PROTO, V1
   Allan K., 2008, EXCELLENCE DEMENTIA, P212
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT
   Argyle E, 2017, AGING MENT HEALTH, V21, P1005, DOI 10.1080/13607863.2016.1222351
   Ballard C., 2010, SUPPORTIVE CARE PERS, P105
   Beauchamp TL, 2001, PRINCIPLES BIOETHICS
   BOGO M, 1987, J GERONTOL SOC WORK, V10, P5, DOI 10.1300/J083V10N01_02
   Bowen ME, 2011, DEMENT GERIATR COGN, V31, P406, DOI 10.1159/000329792
   Cantor MD, 2006, GENERATIONS, V30, P49
   Cassarino M, 2015, AGEING RES REV, V23, P167, DOI 10.1016/j.arr.2015.06.003
   Chiu YC, 2005, INT J GERIATR PSYCH, V20, P760, DOI 10.1002/gps.1356
   Dewing J, 2006, INT J OLDER PEOPLE N, V1, P239, DOI 10.1111/j.1748-3743.2006.00045.x
   Essen A, 2008, SOC SCI MED, V67, P128, DOI 10.1016/j.socscimed.2008.03.005
   Gabriels K, 2016, ETHICS INF TECHNOL, V18, P175, DOI 10.1007/s10676-016-9405-1
   Gambrill E., 2005, CRITICAL THINKING CL
   Gergerich E, 2017, J GERONTOL SOC WORK, V60, P232, DOI 10.1080/01634372.2017.1293757
   Guta A, 2012, AM J BIOETHICS, V12, P57, DOI 10.1080/15265161.2012.699140
   Hermans DG, 2007, COCHRANE DB SYST REV, DOI 10.1002/14651858
   Hope T, 2001, INT PSYCHOGERIATR, V13, P137, DOI 10.1017/S1041610201007542
   Hope T., 2008, MED ETHICS LAW CORE, V2
   Hughes J. C., 2008, J ETHICS MENTAL HLTH, V3, P1
   Hughes J. C., 2006, ETHICAL ISSUES DEMEN
   Hughes JC, 2002, BRIT MED J, V325, P847, DOI 10.1136/bmj.325.7369.847
   Hunt LA, 2010, AM J OCCUP THER, V64, P225, DOI 10.5014/ajot.64.2.225
   Innes A, 2009, DEMENTIA STUDIES
   Kaplan DB, 2013, J GERONTOL SOC WORK, V56, P164, DOI 10.1080/01634372.2012.753652
   Kaufman AV, 2010, J GERONTOL SOC WORK, V53, P251, DOI 10.1080/01634370903478989
   KOESTER RJ, 1995, WILD ENVIRON MED, V6, P34, DOI 10.1016/S1080-6032(13)80007-5
   Kwok TCY, 2010, INT J GERIATR PSYCH, V25, P427, DOI 10.1002/gps.2361
   Lai CKY, 2003, J ADV NURS, V44, P173, DOI 10.1046/j.1365-2648.2003.02781.x
   Landau R, 2009, BRIT J SOC WORK, V39, P670, DOI 10.1093/bjsw/bcp037
   Lerner JS, 2015, ANNU REV PSYCHOL, V66, P799, DOI 10.1146/annurev-psych-010213-115043
   Liu LL, 2017, J TECHNOL HUMAN SERV, V35, P99, DOI 10.1080/15228835.2016.1266724
   Lovheim H, 2008, INT PSYCHOGERIATR, V20, P777, DOI 10.1017/S1041610208006777
   Lymbery M., 2005, SOCIAL WORK OLDER PE
   Macnish K, 2014, SURVEILL SOC, V12, P142
   Marshall M., 2006, SOCIAL WORK PEOPLE D
   Matsumoto N, 2007, DEMENT GERIATR COGN, V23, P219, DOI 10.1159/000099472
   McShane R, 1998, INT J GERIATR PSYCH, V13, P556, DOI 10.1002/(SICI)1099-1166(199808)13:8<556::AID-GPS834>3.0.CO;2-6
   MCSHANE R, 1994, LANCET, V343, P1274, DOI 10.1016/S0140-6736(94)92159-8
   McShane R, 1998, Int Psychogeriatr, V10, P253, DOI 10.1017/S1041610298005365
   Milne H, 2014, BMC PSYCHIATRY, V14, DOI 10.1186/1471-244X-14-160
   Montgomery P., 2006, PRINCIPLES PRACTICE, V1, P733
   Nagata T, 2010, INT PSYCHOGERIATR, V22, P463, DOI 10.1017/S1041610209991323
   Nagel SK, 2012, AM J BIOETHICS, V12, P53, DOI 10.1080/15265161.2012.699146
   Nellis M, 2013, ELECT MONITORED PUNI
   Niemeijer AR, 2010, INT PSYCHOGERIATR, V22, P1129, DOI 10.1017/S1041610210000037
   Nuffield Council on Bioethics, 2009, DEM ETH ISS 978 1 90
   Oderud T, 2015, STUD HEALTH TECHNOL, V217, P212, DOI 10.3233/978-1-61499-566-1-212
   Oppenheimer C, 1997, PSYCHIAT ELDERLY, V1, P709
   Percival J, 2006, CRIT SOC POLICY, V26, P888, DOI 10.1177/0261018306068480
   Pot AM, 2012, AGING MENT HEALTH, V16, P127, DOI 10.1080/13607863.2011.596810
   Robinson L, 2007, HEALTH RISK SOC, V9, P389, DOI 10.1080/13698570701612774
   Robinson L, 2007, INT J GERIATR PSYCH, V22, P9, DOI 10.1002/gps.1643
   Robinson L, 2006, HEALTH TECHNOL ASSES, V10, P1
   Rowe M A, 2001, Am J Alzheimers Dis Other Demen, V16, P344, DOI 10.1177/153331750101600610
   Rowe Meredeth A, 2003, Am J Alzheimers Dis Other Demen, V18, P343
   Royse D., 2010, PROGRAM EVALUATION I, V5
   Scarmeas N, 2007, ARCH NEUROL-CHICAGO, V64, P1755, DOI 10.1001/archneur.64.12.1755
   Song JA, 2008, ARCH PSYCHIAT NURS, V22, P318, DOI 10.1016/j.apnu.2007.10.008
   Sorell T, 2012, AM J BIOETHICS, V12, P36, DOI 10.1080/15265161.2012.699137
   Stevenson M, 2018, J RISK RES, V21, P692, DOI 10.1080/13669877.2016.1235604
   Swanberg MM, 2004, ARCH NEUROL-CHICAGO, V61, P556, DOI 10.1001/archneur.61.4.556
   Tavani H. T., 2008, ETHICS TECHNOLOGY
   The Alzheimer's Society, 2007, POS STAT SAF WALK TE
   United Nations D. o. E. a. S. A. Population Division, 2013, STSEASERA348 UN
   White EB, 2016, HEALTH SOC CARE COMM, V24, P473, DOI 10.1111/hsc.12226
   White EB, 2015, AGING MENT HEALTH, V19, P224, DOI 10.1080/13607863.2014.924091
   White EB, 2014, RES SOCIAL WORK PRAC, V24, P400, DOI 10.1177/1049731513514116
   White EB, 2014, DEMENTIA-LONDON, V13, P216, DOI 10.1177/1471301212460445
   White EB, 2010, BRIT J OCCUP THER, V73, P152, DOI 10.4276/030802210X12706313443901
   WHO, 2012, DEM PUBL HLTH PRIOR
   Yang YT, 2016, J AM GERIATR SOC, V64, P1708, DOI 10.1111/jgs.14265
   Zwijsen SA, 2011, AGING MENT HEALTH, V15, P419, DOI 10.1080/13607863.2010.543662
NR 74
TC 2
Z9 2
U1 6
U2 9
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1540-4048
EI 0163-4372
J9 J GERONTOL SOC WORK
JI J. Gerontol. Soc. Work
PY 2018
VL 61
IS 3
BP 261
EP 279
DI 10.1080/01634372.2018.1433738
PG 19
WC Geriatrics & Gerontology; Gerontology; Social Work
SC Geriatrics & Gerontology; Social Work
GA GE6IE
UT WOS:000431329200003
PM 29381128
DA 2019-03-21
ER

PT J
AU Vandemeulebroucke, T
   de Casterle, BD
   Gastmans, C
AF Vandemeulebroucke, Tijs
   de Casterle, Bernadette Dierckx
   Gastmans, Chris
TI The use of care robots in aged care: A systematic review of
   argument-based ethics literature
SO ARCHIVES OF GERONTOLOGY AND GERIATRICS
LA English
DT Review
DE Aging; Older adults; Aged-care practices; Robotics; Normative ethics;
   Roboethics
ID SOCIALLY ASSISTIVE ROBOTS; ELDERLY-PEOPLE; HEALTH-CARE; DECEPTION;
   DEMENTIA
AB Background: As care robots become more commonplace in aged-care settings, the ethical debate on their use becomes increasingly important. Our objective was to examine the ethical arguments and underlying concepts used in the ethical debate on care robot use in aged care.
   Methods: We conducted a systematic literature search for argument-based ethics publications focusing on care robot use in aged-care practices. We used an innovative methodology that consisted of three steps: (a) identifying conceptual-ethical questions, (b) conducting a literature search, and (c) identifying, describing and analyzing the ethical arguments in connection with the conceptual-ethical questions.
   Results: Twenty-eight appropriate publications were identified. All were published between 2002 and 2016. Four primary ethical approaches were distinguished: (a) a deontological, (b) a principlist, (c) an objective-list, and (d) a care-ethical. All approaches were equally represented across the articles, and all used similar concepts that grounded their diverse ethical arguments. A small group of publications could not be linked to an ethical approach.
   Conclusions: All included publications presented a strong ethical rationale based on fully elaborated normative arguments. Although the reviewed studies used similar grounding concepts, the studies' arguments were very diverse and sometimes diametrically opposed. Our analysis shows how one envisions care robot use in aged-care settings is influenced by how one views the traditional boundaries of the ethical landscape in aged care. We suggest that an ethical analysis of care robot use employs "democratic spaces," in which all stakeholders in aged care, especially care recipients, have a voice in the ethical debate.
C1 [Vandemeulebroucke, Tijs; Gastmans, Chris] Univ Leuven, KU Leuven, Ctr Biomed Eth & Law, Fac Med, Kapucijnenvoer 35-D Box 7001, B-3000 Leuven, Belgium.
   [de Casterle, Bernadette Dierckx] Univ Leuven, KU Leuven, Acad Ctr Nursing & Midwifery, Fac Med, Kapucijnenvoer 35-D Box 7001, B-3000 Leuven, Belgium.
RP Vandemeulebroucke, T (reprint author), Univ Leuven, KU Leuven, Ctr Biomed Eth & Law, Fac Med, Kapucijnenvoer 35-D Box 7001, B-3000 Leuven, Belgium.
EM tijs.vandemeulebroucke@kuleuven.be;
   bernadette.dierckxdecasterle@kuleuven.be; chris.gastmans@kuleuven.be
CR Bedaf S, 2015, ASSIST TECHNOL, V27, P88, DOI 10.1080/10400435.2014.978916
   Bemelmans R, 2012, J AM MED DIR ASSOC, V13, P114, DOI 10.1016/j.jamda.2010.10.002
   Blackford R, 2012, ETHICS INF TECHNOL, V14, P41, DOI 10.1007/s10676-011-9266-6
   Borenstein J, 2010, ETHICS INF TECHNOL, V12, P277, DOI 10.1007/s10676-010-9236-4
   Coeckelbergh M, 2016, AI SOC, V31, P455, DOI 10.1007/s00146-015-0626-3
   Coeckelbergh M, 2015, THEOR MED BIOETH, V36, P265, DOI 10.1007/s11017-015-9331-y
   Coeckelbergh M, 2012, IEEE T AFFECT COMPUT, V3, P388, DOI 10.1109/T-AFFC.2011.29
   Coeckelbergh M, 2010, ETHICAL THEORY MORAL, V13, P181, DOI 10.1007/s10677-009-9186-2
   de Casterle BD, 2012, INT J NURS STUD, V49, P360, DOI 10.1016/j.ijnurstu.2011.09.012
   de Graaf MMA, 2013, ROBOT AUTON SYST, V61, P1476, DOI 10.1016/j.robot.2013.07.007
   Decker M, 2008, AI SOC, V22, P315, DOI 10.1007/s00146-007-0151-0
   FEENBERG Andrew, 1999, QUESTIONING TECHNOLO
   Feil-Seifer D, 2005, INT C REHAB ROBOT, P465
   Feil-Seifer D, 2011, IEEE ROBOT AUTOM MAG, V18, P24, DOI [10.1109/MRA.2010.940149, 10.1109/MRA.2010.940150]
   Flandorfer P, 2012, INT J POPULATION RES
   Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
   Hooker Brad, 2000, MORAL PARTICULARISM
   Ienca M, 2016, INT J SOC ROBOT, V8, P565, DOI 10.1007/s12369-016-0366-7
   Kachouie R, 2014, INT J HUM-COMPUT INT, V30, P369, DOI 10.1080/10447318.2013.873278
   Kortner T, 2016, Z GERONTOL GERIATR, V49, P303, DOI 10.1007/s00391-016-1066-5
   Liberati A, 2009, BMJ-BRIT MED J, V339, DOI 10.1136/bmj.b2700
   Lin P., 2014, ROBOT ETHICS ETHICAL
   Matthias A, 2015, KENNEDY INST ETHIC J, V25, P169, DOI 10.1353/ken.2015.0007
   McCullough LB, 2007, J MED PHILOS, V32, P65, DOI 10.1080/03605310601152206
   Mertz M, 2016, BMC MED, V14, DOI 10.1186/s12916-016-0688-1
   Metzler TA, 2016, NURS PHILOS, V17, P36, DOI 10.1111/nup.12101
   Metzler TA, 2014, NURS PHILOS, V15, P4, DOI 10.1111/nup.12027
   Misselhorn C, 2013, GEROPSYCH, V26, P121, DOI 10.1024/1662-9647/a000088
   Mordoch E, 2013, MATURITAS, V74, P14, DOI 10.1016/j.maturitas.2012.10.015
   Nussbaum M., 2006, FRONTIERS JUSTICE DI
   Parks JA, 2010, HYPATIA, V25, P100, DOI 10.1111/j.1527-2001.2009.01086.x
   PINCH TJ, 1984, SOC STUD SCI, V14, P399, DOI 10.1177/030631284014003004
   Preuss D., 2016, J MED ETHICS, P1
   Robinson H, 2014, INT J SOC ROBOT, V6, P575, DOI 10.1007/s12369-014-0242-2
   Rodogno R., 2015, ETHICS INFORM TECHNO, V18
   Sharkey A, 2014, ETHICS INF TECHNOL, V16, P63, DOI 10.1007/s10676-014-9338-5
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   Sharkey A, 2011, IEEE ROBOT AUTOM MAG, V18, P32, DOI [10.1109/MRA.2010.940151, 10.1109/MRA.2010.940150]
   Sharkey N, 2012, GERONTOLOGY, V58, P282, DOI 10.1159/000329483
   Shatzer J, 2013, NEW BIOETH, V19, P46, DOI 10.1179/2050287713Z.00000000022
   Sofaer N, 2012, BIOETHICS, V26, P315, DOI 10.1111/j.1467-8519.2011.01858.x
   Sorell T, 2014, ETHICS INF TECHNOL, V16, P183, DOI 10.1007/s10676-014-9344-7
   Sparrow R., 2002, Ethics and Information Technology, V4, P305, DOI 10.1023/A:1021386708994
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Sparrow R, 2016, AI SOC, V31, P445, DOI 10.1007/s00146-015-0625-4
   Tzafestas Spyros G, 2016, ROBOETHICS NAVIGATIN
   Vallor S., 2011, PHILOS TECHNOLOGY, V24, P251, DOI DOI 10.1007/S13347-011-0015-X
   van Wynsberghe A, 2013, SCI ENG ETHICS, V19, P407, DOI 10.1007/s11948-011-9343-6
   Vandemeulebroucke T., 2017, AGING MENTAL HLTH
   Vanlaere L., 2012, TGE TIJDSCHRIFT GEZO, V3, P85
   World Health Organization, 2015, WORLD REP AG HLTH
NR 51
TC 3
Z9 3
U1 9
U2 45
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0167-4943
EI 1872-6976
J9 ARCH GERONTOL GERIAT
JI Arch. Gerontol. Geriatr.
PD JAN
PY 2018
VL 74
BP 15
EP 25
DI 10.1016/j.archger.2017.08.014
PG 11
WC Geriatrics & Gerontology
SC Geriatrics & Gerontology
GA FN4NH
UT WOS:000415983300003
PM 28926749
DA 2019-03-21
ER

PT J
AU Boddington, P
   Millican, P
   Wooldridge, M
AF Boddington, Paula
   Millican, Peter
   Wooldridge, Michael
TI Minds and Machines Special Issue: Ethics and Artificial Intelligence
SO MINDS AND MACHINES
LA English
DT Article
C1 [Boddington, Paula; Wooldridge, Michael] Univ Oxford, Dept Comp Sci, Wolfson Bldg,Pk Rd, Oxford OX1 3QD, England.
   [Millican, Peter] Hertford Coll, Oxford OX1 3BW, England.
RP Boddington, P (reprint author), Univ Oxford, Dept Comp Sci, Wolfson Bldg,Pk Rd, Oxford OX1 3QD, England.
EM paula.boddington@cs.ox.ac.uk
NR 0
TC 1
Z9 1
U1 5
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-6495
EI 1572-8641
J9 MIND MACH
JI Minds Mach.
PD DEC
PY 2017
VL 27
IS 4
BP 569
EP 574
DI 10.1007/s11023-017-9449-y
PG 6
WC Computer Science, Artificial Intelligence
SC Computer Science
GA FP0JV
UT WOS:000417286400002
OA Bronze
DA 2019-03-21
ER

PT J
AU Pagallo, U
AF Pagallo, Ugo
TI When Morals Ain't Enough: Robots, Ethics, and the Rules of the Law
SO MINDS AND MACHINES
LA English
DT Article
DE AI; Moral theory; Robotics; Secondary rule; Special zone
AB No single moral theory can instruct us as to whether and to what extent we are confronted with legal loopholes, e.g. whether or not new legal rules should be added to the system in the criminal law field. This question on the primary rules of the law appears crucial for today's debate on roboethics and still, goes beyond the expertise of robo-ethicists. On the other hand, attention should be drawn to the secondary rules of the law: The unpredictability of robotic behaviour and the lack of data on the probability of events, their consequences and costs, make hard to determine the levels of risk and hence, the amount of insurance premiums and other mechanisms on which new forms of accountability for the behaviour of robots may hinge. By following Japanese thinking, the aim is to show why legally de-regulated, or special, zones for robotics, i.e. the secondary rules of the system, pave the way to understand what kind of primary rules we may want for our robots.
C1 [Pagallo, Ugo] Univ Turin, Sch Law, Turin, Italy.
RP Pagallo, U (reprint author), Univ Turin, Sch Law, Turin, Italy.
EM ugo.pagallo@unito.it
OI PAGALLO, Ugo/0000-0001-7981-8849
CR Abney K, 2012, INTELL ROBOT AUTON, P35
   Anderson M, 2008, STUD COMPUT INTELL, V107, P233
   Barfield W, 2005, PRESENCE-TELEOP VIRT, V14, P741, DOI 10.1162/105474605775196607
   Bringsjord S, 2012, INTELL ROBOT AUTON, P85
   Chisholm Roderick, 1974, PRACTICAL REASON, P1
   Coudert Allison P., 1995, LEIBNIZ KABBALAH
   Davis J., 2011, J LAW INFORM SCI, V21, P1, DOI DOI 10.5778/JLIS.2011.21.DAVIS.1
   ENAC, 2015, REM PIL AER VEH REG
   Floridi L, 2015, ONLIFE MANIFESTO BEI
   Freitas Pedro Miguel, 2014, AI Approaches to the Complexity of Legal Systems. AICOL 2013 International Workshops, AICOL-IV@IVR. Revised Selected Papers: LNCS 8929, P145, DOI 10.1007/978-3-662-45960-7_11
   Hallevy G., 2015, LIABILITY CRIMES INV
   hart H L A., 1961, CONCEPT LAW
   Horty JF, 2001, AGENCY DEONTIC LOGIC
   Horvitz E., 2014, CISC VIS NETW IND GL
   Kant I., 1999, CAMBRIDGE EDITION WO, V8
   Koops BJ, 2006, INF TECHNOL LAW SER, V9, P77
   Kroll Joshua A., 2017, U PENNSYLVANIA LAW R, V165
   Lewis Clarence I., 1932, SYMBOLIC LOGIC
   MOOR JH, 1985, METAPHILOSOPHY, V16, P266, DOI 10.1111/j.1467-9973.1985.tb00173.x
   Murakami Y., 2004, P 5 INT C ADV MOD LO, P288
   Noack Rick, 2015, WASHINGTON POST
   Pagallo U., 2016, DATA PROTECTION MOVE, P387
   Pagallo U., 2013, PHILOS TECHNOL, V26, P381, DOI [10.1007/s13347-013-0119-6, DOI 10.1007/S13347-013-0119-6]
   Pagallo U., 2016, 3 LESSONS LEARNED IN
   Pagallo U, 2013, COMPUT LAW SECUR REV, V29, P501, DOI 10.1016/j.clsr.2013.07.012
   Pagallo Ugo, 2013, LAWS ROBOTS CRIMES C
   QUINN P, 1978, DIVINE COMMANDS MORA
   Reed Chris, 2012, MAKING LAWS CYBERSPA
   Sartor G, 2009, ARTIF INTELL LAW, V17, P253, DOI 10.1007/s10506-009-9081-0
   UN World Robotics, 2005, ED UN EC COMM EUR CO
   Veruggio G., 2006, P EUR ROB AT FEBR 27
   Wallach W., 2009, MORAL MACHINES TEACH
   Weng YH, 2015, INT J SOC ROBOT, V7, P841, DOI 10.1007/s12369-015-0287-x
NR 33
TC 0
Z9 0
U1 8
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-6495
EI 1572-8641
J9 MIND MACH
JI Minds Mach.
PD DEC
PY 2017
VL 27
IS 4
BP 625
EP 638
DI 10.1007/s11023-017-9418-5
PG 14
WC Computer Science, Artificial Intelligence
SC Computer Science
GA FP0JV
UT WOS:000417286400006
DA 2019-03-21
ER

PT J
AU Yilmaz, L
   Franco-Watkins, A
   Kroecker, TS
AF Yilmaz, Levent
   Franco-Watkins, Ana
   Kroecker, Timothy S.
TI Computational models of ethical decision-making: A coherence-driven
   reflective equilibrium model
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Decision-making; Machine ethics; Cognitive coherence; Reflective
   equilibrium; Cognitive agent
ID MACHINE
AB There are scientific and technical challenges that must be addressed in developing systems that interact with humans and work along with other agents in complex, dynamic, and uncertain environments where ethical concerns may arise. In such systems relationships between users and autonomous components will be driven as much by issues such as trust, responsibility, and acceptability, as technical ones such as planning and coordination. This paper provides a comprehensive review and classification of existing methods in machine ethics, resulting in delineation of specific challenges and issues. To address the identified challenges, we introduce a method that leverages the method of reflective equilibrium and the multi-coherence theory as a unifying constraint satisfaction framework to simultaneously assess multiple ethical principles and manage ethical conflicts in a context-sensitive manner. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Yilmaz, Levent] Auburn Univ, Dept Comp Sci & Software Engn, 3101 Shelby Ctr, Auburn, AL 36849 USA.
   [Franco-Watkins, Ana] Auburn Univ, Dept Pyschol, Auburn, AL 36849 USA.
   [Kroecker, Timothy S.] US Air Force, Res Lab, Washington, DC 20330 USA.
RP Yilmaz, L (reprint author), Auburn Univ, Dept Comp Sci & Software Engn, 3101 Shelby Ctr, Auburn, AL 36849 USA.
EM yilmaz@auburn.edu
CR Anderson M., 2011, MACHINE ETHICS
   Anderson M., 2013, P 11 INT S LOG FORM
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64
   Angluin D., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P351, DOI 10.1145/129712.129746
   Apt K. R, 2003, PRINCIPLES CONSTRAIN
   Arkin R., 2009, GOVERNING LETHAL BEH
   Arkoudas K, 2005, AAAI FALL S MACH ETH
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82
   Clarke R., 1993, IEEE COMPUT, V26, P53
   Daniels N., 1996, JUSTICE JUSTIFICATIO, V22
   Dennis L., 2013, C AUT ROB SYST, P433
   Gert B., 1998, MORALITY ITS NATURE
   Gips J., 1995, ANDROID EPISTEMOLOGY, P243
   Grogan Abi, 2012, Engineering & Technology, V7, P54, DOI 10.1049/et.2012.0514
   Herman M., 2014, J COGNITION NEUROETH, V73, P127
   Jennings NR, 2014, COMMUN ACM, V57, P80, DOI 10.1145/2629559
   KURLAND NB, 1995, J APPL SOC PSYCHOL, V25, P297, DOI 10.1111/j.1559-1816.1995.tb02393.x
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80
   Pereira Luis Moniz, 2009, International Journal of Reasoning-based Intelligent Systems, V1, P209, DOI 10.1504/IJRIS.2009.028020
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77
   Rawls J, 2009, THEORY JUSTICE
   Robbins RW, 2007, DECIS SUPPORT SYST, V43, P1571, DOI 10.1016/j.dss.2006.03.003
   Ross W. D., 1930, RIGHT GOOD
   Sen S, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1507
   Thagard P, 2002, COHERENCE THOUGHT AC
   Han TA, 2012, LECT NOTES COMPUT SC, V7180, P212, DOI 10.1007/978-3-642-28717-6_18
   Turilli M., 2007, Ethics and Information Technology, V9, P49, DOI 10.1007/s10676-006-9128-9
   Tversky A., 1985, ENVIRON IMPACT ASSES, P107
   Wallach W., 2008, MORAL MACHINES TEACH
   Weiss G., 1999, MULTIAGENT SYSTEMS M
   Wright R, 2010, MORAL ANIMAL WHY WE
   Yilmaz L, 2016, 2016 IEEE INTERNATIONAL MULTI-DISCIPLINARY CONFERENCE ON COGNITIVE METHODS IN SITUATION AWARENESS AND DECISION SUPPORT (COGSIMA), P42, DOI 10.1109/COGSIMA.2016.7497784
NR 33
TC 0
Z9 0
U1 2
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD DEC
PY 2017
VL 46
SI SI
BP 61
EP 74
DI 10.1016/j.cogsys.2017.02.005
PG 14
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental
SC Computer Science; Neurosciences & Neurology; Psychology
GA FL4WU
UT WOS:000414233000007
DA 2019-03-21
ER

PT J
AU Bertram, J
AF Bertram, Jutta
TI 300 Keywords Information Ethics. Basic knowledge of Computer-, Network
   and New-Media-Ethics as well as Machine Ethics
SO INFORMATION-WISSENSCHAFT UND PRAXIS
LA German
DT Book Review
EM jutta.bertram@fh-hannover.de
CR Bendel O, 2016, 300 KEYWORDS INFORMA
   Heesen Jessica, 2016, HDB MEDIEN INFORMATI
NR 2
TC 0
Z9 0
U1 1
U2 2
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 1434-4653
EI 1619-4292
J9 INFORM-WISS PRAX
JI Inform.-Wiss. Prax.
PD OCT
PY 2017
VL 68
IS 5-6
SI SI
BP 383
EP 384
PG 2
WC Computer Science, Information Systems; Information Science & Library
   Science
SC Computer Science; Information Science & Library Science
GA FM3UX
UT WOS:000414935800010
DA 2019-03-21
ER

PT J
AU Bein, T
   Brodie, D
AF Bein, Thomas
   Brodie, Daniel
TI Understanding ethical decisions for patients on extracorporeal life
   support
SO INTENSIVE CARE MEDICINE
LA English
DT Editorial Material
ID INTENSIVE-CARE-UNIT; ADULTS
C1 [Bein, Thomas] Univ Hosp Regensburg, Dept Anesthesia & Operat Intens Care, D-93042 Regensburg, Germany.
   [Brodie, Daniel] Columbia Univ, Coll Phys & Surg, Div Pulm Allergy & Crit Care Med, New York Presbyterian Hosp, New York, NY USA.
RP Bein, T (reprint author), Univ Hosp Regensburg, Dept Anesthesia & Operat Intens Care, D-93042 Regensburg, Germany.
EM thomas.bein@ukr.de
CR Bein T, 2015, INTENS CARE MED, V41, P1714, DOI 10.1007/s00134-015-3696-2
   Berning JN, 2016, ANN AM THORAC SOC, V13, P1333, DOI 10.1513/AnnalsATS.201512-831OC
   Combes A, 2014, AM J RESP CRIT CARE, V190, P488, DOI 10.1164/rccm.201404-0630CP
   Cypel M, 2017, J THORAC CARDIOV SUR, V153, pE67, DOI 10.1016/j.jtcvs.2016.11.031
   Dingfield LE, 2017, CHEST, V151, P1387, DOI 10.1016/j.chest.2017.02.024
   Doorenbos AZ, 2013, J PALLIAT MED, V16, P492, DOI 10.1089/jpm.2012.0536
   Ha TS, 2017, EMERG MED J, V34, P107, DOI 10.1136/emermed-2015-204817
   Howe Edmund G, 2016, J Clin Ethics, V27, P267
   Karagiannidis C, 2016, INTENS CARE MED, V42, P889, DOI 10.1007/s00134-016-4273-z
   Meltzer Ellen C, 2016, J Clin Ethics, V27, P281
   Ramanathan K, 2015, J CARDIOTHOR VASC AN, V29, P229, DOI 10.1053/j.jvca.2014.07.015
   Riggs KR, 2015, RESUSCITATION, V91, P73, DOI 10.1016/j.resuscitation.2015.03.021
   Romano ME, 2009, MAYO CLIN PROC, V84, P581, DOI 10.1016/S0025-6196(11)60746-5
NR 13
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0342-4642
EI 1432-1238
J9 INTENS CARE MED
JI Intensive Care Med.
PD OCT
PY 2017
VL 43
IS 10
BP 1510
EP 1511
DI 10.1007/s00134-017-4781-5
PG 2
WC Critical Care Medicine
SC General & Internal Medicine
GA FH9GA
UT WOS:000411517800011
PM 28349177
OA Green Published, Other Gold
DA 2019-03-21
ER

PT J
AU Sadeghi, AR
AF Sadeghi, Ahmad-Reza
TI AI Industrial Complex: The Challenge of AI Ethics
SO IEEE SECURITY & PRIVACY
LA English
DT Editorial Material
CR [Anonymous], 2017, ETH COMM AUT CONN DR
   Cooper D., 2017, ENGADGET
   Future of Life Institute, 2015, AUT WEAP OP LETT AI
   Gibbs Samuel, 2017, GUARDIAN
   Griffin A., 2015, INDEPENDENT
   Loizos Connie, 2017, TECHCRUNCH
   Solon Olivia, 2017, GUARDIAN
   Sulleyman Aatif, 2017, INDEPENDENT
NR 8
TC 0
Z9 0
U1 3
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1540-7993
EI 1558-4046
J9 IEEE SECUR PRIV
JI IEEE Secur. Priv.
PD SEP-OCT
PY 2017
VL 15
IS 5
SI SI
BP 3
EP 5
PG 3
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
SC Computer Science
GA FJ0VR
UT WOS:000412429400001
DA 2019-03-21
ER

PT J
AU Sparrow, R
   Howard, M
AF Sparrow, Robert
   Howard, Mark
TI When human beings are like drunk robots: Driverless vehicles, ethics,
   and the future of transport
SO TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES
LA English
DT Article
DE Autonomous cars; Driverless vehicles; Ethics; Urban planning; Safety;
   Transport policy
ID ACCIDENT RISK; BEHAVIOR; SYSTEM; CARS
AB It is often argued that driverless vehicles will save lives. In this paper, we treat the ethical case for driverless vehicles seriously and show that it has radical implications for the future of transport. After briefly discussing the current state of driverless vehicle technology, we suggest that systems that rely upon human supervision are likely to be dangerous when used by ordinary people in real-world driving conditions and are unlikely to satisfy the desires of consumers. We then argue that the invention of fully autonomous vehicles that pose a lower risk to third parties than human drivers will establish a compelling case against the moral permissibility of manual driving. As long as driverless vehicles aren't safer than human drivers, it will be unethical to sell them. Once they are safer than human drivers when it comes to risks to 3rd parties, then it should be illegal to drive them: at that point human drivers will be the moral equivalent of drunk robots. We also describe two plausible mechanisms whereby this ethical argument may generate political pressure to have it reflected in legislation. Freeing people from the necessity of driving, though, will transform the relationship people have with their cars, which will in turn open up new possibilities for the transport uses of the automobile. The ethical challenge posed by driverless vehicles for transport policy is therefore to ensure that the most socially and environmentally beneficial of these possibilities is realised. We highlight several key policy choices that will determine how likely it is that this challenge will be met. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Sparrow, Robert; Howard, Mark] Monash Univ, Dept Philosophy, Clayton, Vic 3800, Australia.
RP Sparrow, R (reprint author), Monash Univ, Dept Philosophy, Clayton, Vic 3800, Australia.
EM robert.sparrow@monash.edu
CR Ackerman E., 2014, IEEE SPECTRUM, V11
   American Law Institute, 1998, REST 3 TORTS PROD LI
   Anderson JM, 2016, AUTONOMOUS VEHICLE T
   Bamonte T., 2013, TRANSP MANAGE ENG
   Bates J., 2012, SPACED OUT PERSPECTI
   Bhuiyan J., 2016, RECODE
   Bilger B., 2013, NEW YORKER
   Borland R, 2006, TOBACCO CONTROL S3, V15, piii34
   Burns LD, 2013, NATURE, V497, P181, DOI 10.1038/497181a
   Chakraborty J, 2009, ANN ASSOC AM GEOGR, V99, P674, DOI 10.1080/00045600903066490
   Conliffe J., 2016, MIT TECHNOL REV
   Department for Transport, 2015, BRIT SOC ATT SURV 20
   European Automobile Manufacturers Association, 2016, AV VEH AG
   Fagnant D. J., 2015, TRANSP RES BOARD 94
   Fagnant DJ, 2015, TRANSPORT RES A-POL, V77, P167, DOI 10.1016/j.tra.2015.04.003
   Fagnant DJ, 2014, TRANSPORT RES C-EMER, V40, P1, DOI 10.1016/j.trc.2013.12.001
   Ferreras LE., 2013, 3 INT C URB PUBL TRA, P405
   Gao P, 2014, MATH PROBL ENG, DOI 10.1155/2014/109892
   Garza AP, 2011, NEW ENGL LAW REV, V46, P581
   Gold C., 2013, P HUM FACT ERG SOC A, V57, P1938, DOI DOI 10.1177/1541931213571433
   Goodall NJ, 2014, LECT N MOBIL, P93, DOI 10.1007/978-3-319-05990-7_9
   Goodall NJ, 2014, TRANSPORT RES REC, P58, DOI 10.3141/2424-07
   Goodin Robert, 1995, UTILITARIANISM PUBLI
   Gordon TJ, 2015, VEHICLE SYST DYN, V53, P958, DOI 10.1080/00423114.2015.1037774
   Guerra E, 2016, J PLAN EDUC RES, V36, P210, DOI 10.1177/0739456X15613591
   Harper CD, 2016, TRANSPORT RES C-EMER, V72, P1, DOI 10.1016/j.trc.2016.09.003
   Harper CD, 2016, ACCIDENT ANAL PREV, V95, P104, DOI 10.1016/j.aap.2016.06.017
   IHS Markit, 2014, AV AG VEH ROAD REM S
   Joint Standing Committee on Road Safety, 2016, DRIV VEH ROAD SAF NS
   JONAH BA, 1986, ACCIDENT ANAL PREV, V18, P255, DOI 10.1016/0001-4575(86)90041-2
   Kim JS, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2013), P851, DOI 10.1109/ICCAS.2013.6704032
   Kirkpatrick K, 2015, COMMUN ACM, V58, P19, DOI 10.1145/2788477
   Kunzli N, 2000, LANCET, V356, P795, DOI 10.1016/S0140-6736(00)02653-2
   Lambert F., 2016, TESLA WILL SOON INTR
   Levin MW, 2016, TRANSPORT RES A-POL, V90, P14, DOI 10.1016/j.tra.2016.05.013
   Levin MW, 2015, TRANSPORT RES REC, P35, DOI 10.3141/2497-04
   Lin P., 2015, AUTONOMES FAHREN, P69
   Litman T., 2015, AUTONOMOUS VEHICLE I
   Marchant G. E., 2012, SANTA CLARA LAW REV, V52, P1321
   Merat  N., 2009, P INT DRIV S HUM FAC, P514
   Mitchell W. J, 2007, UOC PAPERS, P3
   National Highway Traffic Safety Administration, 2011, Ann Emerg Med, V57, P405
   National Highway Traffic Safety Administration, 2008, NAT MOT VEH CRASH CA, P811
   National Highway Traffic Safety Administration and others, 2016, 812329 DOT HS NAT HI, V812, P329
   NOLAND RB, 1995, ACCIDENT ANAL PREV, V27, P503, DOI 10.1016/0001-4575(94)00087-3
   Ohnsman A., 2014, BLOOMBERG TECHNOLOGY
   Radlmayr J., 2014, P HUMAN FACTORS ERGO, V58, P2063, DOI DOI 10.1177/1541931214581434
   Rawls J., 1971, THEORY JUSTICE
   Richtel M., 2015, NY TIMES
   Shladover SE, 2016, SCI AM, V314, P53, DOI 10.1038/scientificamerican0616-52
   Shladover SE, 2012, TRANSPORT RES REC, P63, DOI 10.3141/2324-08
   Singhvi Anjali, 2016, NY TIMES
   Sivak M., 2015, ROAD SAFETY SELF DRI
   Summala H, 1996, SAFETY SCI, V22, P103, DOI 10.1016/0925-7535(96)00009-4
   Tesla, 2016, TESL PRESS INF AUT
   Thrun S., 2010, WHAT WERE DRIVING AT
   Villasenor J., 2014, PRODUCTS LIABILITY D
   Vlasiv B., 2016, NY TIMES
   Wakabayashi D., 2016, NY TIMES
   WILLIAMS BERNARD, 1973, UTILITARIANISM, p[75, 112]
   World Health Organization, 2015, GLOB STAT REP ROAD S
   Zohdy IH, 2016, J INTELL TRANSPORT S, V20, P17, DOI 10.1080/15472450.2014.889918
NR 62
TC 11
Z9 12
U1 16
U2 108
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0968-090X
J9 TRANSPORT RES C-EMER
JI Transp. Res. Pt. C-Emerg. Technol.
PD JUL
PY 2017
VL 80
BP 206
EP 215
DI 10.1016/j.trc.2017.04.014
PG 10
WC Transportation Science & Technology
SC Transportation
GA EY5AO
UT WOS:000403989800011
DA 2019-03-21
ER

PT J
AU Hagendorff, T
AF Hagendorff, Thilo
TI Animal Rights and Robot Ethics
SO INTERNATIONAL JOURNAL OF TECHNOETHICS
LA English
DT Article
DE Animal Rights; Anthropocentrism; Carnism; Compassion; Robot Ethics
AB This paper investigates challenges which anthropocentric and pathocentric ethics have to face when confronted with moral considerations about non-human animals, especially so-called disenhanced animals, and a new class of technological artifacts, namely social robots. Referring to the case of animal welfare, robot ethics emerges as a new discipline that has not yet reflected on the ideological biases that commonly underlie moral judgments toward animals and find expression in robot ethics, too. As a consequence, robot ethics perpetuates the "work of purification," that is, the isolation and definition of a particular entity possessing a moral status. Whenever such an entity is defined, the definition excludes all those entities which could likewise possess a moral status but do not fit exactly to the pre-specified definition. The crucial question, then, is whether to seek an ethic of unconditional compassion that doesn't allow itself to be restricted by ideology and is therefore convenient for animal rights and robot ethics as well.
C1 [Hagendorff, Thilo] Univ Tubingen, Tubingen, Germany.
RP Hagendorff, T (reprint author), Univ Tubingen, Tubingen, Germany.
CR Adams C., 2014, CRITICAL ANIMAL STUD, P18
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   Ascione F. R., 2001, ANIMAL ABUSE YOUTH V, DOI [10.1037/e304142003-001, DOI 10.1037/E304142003-001]
   Asimov I., 2004, I ROBOT
   Bekoff Marc, 2009, WILD JUSTICE MORAL L, DOI [10.7208/chicago/9780226041667.001.0001, DOI 10.7208/CHICAGO/9780226041667.001.0001]
   Bentham J., 1838, WORKS J BENTHAM PUBL, V1
   BOAT BW, 1995, J INTERPERS VIOLENCE, V10, P229, DOI 10.1177/0886260595010002008
   Brauer J., 2014, KLUGER ALS WIR DENKE
   Calverley DJ, 2006, CONNECT SCI, V18, P403, DOI 10.1080/09540090600879711
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P209, DOI 10.1007/s10676-010-9235-5
   Darling K, 2016, ROBOT LAW, P213, DOI DOI 10.4337/9781783476732.00017
   Donovan Josephine, 1996, J SOCIAL PHILOS, V27, P81, DOI DOI 10.1111/J.1467-9833.1996.TB00228.X
   Ferrari A, 2012, NANOETHICS, V6, P65, DOI 10.1007/s11569-012-0139-1
   Freeman C. P, 2010, ARGUMENTS ANIMAL ETH, P11
   Fuchs P., 2002, GEPFEFFERTE FERKEL
   Hayles Katherine, 1999, WE BECAME POSTHUMAN, DOI [10.7208/chicago/9780226321394.001.0001, DOI 10.7208/CHICAGO/9780226321394.001.0001]
   HUFFMAN MA, 1989, PRIMATES, V30, P51, DOI 10.1007/BF02381210
   Joy M, 2005, J HUMANIST PSYCHOL, V45, P106, DOI 10.1177/0022167804272628
   Joy M., 2002, THESIS
   Joy M., 2011, WHY WE LOVE DOGS EAT
   Kant I., 1977, KANTS WERKE AKAD TEX, V1
   KELLERT SR, 1985, HUM RELAT, V38, P1113, DOI 10.1177/001872678503801202
   Kurzweil R., 2005, SINGULARITY IS NEAR
   Kurzweil Ray, 2012, CREATE MIND SECRET H
   Latour B., 2005, REASSEMBLING SOCIAL
   Latour B., 2012, WE HAVE NEVER BEEN M
   Laux Henning, 2011, AKTEUR INDIVIDUUM SU, P275, DOI DOI 10.1007/978-3-531-93463-1_13
   MacDonald L., 2002, BIOTECHNOLOGY MARGIN
   Macho T., 2013, TIERE MENSCH SEINE N, P153
   Nagenborg M, 2008, AI SOC, V22, P349, DOI 10.1007/s00146-007-0153-y
   Palmer C, 2011, NANOETHICS, V5, P43, DOI DOI 10.1007/S11569-011-0115-1
   PATTERSON F, 1978, NATL GEOGR, V154, P438
   Peggs K, 2012, PALG MAC ANIM ETHICS, P1, DOI 10.1057/9780230377271
   Regan T, 2004, CASE ANIMAL RIGHTS
   Regan T., 2003, ANIMAL RIGHTS HUMAN
   ROLLIN BE, 1998, UNHEEDED CRY ANIMAL
   Rosenthal-von der Putten AM, 2013, INT J SOC ROBOT, V5, P17, DOI 10.1007/s12369-012-0173-8
   Rosenthal-von der Putten A. M., 2012, 8 ACM IEEE INT C HUM
   Singer Peter, 1975, ANIMAL LIBERATION
   Thompson P., 2008, NANOETHICS, V2, P305, DOI DOI 10.1007/S11569-008-0052-9
   Thompson PB, 1997, J AGR ENVIRON ETHIC, V10, P1, DOI 10.1023/A:1007758700818
   Turkle S., 2011, ALONE TOGETHER WHY W
   Waal F., 2009, AGE EMPATHY NATURES
   Wallach W., 2009, MORAL MACHINES TEACH, DOI [10.1093/acprof.oso/9780195374049.001.0001, DOI 10.1093/ACPROF:OSO/9780195374049.001.0001]
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8
   Whitby B, 2008, INTERACT COMPUT, V20, P326, DOI 10.1016/j.intcom.2008.02.002
NR 46
TC 1
Z9 1
U1 4
U2 13
PU IGI GLOBAL
PI HERSHEY
PA 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA
SN 1947-3451
EI 1947-346X
J9 INT J TECHNOETHICS
JI Int. J. Technoethics
PD JUL-DEC
PY 2017
VL 8
IS 2
BP 61
EP 71
DI 10.4018/IJT.2017070105
PG 11
WC Ethics
SC Social Sciences - Other Topics
GA EX9KF
UT WOS:000403576200005
DA 2019-03-21
ER

PT J
AU Miller, K
AF Miller, Keith
TI Can We Program Ethics into AI?
SO IEEE TECHNOLOGY AND SOCIETY MAGAZINE
LA English
DT Editorial Material
NR 0
TC 1
Z9 1
U1 2
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0097
EI 1937-416X
J9 IEEE TECHNOL SOC MAG
JI IEEE Technol. Soc. Mag.
PD JUN
PY 2017
VL 36
IS 2
BP 29
EP 30
DI 10.1109/MTS.2017.2697085
PG 2
WC Engineering, Electrical & Electronic
SC Engineering
GA EY2RW
UT WOS:000403818500009
DA 2019-03-21
ER

PT J
AU Arnold, T
   Scheutz, M
AF Arnold, Thomas
   Scheutz, Matthias
TI The Tactile Ethics of Soft Robotics: Designing Wisely for Human-Robot
   Interaction
SO SOFT ROBOTICS
LA English
DT Review
DE tactile human-robot interaction; ethical challenges; designs of soft
   robots
ID TOUCH
AB Soft robots promise an exciting design trajectory in the field of robotics and human-robot interaction (HRI), promising more adaptive, resilient movement within environments as well as a safer, more sensitive interface for the objects or agents the robot encounters. In particular, tactile HRI is a critical dimension for designers to consider, especially given the onrush of assistive and companion robots into our society. In this article, we propose to surface an important set of ethical challenges for the field of soft robotics to meet. Tactile HRI strongly suggests that soft-bodied robots balance tactile engagement against emotional manipulation, model intimacy on the bonding with a tool not with a person, and deflect users from personally and socially destructive behavior the soft bodies and surfaces could normally entice.
C1 [Arnold, Thomas; Scheutz, Matthias] Tufts Univ, Dept Comp Sci, Human Robot Interact Lab, 200 Boston Ave, Medford, MA 02155 USA.
RP Scheutz, M (reprint author), Tufts Univ, Dept Comp Sci, Human Robot Interact Lab, 200 Boston Ave, Medford, MA 02155 USA.
EM matthias.scheutz@tufts.edu
CR Ackerman JM, 2010, SCIENCE, V328, P1712, DOI 10.1126/science.1189993
   Aragon OR, 2015, PSYCHOL SCI, V26, P259, DOI 10.1177/0956797614561044
   Argall BD, 2010, ROBOT AUTON SYST, V58, P1159, DOI 10.1016/j.robot.2010.07.002
   Bourgeois KS, 2005, INFANCY, V8, P233, DOI 10.1207/s15327078in0803_3
   BUSHNELL EW, 1991, PSYCHOL TOUCH, P139
   Cabibihan JJ, 2009, INT J SOC ROBOT, V1, P29, DOI 10.1007/s12369-008-0008-9
   Delong M, 2012, TEXTILE, V10, P44, DOI 10.2752/175183512X13267336595278
   Devlin K, 2015, DEFENCE SEX MACHINE
   Dunbar RIM, 2010, NEUROSCI BIOBEHAV R, V34, P260, DOI 10.1016/j.neubiorev.2008.07.001
   GEMPERLE F, 2003, P 2003 C DES US EXP, P1
   Hertenstein MJ, 2006, GENET SOC GEN PSYCH, V132, P5, DOI 10.3200/MONO.132.1.5-94
   Horton H, 2015, 2050 HUMAN ON ROBTO
   Li J, 2016, P ANN C INT COMM ASS, P9
   Liu M, 2016, KNIGHTSCOPE ISSUES R
   Lott-Lavigna R, 2016, PEPPER ROBOTS CONTRA
   Moraiti A., 2015, P 9 INT C TANG EMB E, P387
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Neppalli S, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, DOI 10.1109/IROS.2007.4399146
   Nie JQ, 2012, ACMIEEE INT CONF HUM, P201
   Richardson K., 2016, ACM SIGCAS COMPUTERS, V45, P290, DOI DOI 10.1145/2874239.2874281
   Robins B, 2010, 2010 IEEE RO-MAN, P704, DOI 10.1109/ROMAN.2010.5598641
   Saygin AP, 2012, SOC COGN AFFECT NEUR, V7, P413, DOI 10.1093/scan/nsr025
   SCHEUTZ M, 2016, ACMIEEE INT CONF HUM, P351
   Scheutz M, 2017, ROBOT SEX SOCIAL ETH
   Scheutz M, 2012, INTELL ROBOT AUTON, P205
   Silvera-Tawil D, 2015, ROBOT AUTON SYST, V63, P230, DOI 10.1016/j.robot.2014.09.008
   Stiehl W. D., 2006, ACM SIGGRAPH 2006 EM, P15
   Stiehl WD, 2005, ROB HUM INT COMM 200, P408, DOI DOI 10.1109/ROMAN.2005.1513813
   Taichi T, 2006 6 IEEE RAS INT, P490
   Trimmer B.A., 2006, 7 INT S TECHN MIN PR, V1, P1
   Turkle S., 2015, RECLAIMING CONVERSAT
   Wada K, 2010, 2010 IEEE RO-MAN, P533, DOI 10.1109/ROMAN.2010.5598615
   Williams LE, 2008, SCIENCE, V322, P606, DOI 10.1126/science.1162548
   Yohanan S, 2012, INT J SOC ROBOT, V4, P163, DOI 10.1007/s12369-011-0126-7
NR 34
TC 1
Z9 1
U1 4
U2 55
PU MARY ANN LIEBERT, INC
PI NEW ROCHELLE
PA 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA
SN 2169-5172
EI 2169-5180
J9 SOFT ROBOT
JI Soft Robot.
PD JUN
PY 2017
VL 4
IS 2
BP 81
EP 87
DI 10.1089/soro.2017.0032
PG 7
WC Robotics
SC Robotics
GA EW7RD
UT WOS:000402711000001
PM 29182090
OA Bronze
DA 2019-03-21
ER

PT J
AU Lumbreras, S
AF Lumbreras, Sara
TI The Limits of Machine Ethics
SO RELIGIONS
LA English
DT Article
DE ethics of machines; theory of mind; values; learning automata
ID SELF
AB Machine Ethics has established itself as a new discipline that studies how to endow autonomous devices with ethical behavior. This paper provides a general framework for classifying the different approaches that are currently being explored in the field of machine ethics and introduces considerations that are missing from the current debate. In particular, law-based codes implemented as external filters for action-which we have named filtered decision making-are proposed as the basis for future developments. The emergence of values as guides for action is discussed, and personal language - together with subjectivity-are indicated as necessary conditions for this development. Last, utilitarian approaches are studied and the importance of objective expression as a requisite for their implementation is stressed. Only values expressed by the programmer in a public language-that is, separate of subjective considerations-can be evolved in a learning machine, therefore establishing the limits of present-day machine ethics.
C1 [Lumbreras, Sara] Univ Pontificia Comillas, Inst Res Technol, Madrid 28001, Spain.
RP Lumbreras, S (reprint author), Univ Pontificia Comillas, Inst Res Technol, Madrid 28001, Spain.
EM slumbreras@comillas.edu
OI Lumbreras, Sara/0000-0002-5506-9027
CR Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4
   Arkin R., 2009, GOVERNING LETHAL BEH
   Asimov I., 1950, I ROBOT
   Avraham Ronen, 2012, UNDERSTANDING INSURA
   Campbell RL, 2002, THEOR PSYCHOL, V12, P795, DOI 10.1177/0959354302126004
   Casey Bryan James, 2017, AMORAL MACHINES ROBO
   Danielson P., 1998, MODELING RATIONALITY
   Floridi Luciano, 2005, ACM SIGCAS COMPUTERS, V35, P3
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872
   Handelsman MM, 2009, OXFORD HDB POSITIVE, P105, DOI DOI 10.1093/OXFORDHB/9780195187243.013.0011
   Hardy SA, 2011, CHILD DEV PERSPECT, V5, P212, DOI 10.1111/j.1750-8606.2011.00189.x
   Head Simon, 2014, MINDLESS WHY SMARTER
   Honderich T., 2005, OXFORD COMPANION PHI
   Howard R. A., 2008, ETHICS REAL WORLD CR
   International Federation of Robotics (IFR), 2016, WORLD ROB 2016
   JACKSON F, 1991, ETHICS, V101, P461, DOI 10.1086/293312
   Kahneman D., 2011, THINKING FAST SLOW
   Kant I., 2004, CRITIQUE PRACTICAL R
   Kuipers B, 2008, ARTIF INTELL MED, V44, P155, DOI 10.1016/j.artmed.2008.07.010
   Kurzweil Ray, 2012, CREATE MIND SECRET H
   Lapsley D. K, 2006, HDB CHILD PSYCHOL
   Leach Javier, 2011, MATH RELIG OUR LANGU
   Lichtenberg J, 2010, ETHICS, V120, P557, DOI 10.1086/652294
   Luxton DD, 2014, ARTIF INTELL MED, V62, P1, DOI 10.1016/j.artmed.2014.06.004
   Martin J, 2004, EDUC PSYCHOL, V39, P135, DOI 10.1207/s15326985ep3902_4
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77
   Rosenbrock H, 1990, MACHINES PURPOSE
   Slote M. A., 1985, COMMON SENSE MORALIT
   Van de Voort M, 2015, ETHICS INF TECHNOL, V17, P41, DOI 10.1007/s10676-015-9360-2
   Veruggio G, 2016, SPRINGER HANDBOOK OF ROBOTICS, P2135
   Wilson E.O., 1975, P1
   Yampolskiy R, 2013, TOPOI-INT REV PHILOS, V32, P217, DOI 10.1007/s11245-012-9128-9
NR 32
TC 1
Z9 1
U1 1
U2 5
PU MDPI AG
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2077-1444
J9 RELIGIONS
JI Religions
PD MAY
PY 2017
VL 8
IS 5
AR 100
DI 10.3390/rel8050100
PG 10
WC Religion
SC Religion
GA FD0LW
UT WOS:000407231800025
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Kowalski, R
AF Kowalski, Robert
TI Programming Machine Ethics by Luis Moniz Pereira and Ari Saptawijaya
SO AI & SOCIETY
LA English
DT Book Review
C1 [Kowalski, Robert] Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2BZ, England.
RP Kowalski, R (reprint author), Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2BZ, England.
EM rak@doc.ic.ac.uk
CR KOWALSKI R, 2017, PROGRAMMING MACHINE
NR 1
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0951-5666
EI 1435-5655
J9 AI SOC
JI AI Soc.
PD MAY
PY 2017
VL 32
IS 2
SI SI
BP 299
EP 300
DI 10.1007/s00146-017-0690-y
PG 2
WC Computer Science, Artificial Intelligence
SC Computer Science
GA EU1OB
UT WOS:000400788600021
OA Other Gold
DA 2019-03-21
ER

PT J
AU Ienca, M
AF Ienca, Marcello
TI COGNITIVE TECHNOLOGY AND HUMAN-MACHINE INTERACTION: THE CONTRIBUTION OF
   EXTERNALISM TO THE THEORETICAL FOUNDATIONS OF MACHINE AND CYBORG ETHICS
SO ANALELE UNIVERSITATII BUCURESTI-FILOSOFIE-ANNALS OF THE UNIVERSITY OF
   BUCHAREST-PHILOSOPHY
LA English
DT Article
DE machine ethics; theoretical foundations; extended cognition; extended
   mind; embodied cognition; externalism; artificial intelligence
ID PERCEPTION; MEMORY
AB Machine ethics is the branch of ethics concerned with the behavior of artificially intelligent systems. Cyborg ethics is the related field of investigation concerned with the ethics of human-machine hybrid systems. While these areas of ethical investigation are experiencing rapid growth urged by disruptive advances in artificial intelligence, robotics and human-machine interaction, yet their theoretical foundations continue to elude consensus among researchers. In fact, most attention in machine and cyborg ethics has been devoted to normative and applied ethical questions concerning the moral status of artificially intelligent systems, the moral permissibility of their application in specific contexts, and the normative principles governing the interaction between artificially intelligent systems and humans. While cyborg ethicists have discussed the ethical implications of integrating man and machines, machine ethicists have long debated on whether artificially intelligent systems have the cognitive capacities necessary for the attribution of moral status. It remains unexplored, however, what theory of cognition is best placed to explain and assess these cognitive capacities or competent actions, especially in relation to human-machine interaction. This contribution aims at harmonizing the theoretical foundations of, respectively, machine and cyborg ethics and argues that an externalist account of cognition based on the notion of extended mind might offer a valid substrate for such harmonization.
C1 [Ienca, Marcello] Univ Basel, Inst Biomed Eth, Basel, Switzerland.
   [Ienca, Marcello] Swiss Fed Inst Technol, Dept Hlth Sci & Technol, Hlth Eth & Policy Lab, Zurich, Switzerland.
RP Ienca, M (reprint author), Univ Basel, Inst Biomed Eth, Basel, Switzerland.; Ienca, M (reprint author), Swiss Fed Inst Technol, Dept Hlth Sci & Technol, Hlth Eth & Policy Lab, Zurich, Switzerland.
EM marcello.ienca@unibas.ch
CR Azevedo FAC, 2009, J COMP NEUROL, V513, P532, DOI 10.1002/cne.21974
   Balcetis E, 2007, PSYCHOL SCI, V18, P917, DOI 10.1111/j.1467-9280.2007.02000.x
   Bekkering H, 2002, PSYCHOL SCI, V13, P370, DOI 10.1111/j.0956-7976.2002.00466.x
   Bentham J., 1823, INTRO PRINCIPLES MOR
   Bickerton D., 2009, ADAMS TONGUE HUMANS
   Block N., 1995, INVITATION COGNITIVE, V3, P377
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032
   Carpenter T. P., 1999, CHILDRENS MATH COGNI
   Carter JA, 2016, J AM PHILOS ASSOC, V2, P542, DOI 10.1017/apa.2016.28
   Chalmers David, 2008, SUPERSIZING MIND
   Chrisley R, 2003, ARTIF INTELL, V149, P131, DOI 10.1016/S0004-3702(03)00055-9
   Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096
   Clark A., 2002, INT J COGNITION TECH, V1, P21, DOI [10.1075/ijct.1.1.03cla, DOI 10.1075/IJCT.1.1.03CLA]
   Clark A., 2008, SUPERSIZING MIND EMB
   Dehaene Stanislas, 1999, NUMBER SENSE
   Dror Itiel E., 2008, COGNITION DISTRIBUTE
   Fernandez-Duque D, 2009, J CLIN EXP NEUROPSYC, V31, P489, DOI 10.1080/13803390802282688
   Fitch Tecumseh, 2011, BIOLINGUISTIC ENTERP
   Forstl H, 1999, EUR ARCH PSY CLIN N, V249, P288, DOI 10.1007/s004060050101
   Gibson J. J., 1966, SENSES CONSIDERED PE
   Gigerenzer G., 2007, GUT FEELINGS INTELLI
   Gigerenzer Gerd, 2011, BOUNDED RATIONALITY
   Ginsburg H. P., 1989, CHILDRENS ARITHMETIC
   Greene J, 2002, TRENDS COGN SCI, V6, P517, DOI 10.1016/S1364-6613(02)02011-9
   HAIDT J, 1993, J PERS SOC PSYCHOL, V65, P613, DOI 10.1037//0022-3514.65.4.613
   Herculano-Houzel S, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.031.2009
   HUTCHINS E., 1995, COGNITION WILD
   Ienca M, 2017, J ALZHEIMERS DIS, V56, P1301, DOI 10.3233/JAD-161037
   Ienca M, 2016, INT J SOC ROBOT, V8, P565, DOI 10.1007/s12369-016-0366-7
   Immanuel Kant, 2002, CRITIQUE PRACTICAL R
   Jennings L., 2011, NEW PERSPECTIVES EVO, P169
   KIRSH D, 1994, COGNITIVE SCI, V18, P513, DOI 10.1016/0364-0213(94)90007-8
   Lakoff G., 1980, METAPHORS WE LIVE BY
   Mace William M., 1977, PERCEIVING ACTING KN, P32
   McClelland JL, 1989, PARALLEL DISTRIBUTED, P8
   McMahan J, 2002, ETHICS KILLING PROBL
   Morowitz Harold J., 1999, Complexity, V4, P39
   Niedenthal PM, 2005, PERS SOC PSYCHOL REV, V9, P184, DOI 10.1207/s15327957pspr0903_1
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Olmstead AJ, 2009, Q J EXP PSYCHOL, V62, P2409, DOI 10.1080/17470210902846765
   Pfeifer R., 2007, BODY SHAPES WAY WE T
   Provins KA, 1997, PSYCHOL REV, V104, P554, DOI 10.1037/0033-295X.104.3.554
   QUINN W, 1984, PHILOS PUBLIC AFF, V13, P24
   Rowlands M., 2003, EXTERNALISM PUTTING
   Rowlands M., 2010, NEW SCI MIND EXTENDE
   Scott CL, 2001, DISCOURSE PROCESS, V31, P293, DOI 10.1207/S15326950dp31-3_4
   Singer Peter, 1993, PRACTICAL ETHICS
   Sparrow B, 2011, SCIENCE, V333, P776, DOI 10.1126/science.1207745
   Steels Luc, 2003, ARTIFICIAL LIFE ROUT
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23
   Torrance S., 2011, MACHINE ETHICS, P115
   Von Frisch K., 1956, BEES THEIR VISION CH
   von Frisch K, 1967, DANCE LANGUAGE ORIEN
   Wilson R. A., 2011, STANFORD ENCY PHILOS
NR 55
TC 0
Z9 0
U1 2
U2 2
PU EDITURA UNIV BUCURESTI
PI BUCHAREST
PA SOSEAUA PANDURI 90-92, SECTOR 5, BUCHAREST, 00000, ROMANIA
SN 0068-3175
EI 2537-4044
J9 AN U BUCUR-FILOSOFI
JI An. Univ. Bucur.-Filos.
PY 2017
VL 66
IS 2
BP 91
EP 115
PG 25
WC Philosophy
SC Philosophy
GA GI0AB
UT WOS:000434030400006
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Balistreri, M
AF Balistreri, Maurizio
TI ROBOT KILLER. ROBOTIC REVOLUTION IN THE WAR AND MORAL QUESTIONS
SO ETICA & POLITICA
LA Italian
DT Article
DE Robot; killing; military ethics; human integrity
AB Almost all of the robotic weapons used today in war or in military missions require a human operator to make key decisions: they are unmanned systems. The lethal autonomous weapons systems (the so-called killer robots) are weapons programmed to autonomously select their target and decide whether or not to attack without any meaningful human intervention. These lethal autonomous weapons do not yet exist, but the technological developments could afford to produce them incredibly quickly. We describe the main objections advanced against the development and use of these weapons: issues of compliance with international humanitarian law, problems of accountability for fully autonomous weapons, lack of human emotions and empathy, deskilling of the military profession and destabilization of the traditional norms of military virtue and reduction of the war to murder. Behind the most part of these objections to the lethal weapons systems there is the fear that, because of using them, we could irremediably loose our humanity. According to the critics of robot killers, i.e., these are machine whose use in battlefield crosses a fundamental moral line, that we should not overcome if we are still interested in beings humans. We show that these concerns are not justified, because killer robot represent only the last effort of human beings to produce, through technology, tools with which to fight and defeat the enemy.
C1 [Balistreri, Maurizio] Univ Torino, Dipartimento Filosofia & Sci Educ, Turin, Italy.
RP Balistreri, M (reprint author), Univ Torino, Dipartimento Filosofia & Sci Educ, Turin, Italy.
EM maurizio.balistreri@unito.it
CR Amato S, 2014, ETICA POLITICA, V16, P182
   Anderson K., 2013, J PERKINS TASK FORCE, P1
   [Anonymous], 2012, COMMUNICATION
   [Anonymous], 2012, LOS HUM CAS KILL ROB
   Arkin R., 2009, GOVERNING LETHAL BEH, P125
   Bacchi S., 2014, SISTEMA INFORM SCHED, V5, P1
   Balistreri M., 2016, MED STORIA, VXVI, P75
   Balistreri M., 2016, FUTURO RIPRODUZIONE
   Balistreri M., 2015, ETHNICS AND POLITICS, VXII, P127
   Beard Jack M, 2014, GEORGENTOWN J INT LA, V45, P617
   Birnbacher Dieter, 2014, NATURALNESS IS NATUR
   Chamayou G., 2014, TEORIA DRONE PRINCIP, P201
   Crawford N.C., 2014, ACCOUNTABILITY KILLI, P219
   Dennett D. C., 1997, HALS LEGACY 2001S CO, P351
   Douglas T, 2013, BIOETHICS, V27, P160, DOI 10.1111/j.1467-8519.2011.01919.x
   Greco L., 2014, ETICA MED NELLA VITA, p[107, 113]
   Guarini M, 2012, INTELL ROBOT AUTON, P129
   Human Rights Watch and IHRC, 2014, LOS HUM CAS KILL ROB, P5
   Human Rights Watch and IHRC, 2014, LOS HUM CAS KILL ROB, P11
   Human Rights Watch and IHRC, 2012, LOS OF HUM, P15
   Human Rights Watch and IHRC, 2012, LOS HUM CAS KILL ROB, P9
   Human Rights Watch and IHRC, 2014, LOS HUM CAS KILL ROB, P8
   Human Rights Watch and IHRC, 2014, LOS HUM CAS KILL ROB, P6
   Hurka T, 2005, PHILOS PUBLIC AFF, V33, P34, DOI 10.1111/j.1088-4963.2005.00024.x
   International Committee of the Red Cross, 2011, INT HUM LAW CHALL CO
   Krishnan A, 2009, KILLER ROBOTS: LEGALITY AND ETHICALITY OF AUTONOMOUS WEAPONS, P1
   Leveringhaus A., 2016, ETHICS AUTONOMOUS WE, P1
   Lombardi A., 2015, LA REPUBBLICA, P30
   McMahan J, 2004, ETHICS, V114, P693, DOI 10.1086/422400
   MCMAHAN J, 1994, ETHICS, V104, P252, DOI 10.1086/293600
   McMahan J., 1994, J POLIT PHILOS, V2, P193
   NAGEL T, 1972, PHILOS PUBLIC AFF, V1, P123
   Pax, 2014, DEADLY DECISIONS 8 O, P15
   Pax, 2014, LOSING HUMANITY CASE, P9
   Pax, 2014, DEADLY DECISIONS 8 O, P12
   Pax, 2011, DOES UNMANNED MAKE U
   Pax, 2014, DEADLY DECISIONS 8 O, P7
   Pax, 2014, LOSING HUMANITY CASE, P10
   Pax, 2014, DEADLY DECISIONS 8 O, V8, P1
   Pax, 2014, DEADLY DECISIONS 8 O, V8, P18
   Pax, 2014, DEADLY DECISIONS 8 O, V8, P16
   Rossi CJ. Carlos, 2016, GUERRA CHE VERRA AUT, P10
   Rubsaam Alix, CASE KILLER ROBOTS P
   Savulescu J, 2012, UNFIT FUTURE NEED MO
   Sharkey, 2010, J MILITARY ETHICS, V9, P369, DOI DOI 10.1080/15027570.2010.537903
   Sharkey NE, 2012, INT REV RED CROSS, V94, P787, DOI 10.1017/S1816383112000732
   Singer P.W., 2009, WIRED WAR ROBOTICS R, P194
   Sparrow R., 2011, NEW WARS NEW SOLDIER, P117
   Sparrow R, 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X
   Sparrow R, 2016, ETHICS INT AFF, V30, P93, DOI 10.1017/S0892679415000647
   Sparrow R, 2009, IEEE TECHNOL SOC MAG, V28, P25, DOI 10.1109/MTS.2009.931862
   Sparrow Robert, 2013, KILLING REMOTE CONTR, P84
   Tonkens Ryan, 2012, J MILITARY ETHICS, V11, P149, DOI DOI 10.1080/15027570.2012.708265
   UNIDIR, 2015, WEAP INCR TECHN MAR, P1
   Veruggio G., 2015, MONDO DIGITALE, P14
   Victor Daniel, 2015, NY TIMES
   Walker Mark, 2009, Politics Life Sci, V28, P27, DOI 10.2990/28_2_27
NR 57
TC 0
Z9 0
U1 3
U2 21
PU UNIV STUDI TRIESTE, EDIZIONI UNIVERSITA TRIESTE-EUT
PI TRIESTE
PA VIA EDOARDO WEISS 21, TRIESTE, 34128, ITALY
SN 1825-5167
J9 ETICA POLITICA
JI Etica Politica
PY 2017
VL 19
IS 2
BP 405
EP 430
PG 26
WC Philosophy
SC Philosophy
GA FI0KS
UT WOS:000411614800023
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Breakey, H
AF Breakey, Hugh
TI BUILDING ETHICS REGIMES: CAPABILITIES OBSTACLES AND SUPPORTS FOR
   PROFESSIONAL ETHICAL DECISION-MAKING
SO UNIVERSITY OF NEW SOUTH WALES LAW JOURNAL
LA English
DT Article
ID INTEGRITY
C1 [Breakey, Hugh] Griffith Univ, Law Futures Ctr, Nathan, Qld, Australia.
RP Breakey, H (reprint author), Griffith Univ, Law Futures Ctr, Nathan, Qld, Australia.
EM h.breakey@griffith.edu.au
FU Australian Research Council; Professional Standards Councils; Centre for
   Law Markets and Regulation at UNSW Law
FX Research Fellow, Law Futures Centre, Griffith University.
   (Correspondence: h.breakey@griffith.edu.au). I acknowledge the support
   of the Australian Research Council and the Professional Standards
   Councils for this work. I am also grateful for the support of
   professional partners to the grant, law firms Allens and Corrs. I also
   acknowledge the support of the Centre for Law Markets and Regulation at
   UNSW Law for this work.
CR Anthony Kwame, 2010, HONOR CODE MORAL REV, P194
   Aristotle, 2002, NICOMACHEAN ETHICS
   Benjamin Martin, 1990, SPLITTING DIFFERENCE, P36
   Breakey H, 2017, ROUTL CHALLENG GLOB, P203
   Breakey H, 2017, ROUTL CHALLENG GLOB, P72
   Breakey H, 2017, U NSW LAW J, V40, P385
   Breakey H, 2017, U NSW LAW J, V40, P262
   Breakey H, 2016, J VALUE INQUIRY, V50, P613, DOI 10.1007/s10790-016-9541-1
   Breakey H, 2014, RES ETH ISS ORG, V11, P51, DOI 10.1108/S1529-209620140000011003
   Breakey H, 2015, RES ETH ISS ORG, V14, P1, DOI 10.1108/S1529-209620150000014001
   Breakey Hugh, 2017, PHILOS STUD IN PRESS
   Breakey Hugh, 2017, U NEW S WALES LAW RE, V40, P410
   Breakey Hugh, 2016, RES ETHICAL ISSUES O, V1
   Brimble Mark, 2012, AUSTRALASIAN ACCOUNT, V6, P79
   Carper Kenneth L, 1991, J PROFESSIONAL ISSUE, V117, P256
   Carper Kenneth L, 1991, J PROFESSIONAL ISSUE, V117, P250
   DAVIS M, 1991, PHILOS PUBLIC AFF, V20, P150
   Davis Michael, 2005, OXFORD HDB PRACTICAL
   Davis Michael, 1988, GEORGETOWN J LEGAL E, V2, P341
   Davis Michael, 1988, GEORGETOWN J LEGAL E, V2, P353
   Flood John, 2011, CURR SOCIOL, V59, P507
   Frumento Aegis J, 2013, J INVESTMENT COMPLIA, V14, P32
   Gibbs J. C, 2010, MORAL DEV REALITY TH
   GIOIA DA, 1992, J BUS ETHICS, V11, P379, DOI 10.1007/BF00870550
   Grace Damian, 2013, BUSINESS ETHICS, P219
   Haidt J, 2012, RIGHTEOUS MIND WHY G
   Hamilton N., 2011, GEORGETOWN J LEGAL E, V24, P137
   Hamilton Neil, 2011, U ST THOMAS LAW J, V9, P325
   Heath J, 2008, J BUS ETHICS, V83, P595, DOI 10.1007/s10551-007-9641-8
   Heath Joseph, 2008, J BUS ETHICS, V83, P600
   Hobbes T, 2008, LEVIATHAN
   Hume D., 1969, TREATISE HUMAN NATUR
   Hursthouse R, 1999, VIRTUE ETHICS
   Iseda T, 2008, SCI ENG ETHICS, V14, P165, DOI 10.1007/s11948-007-9039-0
   James Colin, 2005, INT J CLIN LEGAL ED, V8, P123
   Kant Immanuel, 1948, MORAL LAW KANTS GROU
   Kelly B, 1998, J ADV NURS, V28, P1134, DOI 10.1046/j.1365-2648.1998.00810.x
   KIPNIS K, 1991, J BUS ETHICS, V10, P569, DOI 10.1007/BF00382874
   Lau D. C., 1979, ANALECTS
   Leicht KT, 2016, J PROF ORGAN, V3, P103, DOI 10.1093/jpo/jov006
   Luban D, 2003, FORDHAM LAW REV, V72, P279
   MacIntyre Alasdair, 1999, PHILOSOPHY, V74, P311
   McGraw David K, 2004, J INFORM COMMUNICATI, V2, P235
   McGraw David K, 2004, J INFORM COMMUNICATI, V2, P239
   Mill John Stuart, 2001, UTILITARIANISM, V29
   Montgomery J. E., 2008, U TOLEDO LAW REV, V39, P323
   Nietzsche Friedrich, 1996, GENEALOGY MORALS
   Preston Noel, 2002, ENCOURAGING ETHICS C, P32
   Provis Chris, 2015, HDB VIRTUE ETHICS BU, P425
   Rest James R, 1994, MORAL DEV PROFESSION, P1
   Rest James R, 1946, HDB CHILD PSYCHOL, V3, P556
   REST JR, 1982, HASTINGS CENT REP, V12, P29, DOI 10.2307/3560621
   Rokeach Milton, 1968, BELIEFS ATTITUDES VA, p[123, 159]
   Rozuel cile, 2011, J BUS ETHICS, V102, P685
   Sampford Charles, 2005, LEGAL ETHICS, V8, P16
   Sampford Charles, 2003, LEGAL ETHICS, V6, P85
   Sampford Charles, 1994, ETHICS PUBLIC SECTOR, P14
   Sanders Deen, 2015, CISC VIS NETW IND GL
   Sanders Deen, 2010, THESIS
   Schwartz MS, 2016, J BUS ETHICS, V139, P755, DOI 10.1007/s10551-015-2886-8
   Silver MA, 1999, PSYCHOL PUBLIC POL L, V5, P1173, DOI 10.1037//1076-8971.5.4.1173
   TREVINO LK, 1986, ACAD MANAGE REV, V11, P601, DOI 10.2307/258313
   Wong D. B., 2009, NATURAL MORALITIES D
   Wueste DE, 2014, RES ETH ISS ORG, V12, P5, DOI 10.1108/S1529-209620140000012001
NR 64
TC 3
Z9 3
U1 2
U2 3
PU UNIV NEW SOUTH WALES, FAC LAW
PI KENSINGTON
PA PO BOX 1, KENSINGTON, NSW 2033, AUSTRALIA
SN 0313-0096
EI 1839-2881
J9 U NSW LAW J
JI Univ. NSW Law J.
PY 2017
VL 40
IS 1
BP 322
EP 352
PG 31
WC Law
SC Government & Law
GA EX6NI
UT WOS:000403358600013
DA 2019-03-21
ER

PT J
AU Sharkey, A
AF Sharkey, Amanda
TI Can robots be responsible moral agents? And why should we care?
SO CONNECTION SCIENCE
LA English
DT Article
DE Robot; moral agent; embodiment
AB This principle highlights the need for humans to accept responsibility for robot behaviour and in that it is commendable. However, it raises further questions about legal and moral responsibility. The issues considered here are (i) the reasons for assuming that humans and not robots are responsible agents, (ii) whether it is sufficient to design robots to comply with existing laws and human rights and (iii) the implications, for robot deployment, of the assumption that robots are not morally responsible.
C1 [Sharkey, Amanda] Univ Sheffield, Dept Comp Sci, Portobello Rd, Sheffield S1 4DP, S Yorkshire, England.
RP Sharkey, A (reprint author), Univ Sheffield, Dept Comp Sci, Portobello Rd, Sheffield S1 4DP, S Yorkshire, England.
EM a.sharkey@shef.ac.uk
CR Arkin R., 2009, COMPUT EDUC, V58, P978
   Asaro PM, 2006, INT REV INF ETHICS, V6, P9
   BEKOFF M., 2009, WILD JUSTICE MORAL L
   Brosnan SF, 2003, NATURE, V425, P297, DOI 10.1038/nature01963
   Churchland P., 2011, BRAINTRUST WHAT NEUR
   Heyns C., 2013, AHRC2347
   Johnson Deborah G, 2008, Ethics and Information Technology, V10, P123, DOI 10.1007/s10676-008-9174-6
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5
   Malle BF, 2014, IEEE INT S ETH ENG S, P30
   Maturana Humberto, 1980, AUTOPOIESIS COGNITIO
   Riedl M. O., 2016, P 2 INT WORKSH AI ET
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   SHARKEY NE, 2001, COGNITIVE SYSTEMS RE, V2, P251, DOI DOI 10.1016/S1389-0417(01)00036-5
   Sharkey N, 2010, INTERACT STUD, V11, P161, DOI 10.1075/is.11.2.o1sha
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23
   Wallach W., 2009, MORAL MACHINES TEACH
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0_8
NR 18
TC 0
Z9 0
U1 1
U2 6
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0954-0091
EI 1360-0494
J9 CONNECT SCI
JI Connect. Sci.
PY 2017
VL 29
IS 3
SI SI
BP 210
EP 216
DI 10.1080/09540091.2017.1313815
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA EW5AR
UT WOS:000402518100004
OA Green Published
DA 2019-03-21
ER

PT J
AU Malle, BF
AF Malle, Bertram F.
TI Integrating robot ethics and machine morality: the study and design of
   moral competence in robots
SO Ethics and Information Technology
LA English
DT Article
DE Social cognition; Moral cognition; Human-robot interaction; Moral
   psychology; Social robotics
ID JUDGMENT; CHILDRENS; PSYCHOLOGY; PUNISHMENT; TODDLERS; EMOTION; BLAME;
   NEED
AB Robot ethics encompasses ethical questions about how humans should design, deploy, and treat robots; machine morality encompasses questions about what moral capacities a robot should have and how these capacities could be computationally implemented. Publications on both of these topics have doubled twice in the past 10 years but have often remained separate from one another. In an attempt to better integrate the two, I offer a framework for what a morally competent robot would look like (normally considered machine morality) and discuss a number of ethical questions about the design, use, and treatment of such moral robots in society (normally considered robot ethics). Instead of searching for a fixed set of criteria of a robot's moral competence I identify the multiple elements that make up human moral competence and probe the possibility of designing robots that have one or more of these human elements, which include: moral vocabulary; a system of norms; moral cognition and affect; moral decision making and action; moral communication. Juxtaposing empirical research, philosophical debates, and computational challenges, this article adopts an optimistic perspective: if robotic design truly commits to building morally competent robots, then those robots could be trustworthy and productive partners, caretakers, educators, and members of the human community. Moral competence does not resolve all ethical concerns over robots in society, but it may be a prerequisite to resolve at least some of them.
C1 [Malle, Bertram F.] Brown Univ, Dept Cognit Linguist & Psychol Sci, 190 Thayer St, Providence, RI 02912 USA.
RP Malle, BF (reprint author), Brown Univ, Dept Cognit Linguist & Psychol Sci, 190 Thayer St, Providence, RI 02912 USA.
EM bfmalle@brown.edu
FU Office of Naval Research (ONR) [N00014-13-1-0269]
FX This project was partially supported by a grant from the Office of Naval
   Research (ONR), No. N00014-13-1-0269. The opinions expressed here are my
   own and do not necessarily reflect the views of ONR. The ideas on moral
   competence featured in this article have been developed jointly with
   Matthias Scheutz, Tufts University.
CR Alicke MD, 2000, PSYCHOL BULL, V126, P556, DOI 10.1037//0033-2909.126.4.556
   Allen C., 2011, NEW YORK TIMES OPINI
   Anderson M., 2011, MACHINE ETHICS
   ANTAKI C, 1994, EXPLAINING ARGUING S
   Arkin R., 2009, GOVERNING LETHAL BEH
   Asaro PM, 2006, INT REV INF ETHICS, V6, P9
   Avramova YR, 2013, WIRES COGN SCI, V4, P169, DOI 10.1002/wcs.1216
   BAUMEISTER RF, 1995, PSYCHOL BULL, V117, P497, DOI 10.1037/0033-2909.117.3.497
   Bello P., 2012, ADV COGNITIVE SYSTEM, V1, P59
   Bicchieri Cristina, 2006, GRAMMAR SOC NATURE D
   Blomkamp N., 2015, CHAPPIE MOTION PICTU
   Brachman RJ, 2002, IEEE INTELL SYST, V17, P67, DOI 10.1109/MIS.2002.1134363
   Breazeal C. L., 2002, DESIGNING SOCIABLE R
   Bringsjord S., 2009, ERWAGEN WISSEN ETHIK, V20, P193
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82
   Calverley DJ, 2006, CONNECT SCI, V18, P403, DOI 10.1080/09540090600879711
   Coates D. J, 2012, BLAME ITS NATURE NOR, P3, DOI 10.1093/acprof:oso/9780199860821.003.0001
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P209, DOI 10.1007/s10676-010-9235-5
   Cox M., 2011, METAREASONING, P131
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   Cushman F, 2008, COGNITION, V108, P353, DOI 10.1016/j.cognition.2008.03.006
   Cushman F, 2011, COGNITIVE SCI, V35, P1052, DOI 10.1111/j.1551-6709.2010.01167.x
   DeBaets A., 2014, J EVOLUTION TECHNOLO, V24, P76
   Dersley I, 2000, RES LANG SOC INTERAC, V33, P375, DOI 10.1207/S15327973RLSI3304_02
   Eisenberg N, 2000, ANNU REV PSYCHOL, V51, P665, DOI 10.1146/annurev.psych.51.1.665
   Emde R. N., 1992, SOCIAL REFERENCING S, P79
   Fehr E, 2004, EVOL HUM BEHAV, V25, P63, DOI 10.1016/S1090-5138(04)00005-4
   Fisher M., 2014, EXTANT TELEVISION SE
   Fiske S. T., 2008, SOCIAL COGNITION BRA
   Flack JC, 2000, J CONSCIOUSNESS STUD, V7, P1
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   FORD K, 1991, REASONING AGENTS DYN
   Fridin M, 2014, COMPUT HUM BEHAV, V30, P262, DOI 10.1016/j.chb.2013.09.005
   Garcia E, 2007, IEEE ROBOT AUTOM MAG, V14, P90, DOI 10.1109/MRA.2007.339608
   Gilovich T., 2013, SOCIAL PSYCHOL
   Grau Christopher, 2011, MACHINE ETHICS, P451
   Gray K, 2012, PSYCHOL INQ, V23, P101, DOI 10.1080/1047840X.2012.651387
   Greene JD, 2004, NEURON, V44, P389, DOI 10.1016/j.neuron.2004.09.027
   Guglielmo S, 2009, INQUIRY, V52, P449, DOI 10.1080/00201740903302600
   Gunkel DJ, 2014, PHILOS TECHNOL, V27, P113, DOI DOI 10.1007/S13347-013-0121-Z
   Haidt J, 2001, PSYCHOL REV, V108, P814, DOI 10.1037//0033-295X.108.4.814
   Hamlin JK, 2013, CURR DIR PSYCHOL SCI, V22, P186, DOI 10.1177/0963721412470687
   Harenski CL, 2010, J ABNORM PSYCHOL, V119, P863, DOI 10.1037/a0020979
   Heath J, 2001, COMMUNICATIVE ACTION
   Hilton D., 2007, SOCIAL PSYCHOL HDB B, P232
   Hoffman M. L., 2008, HDB EMOTIONS, V3, P440
   Hofmann B, 2013, SCI ENG ETHICS, V19, P389, DOI 10.1007/s11948-011-9348-1
   Huebner B, 2009, TRENDS COGN SCI, V13, P1, DOI 10.1016/j.tics.2008.09.006
   Hutcherson CA, 2011, J PERS SOC PSYCHOL, V100, P719, DOI 10.1037/a0022408
   Johnson AM, 2013, J MIL ETH, V12, P129, DOI DOI 10.1080/15027570.2013.818399
   Kahn Jr P. H., 2012, P 7 ANN ACM IEEE INT, P33, DOI [DOI 10.1145/2157689.2157696, 10.1145/2157689.2157696]
   Kibble R., 2012, MACHINE QUESTION AI, P62
   Knobe J., 2008, MORAL PSYCHOL, P441
   Knobe J, 2010, BEHAV BRAIN SCI, V33, P315, DOI 10.1017/S0140525X10000907
   Kohlberg L., 1984, PSYCHOL MORAL DEV NA
   Lin P, 2012, INTELL ROBOT AUTON, P1
   LIN P., 2013, ATLANTIC
   Littman M. L., 2001, Cognitive Systems Research, V2, P55, DOI 10.1016/S1389-0417(01)00015-8
   Lomas M., 2012, P 7 ACM IEEE INT C H, P187
   Luo QA, 2006, NEUROIMAGE, V30, P1449, DOI 10.1016/j.ncuroimage.2005.11.005
   Malle B F, 1999, Pers Soc Psychol Rev, V3, P23, DOI 10.1207/s15327957pspr0301_2
   Malle B. F., 2007, ENCY SOCIAL PSYCHOL
   Malle B. F., 2014, IEEE INT S ETH ENG S, P30
   Malle BF, 2015, ACMIEEE INT CONF HUM, P117, DOI 10.1145/2696454.2696458
   Malle BF, 2014, PSYCHOL INQ, V25, P147, DOI 10.1080/1047840X.2014.877340
   Malle BF, 2011, ADV EXP SOC PSYCHOL, V44, P297, DOI 10.1016/B978-0-12-385522-0.00006-8
   Malle BF, 2004, MIND EXPLAINS BEHAV
   McCullough ME, 2013, BEHAV BRAIN SCI, V36, P1, DOI 10.1017/S0140525X11002160
   McKenna M., 2012, BLAME ITS NATURE NOR, P119
   MHAT-IV, 2006, MENT HLTH ADV TEAM M
   Mikhail J, 2007, TRENDS COGN SCI, V11, P143, DOI 10.1016/j.tics.2006.12.007
   MILGRAM S, 1963, J ABNORM PSYCHOL, V67, P371, DOI 10.1037/h0040525
   Millar J., 2014, ETHICAL DILEMMA ROBO
   Mithen S., 1998, CREATIVITY HUMAN EVO
   Monroe A. E., 2014, SURROUNDING FREE WIL, P25, DOI [10.1093/acprof:oso/9780199333950.003.0003, DOI 10.1093/ACPROF:OSO/9780199333950.003.0003]
   Monroe AE, 2014, CONSCIOUS COGN, V27, P100, DOI 10.1016/j.concog.2014.04.011
   Monroe AE, 2010, REV PHILOS PSYCHOL, V1, P211, DOI 10.1007/s13164-009-0010-7
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80
   NISBETT RE, 1977, PSYCHOL REV, V84, P231, DOI 10.1037//0033-295X.84.3.231
   Nourbakhsh IR, 2013, ROBOT FUTURES, P1
   Open Roboethics Initiative, 2014, IF DEATH AUT CAR IS
   Open Roboethics Initiative, 2014, MY AUT CAR MY SAF RE
   Parthemore J., 2013, INT J MACH CONSCIOUS, V4, P105
   Paxton JM, 2012, COGNITIVE SCI, V36, P163, DOI 10.1111/j.1551-6709.2011.01210.x
   Petersen S, 2007, J EXP THEOR ARTIF IN, V19, P43, DOI 10.1080/09528130601116139
   Powell NL, 2012, J EXP CHILD PSYCHOL, V113, P186, DOI 10.1016/j.jecp.2012.03.006
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77
   Powers TM, 2011, IEEE ROBOT AUTOM MAG, V18, P51, DOI [10.1109/MRA.2011.940275, 10.1109/MRA.2010.940152]
   Pylyshyn Zenon, 1987, ROBOTS DILEMMA FRAME
   RYLE G., 1949, CONCEPT MIND
   Schank RC., 1977, SCRIPTS PLANS GOALS
   Scheutz M., 2007, P WORKSH ROB ICRA 20
   Scheutz M., 2014, 2014 IEEE ETH C CHIC
   Scheutz M., 2015, 24 IEEE INT S ROB HU
   Scheutz M, 2012, IEEE T AFFECT COMPUT, V3, P424, DOI 10.1109/T-AFFC.2012.29
   Semin G. R., 1983, ACCOUNTABILITY CONDU
   Shaver K. G, 1985, ATTRIBUTION BLAME CA
   Sullins J. P., 2011, PHILOS TECHNOL, V24, P233, DOI DOI 10.1007/S13347-011-0043-6
   Talamadupula K., 2011, PLANNING AGENTS CHAN
   Tanaka F, 2007, P NATL ACAD SCI USA, V104, P17954, DOI 10.1073/pnas.0707769104
   Tedeschi JT, 1981, PSYCHOL ORDINARY EXP, P271
   Thiessen ED, 2013, PSYCHOL BULL, V139, P792, DOI 10.1037/a0030801
   Tomasello M, 2013, ANNU REV PSYCHOL, V64, P231, DOI 10.1146/annurev-psych-113011-143812
   Traverso V, 2009, J PRAGMATICS, V41, P2385, DOI 10.1016/j.pragma.2008.09.047
   Turiel E., 1983, DEV SOCIAL KNOWLEDGE
   Van Berkum JJA, 2009, PSYCHOL SCI, V20, P1092, DOI 10.1111/j.1467-9280.2009.02411.x
   van Wynsberghe A, 2013, SCI ENG ETHICS, V19, P407, DOI 10.1007/s11948-011-9343-6
   Veloso M., 2012, HUMAN ROBOT INTERACT
   Veruggio G, 2011, IEEE ROBOT AUTOM MAG, V18, P21, DOI 10.1109/MRA.2010.940147
   Voiklis J., 2014, P 36 ANN C COGN SCI, P1700
   Walker MU, 2006, MORAL REPAIR: RECONSTRUCTING MORAL RELATIONS AFTER WRONGDOING, P1, DOI 10.2277/ 0521009251
   Wallach W., 2008, MORAL MACHINES TEACH
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8
   Warneken F, 2011, PSYCHOL SCI, V22, P267, DOI 10.1177/0956797610395392
   Weiner B, 1995, JUDGMENTS RESPONSIBI
   Williams KD, 2009, ADV EXP SOC PSYCHOL, V41, P275, DOI 10.1016/S0065-2601(08)00406-1
   Wolpert DM, 2001, CURR BIOL, V11, pR729, DOI 10.1016/S0960-9822(01)00432-8
   Wright JC, 2008, MERRILL PALMER QUART, V54, P56, DOI 10.1353/mpq.2008.0010
   Wyman E, 2009, COGNITIVE DEV, V24, P146, DOI 10.1016/j.cogdev.2009.01.003
NR 119
TC 6
Z9 6
U1 7
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD DEC
PY 2016
VL 18
IS 4
SI SI
BP 243
EP 256
DI 10.1007/s10676-015-9367-8
PG 14
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA EE0JT
UT WOS:000389261500002
OA Bronze
DA 2019-03-21
ER

PT J
AU Toivakainen, N
AF Toivakainen, Niklas
TI Machines and the face of ethics
SO Ethics and Information Technology
LA English
DT Article
DE Ethics; Face; Relationship; Responsibility; Compensatory
AB In this article I try to show in what sense Emmanuel Levinas' 'ethics as first philosophy' moves our ethical thinking away from what has been called 'centrist ethics'. Proceeding via depictions of the structure of Levinasian ethics and including references to examples as well as to some empirical research, I try to argue that human beings always already find themselves within an ethical universe, a space of meaning. Critically engaging with the writings of David Gunkel and Lucas Introna, I try to argue that these thinkers, rather than clarifying, distort our ethical understanding of how we stand in relation to artefacts. Drawing a distinction between how pervasive our ethical relationship to other human beings, and living animals, is and how the nature of artefacts is tied to us, I conclude by indicating that the aspiration to give artefacts an ethical face suggests a fantasy to avoid ethical responsibility and generates what I call a 'compensatory logic'.
C1 [Toivakainen, Niklas] Univ Helsinki, Dept Philosophy Hist Culture & Art Studies, Unioninkatu 40 A,POB 24, FIN-00014 Helsinki, Finland.
RP Toivakainen, N (reprint author), Univ Helsinki, Dept Philosophy Hist Culture & Art Studies, Unioninkatu 40 A,POB 24, FIN-00014 Helsinki, Finland.
EM niklas.toivakainen@helsinki.fi
CR Backstrom J., 2007, THE FEAR OF OPENNESS
   Benso S., 2000, FACE THINGS DIFFEREN
   Berreby David, 2005, US THEM UNDERSTANDIN
   Calarco M., 2008, ZOOGRAPHIES QUESTION
   DARLEY JM, 1973, J PERS SOC PSYCHOL, V27, P100, DOI 10.1037/h0034449
   Davis David Brion, 1966, PROBLEM SLAVERY W CU
   Derrida Jacques, 2008, ANIMAL THEREFORE I A
   Dykstra PA, 2009, EUR J AGEING, V6, P91, DOI 10.1007/s10433-009-0110-3
   Elkins Stanley M., 1959, SLAVERY PROBLEM AM I
   Ellul J., 1990, TECHNOLOGICAL BLUFF
   Ellul J., 1976, ETHICS FREEDOM
   FLORIDI L, 2003, ETHICS INFORMATION T, V4, P287, DOI DOI 10.1023/A:1021342422699
   Floridi Luciano, 2013, ETHICS INFORM
   Gunkel J. D., 2012, THE MACHINE QUESTION
   Hitlin S, 2010, HANDB SOCIOL SOC RES, P3, DOI 10.1007/978-1-4419-6896-8_1
   Introna L., 2014, RUIN MEMORIES MAT AE
   Joyce Richard, 2001, MYTH MORALITY
   Kant I., 1785, GROUNDWORK METAPHYSI, P2002
   Levinas E, 1985, ETHICS INFINITY CONV
   Levinas E., 1969, TOTALITY INFINITY ES
   Mumford Lewis, 2010, TECHNICS CIVILIZATIO
   Northup S., 2014, 12 YEARS A SLAVE
   Nykanen H, 2014, PHILOS PSYCHIATR PSY, V21, P51, DOI 10.1353/ppp.2014.0012
   Nykanen H., 2002, I YOU SOUL ETHICS CO
   Sorle T., 2014, ETHICS INF TECHNOL, V16, P183
   Toivakainen N, 2015, AM PHILOS ASS NEWSLE, V14, P20
   Toivakainen N, 2014, FRONTIERS ARTIFICIAL, V273
   Turkle Sherry, 2011, ALONE TOGERTHER
   Wallgren T., 2006, TRANSFORMATIVE PHILO
   Westerlund F., 2014, HEIDEGGER PROBLEM PH
   Wittgenstein L., 1980, CULTURE VALUE
   WITTGENSTEIN LUDWIG, 1967, PHILOS INVESTIGATION
NR 32
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD DEC
PY 2016
VL 18
IS 4
SI SI
BP 269
EP 282
DI 10.1007/s10676-015-9372-y
PG 14
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA EE0JT
UT WOS:000389261500004
DA 2019-03-21
ER

PT J
AU van Wynsberghe, A
AF van Wynsberghe, A.
TI Service robots, care ethics, and design
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Robot ethics; Care ethics; Value-sensitive design; Service robots;
   Applied ethics
AB It should not be a surprise in the near future to encounter either a personal or a professional service robot in our homes and/or our work places: according to the International Federation for Robots, there will be approx 35 million service robots at work by 2018. Given that individuals will interact and even cooperate with these service robots, their design and development demand ethical attention. With this in mind I suggest the use of an approach for incorporating ethics into the design process of robots known as Care Centered Value Sensitive Design (CCVSD). Although this approach was originally and intentionally designed for the healthcare domain, the aim of this paper is to present a preliminary study of how personal and professional service robots might also be evaluated using the CCVSD approach. The normative foundations for CCVSD come from its reliance on the care ethics tradition and in particular the use of care practices for: (1) structuring the analysis and, (2) determining the values of ethical import. To apply CCVSD outside of healthcare one must show that the robot has been integrated into a care practice. Accordingly, the practice into which the robot is to be used must be assessed and shown to meet the conditions of a care practice. By investigating the foundations of the approach I hope to show why it may be applicable for service robots and further to give examples of current robot prototypes that can and cannot be evaluated using CCVSD.
C1 [van Wynsberghe, A.] Univ Twente, Dept Philosophy, Drienerlolaan 5, NL-7522 NB Enschede, Netherlands.
RP van Wynsberghe, A (reprint author), Univ Twente, Dept Philosophy, Drienerlolaan 5, NL-7522 NB Enschede, Netherlands.
EM a.l.vanwynsberghe@utwente.nl
FU National Science Foundation in the Netherlands
FX Thank you to the reviewers of this text for their insightful comments
   and queries. Many thanks to my fellow robot ethicist Scott Robbins for
   his insight, constructive criticism, critical feedback, and support. A
   most gracious thank you to the National Science Foundation in the
   Netherlands for the funding to allow me to conduct this research.
CR Allen C, 2012, INTELL ROBOT AUTON, P55
   [Anonymous], 2013, MAIL ONLINE
   [Anonymous], 2009, ROBOVIE 2 PERSONAL R
   Asaro PM, 2012, INTELL ROBOT AUTON, P169
   Asaro PM, 2006, INT REV INF ETHICS, V6, P9
   Calo R., 2011, ROBOT ETHICS ETHICAL, P187
   Capurro R, 2009, ETHICS AND ROBOTICS, P117
   Denning T, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P105
   Driessen C, 2015, AGR HUM VALUES, V32, P3, DOI 10.1007/s10460-014-9515-5
   Engelberger J. F., 1989, ROBOTICS IN SERVICE
   Friedman B., 1996, INTERACTIONS, V3, P16, DOI DOI 10.1145/242485.242493
   Friedman B, 2002, VALUE SENSITIVE DESI, P2
   Friedman B, 2015, AARHUS SERIES HUMAN, V1, P9, DOI [10.7146/aahcc.v1i1.21619, DOI 10.7146/AAHCC.VLIL.21619]
   Friedman B., 2003, HUM FAC ER
   Friedman B., 2003, P SIGCHI C HUM FACT, V5, P273, DOI DOI 10.1145/642611.642660
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Little MO, 1998, J MED PHILOS, V23, P190, DOI 10.1076/jmep.23.2.190.8922
   Lokhorst GJ, 2012, INTELL ROBOT AUTON, P145
   Manders-Huits N, 2011, SCI ENG ETHICS, V17, P271, DOI 10.1007/s11948-010-9198-2
   Maslow A, 1970, MOTIVATION PERSONALI
   Mol A., 2010, CARE PRACTICE TINKER
   News F., 2014, NEW YORK POST
   Noddings N., 2002, ED MORAL PEOPLE CARI
   Pedersen SM, 2006, PRECIS AGRIC, V7, P295, DOI 10.1007/s11119-006-9014-9
   Sharkey A, 2014, ETHICS INF TECHNOL, V16, P63, DOI 10.1007/s10676-014-9338-5
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   Sharkey AJC, 2016, ETHICS INF TECHNOL, V18, P283, DOI 10.1007/s10676-016-9387-z
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Spiekermann S., 2015, ETHICAL IT INNOVATIO
   Sullins JP, 2011, MACHINE ETHICS
   Tronto J. C., 1993, MORAL BOUNDARIES POL
   Tronto JC, 2010, ETHICS SOC WELF, V4, P158, DOI 10.1080/17496535.2010.484259
   Vallor S., 2011, PHILOS TECHNOLOGY, V24, P251, DOI DOI 10.1007/S13347-011-0015-X
   Van Evert FK, 2006, WEED TECHNOL, V20, P853, DOI 10.1614/WT-05-132.1
   van Wynsberghe A, 2013, IND ROBOT, V40, P433, DOI 10.1108/IR-12-2012-451
   van Wynsberghe A, 2013, SCI ENG ETHICS, V19, P407, DOI 10.1007/s11948-011-9343-6
   Vanlaere L, 2011, NURS ETHICS, V18, P161, DOI 10.1177/0969733010388924
   VanWynsberghe A, 2015, EMERG TECH ETH INT A, P1
   Verkerk M A, 2001, Med Health Care Philos, V4, P289, DOI 10.1023/A:1012048907443
   Veruggio G, 2006, INT REV INF ETHICS, V6, P2
   Wallach W., 2008, MORAL MACHINES TEACH
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8
NR 42
TC 10
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD DEC
PY 2016
VL 18
IS 4
SI SI
BP 311
EP 321
DI 10.1007/s10676-016-9409-x
PG 11
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA EE0JT
UT WOS:000389261500007
OA Other Gold, Green Published
DA 2019-03-21
ER

PT J
AU Davies, J
AF Davies, Jim
TI Program good ethics into artificial intelligence
SO NATURE
LA English
DT Editorial Material
C1 [Davies, Jim] Carleton Univ, Inst Cognit Sci, Ottawa, ON, Canada.
RP Davies, J (reprint author), Carleton Univ, Inst Cognit Sci, Ottawa, ON, Canada.
EM jim@jimdavies.org
NR 0
TC 2
Z9 2
U1 3
U2 41
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 0028-0836
EI 1476-4687
J9 NATURE
JI Nature
PD OCT 20
PY 2016
VL 538
IS 7625
BP 291
EP 291
PG 1
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA EA5PJ
UT WOS:000386673100004
DA 2019-03-21
ER

PT J
AU Tran, B
AF Tran, Ben
TI Machine (Technology) Ethics: The Theoretical and Philosophical Paradigms
SO INTERNATIONAL JOURNAL OF TECHNOETHICS
LA English
DT Article
DE Act Utilitarianism; Classical Utilitarianism; Ideal Utilitarianism; Rule
   Utilitarianism; Technology; Utilitarianism
AB At the foundational level, for computer programmers, the code that programmers build and built into, are based on instructions, and the purpose of the program it later services. But computers do not have their own discretion beyond what humans incorporate into such systems and are essentially limited only to the extent its writer chooses. However, ABET to date, does not provide assurance or require accredited colleges and universities programs in applied science, computing, engineering, and engineering technology to take ethics courses or offer ethics courses nor train graduates in ethics. Yet, graduates, who then become practitioners, and ethical agents, are expected to be ethical agents. Hence, the purpose of this article is on machine ethics, specifically, on the theoretical and philosophical meaning of ethics-different types of ethics and utilitarianism. In addition to exploring the theoretical and philosophical paradigm of ethics, technology will be defined, in relations to machine ethics.
C1 [Tran, Ben] Alliant Int Univ San Francisco, Calif Sch Profess Psychol, San Francisco, CA 94133 USA.
RP Tran, B (reprint author), Alliant Int Univ San Francisco, Calif Sch Profess Psychol, San Francisco, CA 94133 USA.
CR ALLEN PM, 1994, FUTURES, V26, P583, DOI 10.1016/0016-3287(94)90030-2
   Anderson M., 2005, MACHINE ETHICS
   Anderson M., 2011, MACHINE ETHICS, DOI [10.1017/CBO9780511978036, DOI 10.1017/CBO9780511978036]
   Anderson M, 2007, AI MAG, V28, P15
   Anderson S. L., 1995, J PHILOS RES, V20, P543, DOI 10.5840/jpr_1995_10
   Anderson SL, 2013, P 2013 M INT ASS COM
   Anschutz R. P., 2015, JS MILL BRIT PHILOS
   Bentham J., 2012, INTRO PRINCIPLES MOR
   Bijker W. E., 1992, SHAPING TECHNOLOGY B, P21
   Bijker W. E., 1987, SOCIAL CONSTRUCTION
   Brandt R., 1963, MORALITY LANGUAGE CO, P107
   David L., 1965, FORMS LIMITS UTILITA
   Donner W., 2011, JS MILL ART LIFE
   Donner Wendy, 1991, LIBERAL SELF JS MILL
   Driver J, 2014, HIST UTILITARIANISM
   Duignan B., 2015, J BENTHAM BRIT PHILO
   Ellul J., 1964, TECHNOLOGICAL SOC
   Fieser J, ETHICS
   Foucault M., 1988, TECHNOLOGIES SELF SE, P16
   Galvan J. M., 2003, IEEE RAS MAGAZINE, V10, P58
   Hooker B., 2015, RULE CONSEQUENTIALIS
   Hughes T, 1991, ENG SOCIAL ENTERPRIS, P7
   HUGHES TP, 1986, SOC STUD SCI, V16, P281, DOI 10.1177/0306312786016002004
   Hughes TP, 1987, SOCIAL CONSTRUCTION, P51, DOI DOI 10.1177/030631289019001010
   Krantz S. F., 2002, REFUTING PETER SINGE
   Luppicini R., 2010, TECHNOETHICS EVOLVIN, DOI [10.4018/978-1-60566-952-6, DOI 10.4018/978-1-60566-952-6]
   Mayocchi D., 1995, THESIS
   Moore G. E., 1903, MIND, VXII, P433, DOI DOI 10.1093/MIND/XII.4.433
   Moore G. E., 2002, NATURE JUDGMENT
   Moore G. E., 1903, PRINCIPIA ETHICA
   Nef J., 1989, ETHICS TECHNOLOGY ET
   Raval V., 2014, INFORM SYSTEMS AUDIT, V5, P1
   Rooney D., 1997, PROMETHEUS, V15, P399, DOI DOI 10.1080/08109029708632084
   Schmookler J., 1966, INVENTION EC GROWTH, DOI [10.4159/harvard.9780674432833, DOI 10.4159/HARVARD.9780674432833]
   Schneewind J. B., 1977, SIDGWICKS ETHICS VIC
   SIDGWICK H, 1874, METHODS ETHICS
   Singer P., 2013, PREFERENCE UTILITARI
   Singer P., 2011, PRACTICAL ETHICS, DOI [10.1017/CBO9780511975950, DOI 10.1017/CBO9780511975950]
   Sinnott-Armstrong W, 2015, CONSEQUENTIALISM
   Smart J. J. C., 1961, OUTLINE SYSTEM UTILI
   The Editors of Encycloaedia Britannica, 2015, CONS ETH
   The Editors of Encyclopaedia Britannica, 2015, HENR SIDGW BRIT PHIL
   The Editors of Encyclopaedia Britannica, 2015, GE MOOR BRIT PHIL
   Tran B., 2013, ETHICAL DATA MINING, P201
   Wallach W., 2008, MORAL MACHINES TEACH
   Weber M., 1958, RATIONAL SOCIAL FDN
   Willemsen M., 2014, DEFENDING UTILITARIA
   Wolfe A, 2014, WALL STREET J
NR 48
TC 0
Z9 0
U1 0
U2 7
PU IGI GLOBAL
PI HERSHEY
PA 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA
SN 1947-3451
EI 1947-346X
J9 INT J TECHNOETHICS
JI Int. J. Technoethics
PD JUL-DEC
PY 2016
VL 7
IS 2
BP 77
EP 90
DI 10.4018/IJT.2016070105
PG 14
WC Ethics
SC Social Sciences - Other Topics
GA DX9KK
UT WOS:000384713800005
DA 2019-03-21
ER

PT J
AU Cato, KD
   Bockting, W
   Larson, E
AF Cato, Kenrick D.
   Bockting, Walter
   Larson, Elaine
TI Did I Tell You That? Ethical Issues Related to Using Computational
   Methods to Discover Non-Disclosed Patient Characteristics
SO JOURNAL OF EMPIRICAL RESEARCH ON HUMAN RESEARCH ETHICS
LA English
DT Article
DE clinical settings; electronic health record; data mining; LGBT; informed
   consent; LGBTQ; other clinical; risks; benefits; and burdens of
   research/beneficence and non-maleficence; data sharing
ID ELECTRONIC MEDICAL-RECORDS; STAGE LUNG-CANCER; BIG DATA; CONSENT;
   HEALTH; PERCEPTIONS; CARE; PRIVACY; ACCESS; RISK
AB Widespread availability of electronic health records coupled with sophisticated statistical methods offer great potential for a variety of applications for health and disease surveillance, developing predictive models and advancing decision support for clinicians. However, use of "big data" mining and discovery techniques has also raised ethical issues such as how to balance privacy and autonomy with the wider public benefits of data sharing. Furthermore, electronic data are being increasingly used to identify individual characteristics, which can be useful for clinical prediction and management, but were not previously disclosed to a clinician. This process in computer parlance is called electronic phenotyping, and has a number of ethical implications. Using the Belmont Report's principles of respect for persons, beneficence, and justice as a framework, we examined the ethical issues posed by electronic phenotyping. Ethical issues identified include the ability of the patient to consent for the use of their information, the ability to suppress pediatric information, ensuring that the potential benefits justify the risks of harm to patients, and acknowledging that the clinician's biases or stereotypes, conscious or unintended, may become a factor in the therapeutic interaction. We illustrate these issues with two vignettes, using the person characteristic of gender minority status (i.e., transgender identity) and health history characteristic of substance abuse. Data mining has the potential to uncover patient characteristics previously obscured, which can provide clinicians with beneficial clinical information. Hence, ethical guidelines must be updated to ensure that electronic phenotyping supports the principles of respect for persons, beneficence, and justice.
C1 [Cato, Kenrick D.; Bockting, Walter] Columbia Univ, Sch Nursing, 617 West 168th St,Room 247, New York, NY 10032 USA.
   [Bockting, Walter] Columbia Univ, Initiat LGBT Hlth, New York State Psychiat Inst, New York, NY USA.
   [Larson, Elaine] Columbia Univ, Res, New York, NY USA.
   [Larson, Elaine] Columbia Univ, Sch Nursing, Res, New York, NY USA.
   [Larson, Elaine] Columbia Univ, Mailman Sch Publ Hlth, Epidemiol, New York, NY USA.
   [Bockting, Walter] Columbia Univ, Coll Phys & Surg, New York, NY USA.
   [Larson, Elaine] Columbia Univ, Mailman Sch Publ Hlth, Dept Epidemiol, New York, NY USA.
RP Cato, KD (reprint author), Columbia Univ, Sch Nursing, 617 West 168th St,Room 247, New York, NY 10032 USA.
EM kdc2110@columbia.edu
FU Agency for Healthcare Research and Quality [1R01HS022961]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   was funded in part by a grant from the Agency for Healthcare Research
   and Quality, 1R01HS022961.
CR Agaku IT, 2014, J AM MED INFORM ASSN, V21, P374, DOI 10.1136/amiajnl-2013-002079
   Asghar MR, 2012, LECT NOTES COMPUT SC, V7039, P119
   Brehaut JC, 2012, J CLIN EPIDEMIOL, V65, P708, DOI 10.1016/j.jclinepi.2012.01.004
   Butler D, 2013, NATURE, V494, P155, DOI 10.1038/494155a
   Cassell EJ, 2000, HASTINGS CENT REP, V30, P12, DOI 10.2307/3527640
   Cook S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023610
   Currie J, 2013, PEDIATRICS, V131, pS127, DOI 10.1542/peds.2013-0252c
   Cykert S, 2010, JAMA-J AM MED ASSOC, V303, P2368, DOI 10.1001/jama.2010.793
   Dalton AF, 2014, J HEALTH COMMUN, V19, P532, DOI 10.1080/10810730.2013.821550
   Deutsch MB, 2013, J AM MED INFORM ASSN, V20, P700, DOI 10.1136/amiajnl-2012-001472
   Erdmann J, 2013, CHEM BIOL, V20, P1, DOI 10.1016/j.chembiol.2013.01.008
   Erlich Y, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001983
   Ghandour L, 2013, J EMPIR RES HUM RES, V8, P12, DOI 10.1525/jer.2013.8.3.12
   Grant J. M., 2010, NATL TRANSGENDER DIS
   Hayden EC, 2012, NATURE, V486, P312, DOI 10.1038/486312a
   Herland M, 2014, J BIG DATA, V1, P2, DOI DOI 10.1186/2196-1115-1-2
   Holt Tim A, 2014, CMAJ Open, V2, pE248, DOI 10.9778/cmajo.20130095
   Hripcsak G, 2013, J AM MED INFORM ASSN, V20, P117, DOI 10.1136/amiajnl-2012-001145
   Kaye J, 2015, EUR J HUM GENET, V23, P141, DOI 10.1038/ejhg.2014.71
   Klitzman R, 2014, JAMA-J AM MED ASSOC, V312, P1855, DOI 10.1001/jama.2014.13301
   Koenig BA, 2014, HASTINGS CENT REP, V44, P33, DOI 10.1002/hast.329
   Kondylakis H., 2015, P 5 EAI INT C WIR MO, P263
   Kosenko K, 2013, MED CARE, V51, P819, DOI 10.1097/MLR.0b013e31829fa90d
   Kuehn BM, 2013, JAMA-J AM MED ASSOC, V310, P678, DOI 10.1001/jama.2013.194643
   Lazer D, 2014, SCIENCE, V343, P1203, DOI 10.1126/science.1248506
   Lee R, 2011, INT J ENV RES PUB HE, V8, P830, DOI 10.3390/ijerph8030830
   Rahm AK, 2013, J COMMUN GENET, V4, P445, DOI 10.1007/s12687-013-0146-0
   Richards Neil M., 2014, WAKE FOREST L REV, V49, P393
   Schwartz LM, 1999, NEW ENGL J MED, V341, P279, DOI 10.1056/NEJM199907223410411
   Smedley BD, 2002, UNEQUAL TREATMENT CO
   Sperber J, 2005, INT J TRANSGENDERISM, V8, P75, DOI 10.1300/J485v08n02_08
   Tamariz L, 2013, J GEN INTERN MED, V28, P121, DOI 10.1007/s11606-012-2133-2
   Teare HJA, 2015, DIGIT HEALTH, V1, DOI 10.1177/2055207615605644
   The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research, 1978, BELM REP ETH PRINC G
   Thiel DB, 2015, PUBLIC HEALTH GENOM, V18, P26, DOI 10.1159/000366128
   Tran T, 2014, BMC PSYCHIATRY, V14, DOI 10.1186/1471-244X-14-76
   U. S. Department of Health and Human Services, 2005, SUMM HIPAA PRIV RUL
   van Ryn M, 2000, SOC SCI MED, V50, P813, DOI 10.1016/S0277-9536(99)00338-X
   van Ryn M, 2002, MED CARE, V40, P140
   White House, 2014, BIG DAT SEIZ OPP PRE
   Williams H, 2015, JMIR MED INF, V3, DOI 10.2196/medinform.3525
NR 41
TC 4
Z9 4
U1 4
U2 22
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1556-2646
EI 1556-2654
J9 J EMPIR RES HUM RES
JI J. Empir. Res. Hum. Res. Ethics
PD JUL
PY 2016
VL 11
IS 3
BP 214
EP 219
DI 10.1177/1556264616661611
PG 6
WC Ethics; Medical Ethics
SC Social Sciences - Other Topics; Medical Ethics
GA DV8SS
UT WOS:000383207600002
PM 27534587
OA Green Accepted
DA 2019-03-21
ER

PT J
AU Etzioni, A
   Etzioni, O
AF Etzioni, Amitai
   Etzioni, Oren
TI AI assisted ethics
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Ethics bot; Communiterianism; Second-layer AI; Driverless cars
AB The growing number of 'smart' instruments, those equipped with AI, has raised concerns because these instruments make autonomous decisions; that is, they act beyond the guidelines provided them by programmers. Hence, the question the makers and users of smart instrument (e.g., driver-less cars) face is how to ensure that these instruments will not engage in unethical conduct (not to be conflated with illegal conduct). The article suggests that to proceed we need a new kind of AI program-oversight programs-that will monitor, audit, and hold operational AI programs accountable.
C1 [Etzioni, Amitai] George Washington Univ, 1922 F St NW,Room 413, Washington, DC 20052 USA.
   [Etzioni, Oren] Allen Inst Artificial Intelligence, Seattle, WA USA.
RP Etzioni, A (reprint author), George Washington Univ, 1922 F St NW,Room 413, Washington, DC 20052 USA.
EM etzioni@gwu.edu
CR Ajzen I., 2005, HDB ATTITUDES
   [Anonymous], 2015, SCI DAILY
   [Anonymous], 2015, ECONOMIST
   Azjen I., 2004, PERSONALITY SOCIAL P, V30, P1108
   Boaz David, 1999, KEY CONCEPTS LIBERTA
   Bonnefon J., 2015, COMPUTERS SOC
   Campbell D., 2006, WORKING PAPER
   Dellinger A. J., 2015, THE DAILY DOT   0629
   Dunning D, 2003, CURR DIR PSYCHOL SCI, V12, P83, DOI 10.1111/1467-8721.01235
   Etzioni A., 2016, VANDERBILT IN PRESS
   Etzioni A., 1988, THE MORAL DIMENSION
   Fleischer P., 2015, COMMUNICATION   1023
   Fradella Henry F., 2011, AM J CRIM L, V38, P289
   Goldhill O., 2015, QUARTZ          1031
   Greene JD, 2014, ETHICS, V124, P695, DOI 10.1086/675875
   Hamburger T., 2015, WASHINGTON POST
   Hardin G., 1974, PSYCHOL TODAY
   Homer, 1978, ODYSSEY
   Institute for Statistics Education, GLOSS STAT TERMS TES
   Kahneman D., 2011, THINKING FAST SLOW
   Kaplan J., 2015, MEDIUM          0922
   LIN P., 2013, ATLANTIC
   Lohr S, 2015, DATA ISM REVOLUTION
   Marcus G., 2012, MORAL MACHINES
   Markoff J., 2013, NY TIMES
   Mayer-Schonberger V, 2014, BIG DATA
   Nielsen, 2015, NIELS PSYCLE LIF GRO
   Pariser E., 2011, CNN             0522
   Richardson H. S., 2014, STANFORD ENCY PHILOS
   Rossi F., 2015, WASHINGTON POST
   SLOBOGIN C, 1993, DUKE LAW J, V42, P727, DOI 10.2307/1372714
   Tegmark M., 2015, OPEN LETT RES PRIORI
   The Economist, 2014, ECONOMIST
   Walzer Michael, 1984, SPHERES JUSTICE DEFE
   Westin A., 2003, J SOC ISSUES, V59, DOI DOI 10.1111/1540-4560.00072/EPDF
   Wolchover N., 2015, QUANTA          0421
   Wrong Dennis, 1995, PROBLEM ORDER WHAT U
NR 37
TC 8
Z9 8
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD JUN
PY 2016
VL 18
IS 2
BP 149
EP 156
DI 10.1007/s10676-016-9400-6
PG 8
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA DM8KQ
UT WOS:000376611900006
OA Bronze
DA 2019-03-21
ER

PT J
AU Vardi, MY
AF Vardi, Moshe Y.
TI The Moral Imperative of Artificial Intelligence
SO COMMUNICATIONS OF THE ACM
LA English
DT Editorial Material
NR 0
TC 1
Z9 1
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 0001-0782
EI 1557-7317
J9 COMMUN ACM
JI Commun. ACM
PD MAY
PY 2016
VL 59
IS 5
BP 5
EP 5
DI 10.1145/2903530
PG 1
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
SC Computer Science
GA DK5AE
UT WOS:000374931100001
OA Bronze
DA 2019-03-21
ER

PT J
AU Funk, M
AF Funk, Michael
TI Robot Ethics: The Ethical and Social Implications of Robotics
SO ETHICAL THEORY AND MORAL PRACTICE
LA English
DT Book Review
C1 [Funk, Michael] Tech Univ Dresden, Dresden, Germany.
RP Funk, M (reprint author), Tech Univ Dresden, Dresden, Germany.
EM michael.funk@posteo.de
CR Lin P., ROBOT ETHICS ETHICAL
NR 1
TC 0
Z9 0
U1 5
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1386-2820
EI 1572-8447
J9 ETHICAL THEORY MORAL
JI Ethical Theory Moral Pract.
PD APR
PY 2016
VL 19
IS 2
BP 547
EP 548
DI 10.1007/s10677-015-9638-9
PG 2
WC Philosophy
SC Philosophy
GA DI8IG
UT WOS:000373744100023
DA 2019-03-21
ER

PT J
AU Fort, J
AF Fort, Jeff
TI THE MACHINE IS/IN US KELLY OLIVER'S DERRIDEAN ETHICS
SO CULTURAL CRITIQUE
LA English
DT Article
C1 [Fort, Jeff] Univ Calif Davis, French, Davis, CA 95616 USA.
RP Fort, J (reprint author), Univ Calif Davis, French, Davis, CA 95616 USA.
CR Burt ES, 2013, OXFORD LITERARY REV, V35, P165, DOI 10.3366/olr.2013.0068
   Butler Judith, 2014, LONDON REV BOOKS
   Derrida J, 1978, WRITING DIFFERENCE, P79
   Derrida J., 2010, COPY ARCH SIGNATURE
   Derrida J., 2009, BEAST SOVEREIGN, V1-2, P2009
   Derrida J, 2010, OXFORD LITERARY REV, V32, P169, DOI 10.3366/E030514981000074X
   Derrida Jacques, 2008, ANIMAL THEREFORE I A
   Derrida Jacques, 2004, WHAT TOMORROW DIALOG
   Derrida Jacques, 2010, ATHENS STILL REMAINS
   Derrida Jacques, 2014, THE DEATH PENALTY, VI
   Harris J, 2007, ENHANCING EVOLUTION
   Kamuf Peggy, 2014, LOS ANGELES REV 0305
   MARIN Louis, 1988, PORTRAIT OF THE KING
   Mieszkowski Jan, 2014, LOS ANGELES REV 0305
   Naas M, 2011, MOSAIC, V44, P81
   Naas M, 2011, S ATL Q, V110, P205, DOI 10.1215/00382876-2010-029
   Oliver K, 2013, TECHNOLOGIES OF LIFE AND DEATH: FROM CLONING TO CAPITAL PUNISHMENT, P1
   Oliver K, 2014, J FR FRANCOPH PHILOS, V22, P70, DOI 10.5195/jffp.2014.664
   Richter Gerhard, 2011, AFTERNESS FIGURES FO, P118
   Shershow Scott Cutler, 2013, DECONSTRUCTING DIGNI
NR 20
TC 0
Z9 0
U1 0
U2 0
PU UNIV MINNESOTA PRESS
PI MINNEAPOLIS
PA MILL PLACE, SUITE 290 111 THIRD AVE S, MINNEAPOLIS, MN 55401-2520 USA
SN 0882-4371
EI 1460-2458
J9 CULT CRIT
JI Cult. Crit.
PD SPR
PY 2016
IS 93
BP 168
EP 195
PG 28
WC Cultural Studies
SC Cultural Studies
GA DU7WQ
UT WOS:000382425700008
DA 2019-03-21
ER

PT J
AU Bendel, O
AF Bendel, Oliver
TI Considerations about the relationship between animal and machine ethics
SO AI & SOCIETY
LA English
DT Article
DE Animal ethics; Machine ethics; Robot ethics; Information ethics;
   Technology ethics; Moral machines; Animal-machine interaction
AB Ethics researches morality in respect to humans and animals. Usually, it implies human morality; therefore, the focus is on human-human relationships (generally in ethics) and human-animal relationships (in animal ethics). Ethics can also deal with the morality of machines such as unmanned aerial vehicles, robots and agents or of self-driving cars and computers in automated trading, in other words more or less autonomous systems and programs. Machine ethics almost exclusively concentrates on machine-human relationships rather than on machine-animal relationships. Before this background, this article contributes some basic considerations about the relationship between animal and machine ethics.
C1 [Bendel, Oliver] Univ Appl Sci & Arts Northwester Switzerland FHNW, Sch Business, Inst Informat Syst, Bahnhofstr 6, CH-5210 Windisch, Switzerland.
RP Bendel, O (reprint author), Univ Appl Sci & Arts Northwester Switzerland FHNW, Sch Business, Inst Informat Syst, Bahnhofstr 6, CH-5210 Windisch, Switzerland.
EM oliver.bendel@fhnw.ch
CR Anderson M., 2011, MACHINE ETHICS
   Bendel O, 2012, MORAL MASCHINEN UBER
   Bendel O, 2013, TECHNOLOGY ASSESSMEN, P229
   Bendel O, 2013, UNTERNEHMERZEITUNG, V7, P30
   Bendel O, 2012, DIE RACHE DER NERDS
   Bendel O, 2003, THESIS
   Bendel O, 2012, BEITRAG GABLER WIRTS
   Bendel O, 2012, INFORM SPEKTRUM
   Buttner R, 2011, SPIEGEL ONLINE
   MacDorman KF, 2005, P COGSCI 2005 WORKSH
   Wendt J, 2013, ZEIT ONLINE
   Wild Markus, 2006, ANTHR DIFFERENZ GEIS
   Wolf Ursula, 2012, ETHIK MENSCH TIER BE
   Wollan M, 2010, NY TIMES
NR 14
TC 1
Z9 1
U1 2
U2 21
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0951-5666
EI 1435-5655
J9 AI SOC
JI AI Soc.
PD FEB
PY 2016
VL 31
IS 1
BP 103
EP 108
DI 10.1007/s00146-013-0526-3
PG 6
WC Computer Science, Artificial Intelligence
SC Computer Science
GA DV7WW
UT WOS:000383150000010
DA 2019-03-21
ER

PT J
AU Omari, RM
   Mohammadian, M
AF Omari, Rollin M.
   Mohammadian, Masoud
TI Rule based fuzzy cognitive maps and natural language processing in
   machine ethics
SO JOURNAL OF INFORMATION COMMUNICATION & ETHICS IN SOCIETY
LA English
DT Article
DE Decision making and ethics; Natural language processing in machine
   ethics; Rule based fuzzy cognitive maps
ID LATENT SEMANTIC ANALYSIS; AGENT
AB Purpose - The developing academic field of machine ethics seeks to make artificial agents safer as they become more pervasive throughout society. In contrast to computer ethics, machine ethics is concerned with the behavior of machines toward human users and other machines. This study aims to use an action-based ethical theory founded on the combinational aspects of deontological and teleological theories of ethics in the construction of an artificial moral agent (AMA).
   Design/methodology/approach - The decision results derived by the AMA are acquired via fuzzy logic interpretation of the relative values of the steady-state simulations of the corresponding rule-based fuzzy cognitive map (RBFCM).
   Findings - Through the use of RBFCMs, the following paper illustrates the possibility of incorporating ethical components into machines, where latent semantic analysis (LSA) and RBFCMs can be used to model dynamic and complex situations, and to provide abilities in acquiring causal knowledge.
   Research limitations/implications - This approach is especially appropriate for data-poor and uncertain situations common in ethics. Nonetheless, to ensure that a machine with an ethical component can function autonomously in the world, research in artificial intelligence will need to further investigate the representation and determination of ethical principles, the incorporation of these ethical principles into a system's decision procedure, ethical decision-making with incomplete and uncertain knowledge, the explanation for decisions made using ethical principles and the evaluation of systems that act based upon ethical principles.
   Practical implications - To date, the conducted research has contributed to a theoretical foundation for machine ethics through exploration of the rationale and the feasibility of adding an ethical dimension to machines. Further, the constructed AMA illustrates the possibility of utilizing an action-based ethical theory that provides guidance in ethical decision-making according to the precepts of its respective duties. The use of LSA illustrates their powerful capabilities in understanding text and their potential application as information retrieval systems in AMAs. The use of cognitive maps provides an approach and a decision procedure for resolving conflicts between different duties.
   Originality/value - This paper suggests that cognitive maps could be used in AMAs as tools for meta-analysis, where comparisons regarding multiple ethical principles and duties can be examined and considered. With cognitive mapping, complex and abstract variables that cannot easily be measured but are important to decision-making can be modeled. This approach is especially appropriate for data-poor and uncertain situations common in ethics.
C1 [Omari, Rollin M.] Australian Natl Univ, Sch Comp Sci, Canberra, ACT, Australia.
   [Mohammadian, Masoud] Univ Canberra, Fac Business Govt & Law, Canberra, ACT, Australia.
RP Mohammadian, M (reprint author), Univ Canberra, Fac Business Govt & Law, Canberra, ACT, Australia.
EM masoudm991@gmail.com
CR Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   Anderson M., 2004, P AAAI SAN JOS CA
   Anderson M, 2007, AI MAG, V28, P15
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64
   Arkin R. C., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P121
   Beauchamp TL, 2001, PRINCIPLES BIOMEDICA
   Bostrum N., 2014, SUPERINTELLIGENCE PA
   Carvalho J. P., 1999, COMP INT MOD CONTR A
   Carvalho JP, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P407, DOI 10.1109/NAFIPS.2000.877462
   Carvalho JP, 1999, 18TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P115, DOI 10.1109/NAFIPS.1999.781665
   Cassinelli Alvaro, 2009, REYN CASS 5 AS PAC C, P95
   Dehak N, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P71
   Dickerson J. A., 1993, IEEE Virtual Reality Annual International Symposium (Cat. No.93CH3336-5), P471, DOI 10.1109/VRAIS.1993.380742
   Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189
   EDEN C, 1992, J MANAGE STUD, V29, P309
   Foltz P. W., 1999, INTERACTIVE MULTIMED, V1
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   KLEIN JH, 1982, J OPER RES SOC, V33, P63, DOI 10.1057/jors.1982.7
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Kosko B., 1987, IEEE First International Conference on Neural Networks, P261
   Kosko B., 1988, International Journal of Approximate Reasoning, V2, P377, DOI 10.1016/0888-613X(88)90111-9
   Kosko B., 1992, FUZZY EXPERT SYSTEMS, P135
   Kosko B., 1997, FUZZY ENG
   Landauer TK, 1998, ADV NEUR IN, V10, P45
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   McCarthy John, 1969, MACH INTELL, P431
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80
   Mouratiadou I, 2007, ECOL ECON, V62, P66, DOI 10.1016/j.ecolecon.2007.01.009
   Ozesmi U., 2001, YUSUFELI BARAJI YENI, P154
   Papageorgiou EI, 2005, J INTELL INF SYST, V25, P95, DOI 10.1007/s10844-005-0864-9
   Reimann S, 1998, NEURAL NETWORKS, V11, P611, DOI 10.1016/S0893-6080(98)00001-X
   Ross WD, 1930, RIGHT GOOD
   TABER R, 1991, EXPERT SYST APPL, V2, P83, DOI 10.1016/0957-4174(91)90136-3
   Turing A.M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433
   Weng YH, 2009, INT J SOC ROBOT, V1, P267, DOI 10.1007/s12369-009-0019-1
   Yampolskiy R. V., 2013, ARTIF INTELL, P389
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 38
TC 2
Z9 2
U1 1
U2 3
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 1477-996X
EI 1758-8871
J9 J INF COMMUN ETHICS
JI J. Inf. Commun. Ethics Soc.
PY 2016
VL 14
IS 3
BP 231
EP 253
DI 10.1108/JICES-10-2015-0034
PG 23
WC Ethics
SC Social Sciences - Other Topics
GA FJ2KF
UT WOS:000412554900002
DA 2019-03-21
ER

PT J
AU Fabris, A
AF Fabris, Adriano
TI Machine ethics
SO TEORIA-RIVISTA DI FILOSOFIA
LA Italian
DT Article
DE ethics; machine; artificial intelligence; emerging technologies, robot;
   autonomy
AB This paper discusses some issues concerning the so-called "machine ethics". Firstly, human agency and machine agency are distinguished clearly, from an ethical viewpoint. Secondly, the concept of "autonomy" is applied to machine agency and is defined as a "relative autonomy". Finally the principles of an ethical attitude of the human being in relation to the machine world are developed in detail.
C1 [Fabris, Adriano] Univ Pisa, Dipartimento Civilta & Forme Sapere, I-56100 Pisa, Italy.
RP Fabris, A (reprint author), Univ Pisa, Dipartimento Civilta & Forme Sapere, I-56100 Pisa, Italy.
EM adriano.fabris@unipi.it
CR Anderson M., 2011, MACHINE ETHICS
   [Anonymous], 2012, SULLARGOMENTO MI PER
   Calo R, 2016, ROBOT LAW
   Cantoni L., 2015, COMMUNICATION TECHNO, P365
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   Floridi Luciano, 2013, ETHICS INFORM
   Hibbard B., 2014, ETHICAL ARTIFICIAL I
   Koch C., 2013, COSCIENZA CONFESSION, P164
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Pagallo Ugo, 2013, LAWS ROBOTS CRIMES C
   Paic Z., 2016, THEORIZING IMAGES, P111
   REICHLIN M, 2013, LUTILITARISMO
   RelAzione, 2016, RELAZIONE FILOSOFIA
   Shannon C. E., 1963, MATEMATHICAL THEORY
   Wallach W., 2009, MORAL MACHINES TEACH, P4
   Wiener N, 1948, CYBERNETICS CONTROL
NR 17
TC 0
Z9 0
U1 1
U2 10
PU EDIZIONI ETS
PI PISA
PA PIAZZA CARRARA 16-19, 56126 PISA, ITALY
SN 1122-1259
J9 TEORIA
JI Teoria
PY 2016
VL 36
IS 2
BP 119
EP 136
PG 18
WC Philosophy
SC Philosophy
GA EK0AY
UT WOS:000393590000009
DA 2019-03-21
ER

PT J
AU Millar, J
AF Millar, Jason
TI An Ethics Evaluation Tool for Automating Ethical Decision-Making in
   Robots and Self-Driving Cars
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
ID DESIGN
AB As we march down the road of automation in robotics and artificial intelligence, we will need to automate an increasing amount of ethical decision-making in order for our devices to operate independently from us. But automating ethical decision-making raises novel questions for engineers and designers, who will have to make decisions about how to accomplish that task. For example, some ethical decision-making involves hard moral cases, which in turn requires user input if we are to respect established norms surrounding autonomy and informed consent. The author considers this and other ethical considerations that accompany the automation of ethical decision-making. He proposes some general ethical requirements that should be taken into account in the design room, and sketches a design tool that can be integrated into the design process to help engineers, designers, ethicists, and policymakers decide how best to automate certain forms of ethical decision-making.
C1 [Millar, Jason] Carleton Univ, Dept Philosophy, Ottawa, ON K1S 5B6, Canada.
RP Millar, J (reprint author), Carleton Univ, Dept Philosophy, Ottawa, ON K1S 5B6, Canada.
EM Jason.Millar@carleton.ca
FU Canada's Social Sciences and Humanities Research Council (SSHRC) through
   a Joseph Armand Bombardier Canada Graduate Scholarship; Canadian
   Institutes for Health Research (CIHR) through a Science Policy
   Fellowship
FX This research was funded in part by Canada's Social Sciences and
   Humanities Research Council (SSHRC) through a Joseph Armand Bombardier
   Canada Graduate Scholarship, and in part by the Canadian Institutes for
   Health Research (CIHR) through a Science Policy Fellowship.
CR Breazeal C., 2014, NY TIMES
   Breazeal C. L., 2002, DESIGNING SOCIABLE R
   Cabo Ryan, 2015, CALIF L REV IN PRESS, V103
   Chang R, 2002, ETHICS, V112, P659, DOI 10.1086/339673
   Chang R, 2012, PHILOS ISSUES, V22, P106, DOI 10.1111/j.1533-6077.2012.00239.x
   Collins H., 2007, RETHINKING EXPERTISE
   Darling K., 2015, WE ROB 2015 P
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   Freidman B., 2006, HUMAN COMPUTER INTER, P348
   Friedman B., 2003, HUMAN COMPUTER INTER, P1127
   Friedman B., 2002, TECHNICAL REPORT
   Jonsen Albert R., 2008, SHORT HIST MED ETHIC
   Latour B, 1992, SHAPING TECHNOLOGY B, P225
   LATOUR B, 1999, PANDORAS HOPE ESSAYS
   Millar J., 2015, TECHNOLOGY SOC MAGAZ, V34, P47
   Millar J, 2014, WIRED
   Millar J., 2014, CONVERSATION
   Millar J, 2014, FACEBOOK OUR FFRIEND
   Millar J., 2014, ETHICAL DILEMMA ROBO
   Ngai D., 2010, INTERNET J LAW HEALT, V1, P1
   Norman D. A., 2010, LIVING COMPLEXITY
   NORMAN Donald, 1988, DESIGN EVERYDAY THIN
   Open Roboethics initiative, 2014, RES MY AUT CAR MY SA
   Open Roboethics Initiative, 2014, DEATH AUT CAR IS UN
   Pollock A., 2008, INNER HIST DEVICES, P98
   Proudfoot D, 2011, ARTIF INTELL, V175, P950, DOI 10.1016/j.artint.2011.01.006
   Riek L., 2014, P WE ROB 2014
   van Wynsberghe A, 2014, INT J TECHNOETHICS, V5, P11, DOI 10.4018/ijt.2014070102
   van Wynsberghe A, 2014, SCI ENG ETHICS, V20, P947, DOI 10.1007/s11948-013-9498-4
   van Wynsberghe A, 2013, SCI ENG ETHICS, V19, P407, DOI 10.1007/s11948-011-9343-6
   Verbeek Peter Paul, 2011, MORALIZING TECHNOLOG
   Verbeek PP, 2006, SCI TECHNOL HUM VAL, V31, P361, DOI 10.1177/0162243905285847
NR 32
TC 0
Z9 0
U1 6
U2 33
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PY 2016
VL 30
IS 8
BP 787
EP 809
DI 10.1080/08839514.2016.1229919
PG 23
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA EE5KR
UT WOS:000389646400004
DA 2019-03-21
ER

PT J
AU Martinez, M
AF Martinez, Mark
TI Photography as a machine organism: The cyberneticization of the
   photographic and techne as ethics
SO PHILOSOPHY OF PHOTOGRAPHY
LA English
DT Article
DE cybernetics; machine-organism; technical objects; living systems;
   techniques; ethics
AB This article proposes a cybernetic photographic theory that takes seriously the philosophical claim that cameras, images and human beings exist as evolving systems of machines-organisms. It provides an epistemological challenge to the modernist problematic of representation - namely, the emergence of human consciousness outside and above nature, and a rationalist distinction between an active, visual-reasoning subject and a passive object. I utilize the (non) philosophy of Francois Lauruelle in order to foreground and deepen the understanding of the ethical thought in cybernetics. My purpose is to build upon ethical philosophy that, as Gilbert Simondon contended, would 'save the technical object'. There is some urgency to this task as, in saving machines from their own histories and statuses as non-human, representational things in the world, we may begin an ethico-political programme that evaluates the complementary creative processes of human and machine - in a word, our shared Art - in order to save ourselves. It is perhaps the case that any recuperation of cybernetic and photographic theory today be poised not to reckon with our 'digital' moment but rather with our Anthropocene era defined by human's extinction level powers of destruction.
C1 [Martinez, Mark] Spalding Univ, Sch Commun, Commun Media Studies, 901 South 4th St, Louisville, KY 40203 USA.
RP Martinez, M (reprint author), Spalding Univ, Sch Commun, Commun Media Studies, 901 South 4th St, Louisville, KY 40203 USA.
EM mmartinez01@spalding.edu
CR Barnes J., 1991, COMPLETE WORKS ARIST
   Colebrook C., 2014, DEATH POSTHUMAN ESSA, V1
   De Landa M, 2006, NEW PHILOS SOC ASSEM
   DeBoever A., 2009, PARRHESIA, V7
   Deleuze G., 2005, 1000 PLATEAUS
   Deleuze Giles, 1995, NEGOTIATIONS
   Deleuze Gilles, 1990, LOGIC SENSE
   Derrida J, 2002, ALIBI
   Derrida Jacques, 1981, DISSEMINATION
   Douglas P., 1992, CRISIS MODERNISM BER
   Galloway Alexander, 2014, LARUELLE DIGITAL
   KECHCKIAN A, 1983, ESPRIT, P147
   Kittler F., 1996, CTHEORY SPECIAL ISSU
   Kittler F, 2010, OPTICAL MEDIA
   Laruelle F., 2011, CONCEPT NONPHOTOGRAP
   Marks John, 1998, G DELEUZE VITALISM M
   Martinez M, 2015, PHILOS PHOTOGR, V6, P61, DOI 10.1386/pop.6.1-2.61_1
   Phys.org, 2015, 1 EV PHOT LIGHT BOTH
   Piazza L., 2015, NATURE COMMUNICATION
   Rosen R., 2000, ESSAYS LIFE ITSELF
   Simondon G., 1980, MODE TECHNICAL EXIST
   VonFoerster H, 2014, MEAN SYST, P1
   Wiener N., 1965, CYBERNETICS CONTROL
   Wiener N., 1964, GOD AND GOLEM INC
   Wolfe C., 2012, LAW HUMANS OTHER ANI
   Zylinska Joanna, 2014, MINIMAL ETHICS ANTHR
NR 26
TC 1
Z9 1
U1 1
U2 3
PU INTELLECT LTD
PI BRISTOL
PA THE MILL, PARNALL RD, BRISTOL, BS16 3JG, ENGLAND
SN 2040-3682
EI 2040-3690
J9 PHILOS PHOTOGR
JI PHILOS. PHOTOGR.
PD DEC
PY 2015
VL 6
IS 1-2
BP 61
EP 72
DI 10.1386/pop.6.1-2.61_1
PG 12
WC Art
SC Art
GA DX5FW
UT WOS:000384406200006
DA 2019-03-21
ER

PT J
AU Gregory, T
AF Gregory, Thomas
TI Military Robots: Mapping the Moral Landscape
SO POLITICAL SCIENCE
LA English
DT Book Review
C1 [Gregory, Thomas] Univ Auckland, Auckland 1, New Zealand.
RP Gregory, T (reprint author), Univ Auckland, Auckland 1, New Zealand.
OI Gregory, Thomas/0000-0003-2223-1726
CR Galliott J, 2015, MILIT DEFEN ETHIC, P1
NR 1
TC 0
Z9 0
U1 0
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0032-3187
EI 2041-0611
J9 POLIT SCI
JI Polit. Sci.
PD DEC
PY 2015
VL 67
IS 2
BP 179
EP 181
DI 10.1177/0032318715609193
PG 4
WC Political Science
SC Government & Law
GA DB3OF
UT WOS:000368420300008
DA 2019-03-21
ER

PT J
AU Frost, M
AF Frost, Mervyn
TI Military Robots: Mapping the Moral Landscape
SO RUSI JOURNAL
LA English
DT Book Review
C1 [Frost, Mervyn] Kings Coll London, Dept War Studies, London WC2R 2LS, England.
RP Frost, M (reprint author), Kings Coll London, Dept War Studies, London WC2R 2LS, England.
OI Frost, Mervyn/0000-0002-5573-1332
CR Galliott J, 2015, MILIT DEFEN ETHIC, P1
NR 1
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0307-1847
EI 1744-0378
J9 RUSI J
JI RUSI J.
PD NOV 2
PY 2015
VL 160
IS 6
BP 84
EP 85
PG 2
WC Political Science
SC Government & Law
GA CZ4IH
UT WOS:000367066200003
DA 2019-03-21
ER

PT J
AU Schafer, B
   Komuves, D
   Zatarain, JMN
   Diver, L
AF Schafer, Burkhard
   Komuves, David
   Zatarain, Jesus Manuel Niebla
   Diver, Laurence
TI A fourth law of robotics? Copyright and the law and ethics of machine
   co-production
SO ARTIFICIAL INTELLIGENCE AND LAW
LA English
DT Article
DE Robotics; Copyright law; Bing
ID DEVELOPMENTAL ROBOTICS; BRAIN; CREATIVITY; ART; KNOWLEDGE; FRAMEWORK;
   PROGRAMS; SYSTEMS
AB Jon Bing was not only a pioneer in the field of artificial intelligence and law and the legal regulation of technology. He was also an accomplished author of fiction, with an oeuvre spanning from short stories and novels to theatre plays and even an opera. As reality catches up with the imagination of science fiction writers who have anticipated a world shared by humans and non-human intelligences of their creation, some of the copyright issues he has discussed in his academic capacity take on new resonance. How will we regulate copyright when robots are producers and consumers of art? This paper tries to give a sketch of the problem and hints at possible answers that are to a degree inspired by Bing's academic and creative writing.
C1 [Schafer, Burkhard; Komuves, David; Zatarain, Jesus Manuel Niebla; Diver, Laurence] Univ Edinburgh, Sch Law, SCRIPT Ctr, Edinburgh, Midlothian, Scotland.
RP Schafer, B (reprint author), Univ Edinburgh, Sch Law, SCRIPT Ctr, Edinburgh, Midlothian, Scotland.
EM B.Schafer@ed.ac.uk
OI Diver, Laurence/0000-0002-1297-9311
FU Arts and Humanities Research Council [AH/K000179/1]
CR Abie H., 2004, Electronic Government, V1, P8, DOI 10.1504/EG.2004.004134
   Asada M, 2001, ROBOT AUTON SYST, V37, P185, DOI 10.1016/S0921-8890(01)00157-9
   Bing J., 2003, Alexandria, V15, P171
   BING J, 1984, HDB LEGAL INFORM RET
   Bing J, 1981, PENGUIN WORLD OMNIBU
   Bing J, 2003, LAW ELECT AGENTS
   Bing J, 2013, J OPEN ACCESS LAW, V1, P1
   Bing J, 1991, JL INF SCI, V2, P1
   Bing J, 1997, IFLA J, V23, P4
   Bing J, 1998, A VIRTUAL NEW WORLD
   Bing J, 2007, PEGASUS, V3, P24
   Bing J, 2008, J INT COMMER LAW TEC, V3, P197
   Bing J, 1996, INT JL INFO TECH, V4, P234
   Bing J, 2004, INT REV LAW COMPUT T, V18, P347
   Bing J, 2009, RES HBK INTELLECT, P401
   Boden MA, 1998, ARTIF INTELL, V103, P347, DOI 10.1016/S0004-3702(98)00055-1
   BODEN MA, 1994, BEHAV BRAIN SCI, V17, P519, DOI 10.1017/S0140525X0003569X
   Boden MA, 2009, AI MAG, V30, P23, DOI 10.1609/aimag.v30i3.2254
   Borel E., 1913, Journal de Physique, V3, P189, DOI 10.1051/jphystap:019130030018900
   Borges JL, 2007, THE TOTAL LIB
   Bridy Annemarie, 2012, STAN TECH L REV, V5, P1
   Butler TL, 1981, COMM ENT LS, V4, P707
   Cangelosi A, 2010, IEEE T AUTON MENT DE, V2, P167, DOI 10.1109/TAMD.2010.2053034
   Chon M., 2007, UC DAVIS L REV, V40, P803
   Collingwood RG, 1958, PRINCIPLES ART, V11
   Contissa G, 2008, FR ART INT, V189, P98, DOI 10.3233/978-1-58603-952-3-98
   Cox IJ, 1998, IEEE J SEL AREA COMM, V16, P587, DOI 10.1109/49.668980
   Di Dio C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001201
   Favale M, 2011, INT J LAW INFORM TEC, V19, P306, DOI 10.1093/ijlit/ear010
   Funkhouser C., 2007, PREHISTORIC DIGITAL
   Gervas P, 2001, KNOWL-BASED SYST, V14, P181, DOI 10.1016/S0950-7051(01)00095-8
   Gervas P., 2000, P AISB 00 S CREAT CU, P93
   Goncalo Oliveira H., 2012, P ECAI 2012 WORKSH C
   Gordon T. F., 2011, P 13 INT C ART INT L, P51
   Hartman Charles O, 1996, VIRTUAL MUSE EXPT CO
   Haupenthal G, 1994, THESIS SAARBRUCKEN, V2
   Hong J, 2014, KUNSTLICHE MENSCHEN
   Horikawa T, 2013, SCIENCE, V340, P639, DOI 10.1126/science.1234330
   J McCormack, 2012, COMPUTERS CREATIVITY
   Jiang LQ, 2008, ADV DIFFER EQU-NY, DOI 10.1155/2008/345916
   Jordanous A, 2012, COGN COMPUT, V4, P246, DOI 10.1007/s12559-012-9156-1
   Kac E, 1997, ART J, V56, P60, DOI 10.2307/777838
   Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444
   Komuves D, 2015, JUSLETTER IT, V26, pRZ1
   Kostelanetz R, 1971, CENTENNIAL REV, V15, P229
   LEE Edward, 2012, VAND J ENT TECH L, V14, P919
   Lee JH, 2009, NEUROSCI LETT, V450, P1, DOI 10.1016/j.neulet.2008.11.024
   Legaspi R, 2007, 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P216
   Lessig L, 1999, CODE OTHER LAWS CYBE
   Mahler T, 2006, SCAND STUD LAW, V49, P339
   Manurung R, 2012, J EXP THEOR ARTIF IN, V24, P43, DOI 10.1080/0952813X.2010.539029
   Marino D, 2006, INT REV INF ETHICS, V6, P46
   Matthias A., 2004, Ethics and Information Technology, V6, P175, DOI 10.1007/s10676-004-3422-1
   McCutcheon J, 2013, MELB UNIV LAW REV, V36, P915
   Moffat DC, 2006, ASSESSMENT, V13, P11
   MULLIGAN DK, 2003, P 2003 ACM WORKSH DI, P77
   Nadal M, 2008, SPATIAL VISION, V21, P379, DOI 10.1163/156856808784532653
   Nierhaus G., 2009, ALGORITHMIC COMPOSIT
   OBERLE D, 2012, SCRIPTED, V9, P280
   Petrie HG, 2011, DILEMMA ENQUIRY LEAR
   Pogue D, 2012, SCI AM, V307, P32, DOI 10.1038/scientificamerican1212-32
   Pynadath DV, 2002, LECT NOTES ARTIF INT, V2333, P307
   Raabe O, 2010, GLOBALE SICHERHEIT P, V266, P643
   RACTER, 1985, POLICEMANS BEARD HAL
   Reese RA, 2008, COLUMBIA J LAW ARTS, V31, P2012
   REICHARDT J, 1978, ROBOTS FACT FICTION
   Riedl MO, 2014, PREPRINT
   Roos JW, 2005, IFLA J-INT FED LIBR, V31, P52, DOI 10.1177/0340035205052647
   Rowe E, 2001, MACHINE MUSICIANSHIP
   Rowe R, 1993, INTERACTIVE MUSIC SY
   Schlegel A, 2015, NEUROIMAGE, V105, P440, DOI 10.1016/j.neuroimage.2014.11.014
   Schoffer Nicholas, 1969, VILLE CYBERNETIQUE
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00005756
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   Shinkareva SV, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001394
   Solso RL, 2000, J CONSCIOUSNESS STUD, V7, P75
   Stamp M., 2003, J ELECTRON COMMER RE, V4, P102
   Ward JA, 1992, COLUM VLA J L ARTS, V17, P159
   WELD D, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1042
   Wiggins GA, 2006, KNOWL-BASED SYST, V19, P449, DOI 10.1016/j.knosys.2006.04.009
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Xenakis I, 2001, HARMONOLOGIA SERIES, V6
NR 82
TC 3
Z9 3
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-8463
EI 1572-8382
J9 ARTIF INTELL LAW
JI Artif. Intell. Law
PD SEP
PY 2015
VL 23
IS 3
BP 217
EP 240
DI 10.1007/s10506-015-9169-7
PG 24
WC Computer Science, Artificial Intelligence
SC Computer Science
GA CV3MD
UT WOS:000364162400003
DA 2019-03-21
ER

PT J
AU Lorenc, T
AF Lorenc, Theo
TI Artificial Intelligence and the Ethics of Human Extinction
SO JOURNAL OF CONSCIOUSNESS STUDIES
LA English
DT Article
DE artificial intelligence; ethics; human extinction; humanism; mind
   uploading
ID MACHINES
AB The potential long-term benefits and risks of technological progress in artificial intelligence (AI) and related fields are substantial. The risks include total human extinction as a result of unfriendly superintelligent AI, while the benefits include the liberation of human existence from death and suffering through mind uploading. One approach to mitigating the risk would be to engineer ethical principles into AI devices. However, this may not be possible, due to the nature of ethical agency. Even if it is possible, these principles, extrapolated to logical conclusions, may not favour human survival.
EM theo.e.lorenc@gmail.com
CR ADAMS RM, 1989, PHILOS REV, V98, P439, DOI 10.2307/2185115
   Agar N, 2010, LIFE MIND-PHILOS ISS, P1
   Armstrong S, 2012, MIND MACH, V22, P299, DOI 10.1007/s11023-012-9282-2
   Bostrom N., 2003, ETHICAL ISSUES ADV A
   Bostrom N., 2014, SUPERINTELLIGENCE PA
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316
   Bostrom N, 2013, GLOB POLICY, V4, P15, DOI 10.1111/1758-5899.12002
   Bostrom N, 2012, MIND MACH, V22, P71, DOI 10.1007/s11023-012-9281-3
   Brassier Raymond, 2010, NIHIL UNBOUND ENLIGH
   Chalmers DJ, 2010, J CONSCIOUSNESS STUD, V17, P7
   Crook J, 1999, ECON LETT, V65, P165, DOI 10.1016/S0165-1765(99)00151-2
   Dymski GA, 2006, ELGAR ORIG REF, P215
   Eden Amnon H., 2012, SINGULARITY HYPOTHES
   Egan G, 2008, DIASPORA
   Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
   Hauskeller M, 2012, INT J MACHINE CONSCI, V4, P187, DOI DOI 10.1142/S1793843012400100
   Hopkins P. D., 2012, INT J MACHINE CONSCI, V1, P229
   Kurzweil R, 2014, CREATE MIND SECRET H
   Kurzweil R., 2005, SINGULARITY IS NEAR
   LUCAS JR, 1961, PHILOSOPHY, V36, P112, DOI 10.1017/S0031819100057983
   Lyotard J.-F, 1991, THE INHUMAN, P8
   Marres N., 2012, MAT PARTICIPATION TE
   Moravec Hans, 1988, MIND CHILDREN FUTURE
   Muehlhauser L., 2012, SINGULARITY HYPOSTHE, P101
   Pigliucci M., 2014, INTELLIGENCE UNBOUND
   Sandberg Anders, 2008, WHOLE BRAIN EMULATIO
   Shulman C., 2009, 7 EUR C COMP PHIL EC
   Sotala Kaj, 2012, INT J MACHINE CONSCI, V4, P293, DOI [10.1142/S1793843012400173, DOI 10.1142/S1793843012400173]
   Stross C, 2006, ACCELERANDO
   Vinge V., 1993, WHOLE EARTH REV, P88
   Waser Mark, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P153, DOI 10.1007/978-3-642-22887-2_16
   Wiley K. B., 2014, TAXONOMY METAPHYSICS
   Wolfe C., 2010, WHAT IS POSTHUMANISM
   WOOLGAR S, 1985, SOCIOLOGY, V19, P557, DOI 10.1177/0038038585019004005
   Yudkowsky E., 2004, COHERENT EXTRAPOLATE
NR 35
TC 1
Z9 1
U1 5
U2 121
PU IMPRINT ACADEMIC
PI EXETER
PA PO BOX 200, EXETER EX5 5YX, DEVON, ENGLAND
SN 1355-8250
J9 J CONSCIOUSNESS STUD
JI J. Conscious. Stud.
PD SEP-OCT
PY 2015
VL 22
IS 9-10
BP 194
EP 214
PG 21
WC Philosophy; Social Sciences, Interdisciplinary
SC Philosophy; Social Sciences - Other Topics
GA CT3FZ
UT WOS:000362693900012
DA 2019-03-21
ER

PT J
AU Deng, B
AF Deng, Boer
TI MACHINE ETHICS: THE ROBOT'S DILEMMA
SO NATURE
LA English
DT News Item
CR Anderson M, 2007, AI MAG, V28, P15
   Duncan B., 2009, GITGYU0902
   Pereira L. M., LOGIC ARGUM IN PRESS
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0_8
   2015, NATURE, V518, P20
NR 5
TC 12
Z9 12
U1 2
U2 41
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 0028-0836
EI 1476-4687
J9 NATURE
JI Nature
PD JUL 2
PY 2015
VL 523
IS 7558
BP 24
EP 26
DI 10.1038/523024a
PG 3
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA CL7RN
UT WOS:000357169500012
PM 26135432
OA Bronze
DA 2019-03-21
ER

PT J
AU Chen, K
AF Chen, Kai
TI Military robots: mapping the moral landscape
SO INTERNATIONAL AFFAIRS
LA English
DT Book Review
C1 [Chen, Kai] Xiamen Univ, Xiamen, Peoples R China.
RP Chen, K (reprint author), Xiamen Univ, Xiamen, Peoples R China.
RI Chen, Kai/F-7898-2012
OI Chen, Kai/0000-0002-0891-3408
CR Galliott J, 2015, MILIT DEFEN ETHIC, P1
NR 1
TC 0
Z9 0
U1 0
U2 1
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0020-5850
EI 1468-2346
J9 INT AFF
JI Int. Aff.
PD JUL
PY 2015
VL 91
IS 4
BP 885
EP 886
DI 10.1111/1468-2346.12352
PG 2
WC International Relations
SC International Relations
GA CM8OI
UT WOS:000357961100024
DA 2019-03-21
ER

PT J
AU Berendt, B
   Buchler, M
   Rockwell, G
AF Berendt, Bettina
   Buechler, Marco
   Rockwell, Geoffrey
TI Is it Research or is it Spying? Thinking-Through Ethics in Big Data AI
   and Other Knowledge Sciences
SO KUNSTLICHE INTELLIGENZ
LA English
DT Editorial Material
DE Big Data; Surveillance society; Privacy; Ethics; Interdisciplinary
   knowledge sciences
AB "How to be a knowledge scientist after the Snowden revelations?'' is a question we all have to ask as it becomes clear that our work and our students could be involved in the building of an unprecedented surveillance society. In this essay, we argue that this affects all the knowledge sciences such as AI, computational linguistics and the digital humanities. Asking the question calls for dialogue within and across the disciplines. In this article, we will position ourselves with respect to typical stances towards the relationship between (computer) technology and its uses in a surveillance society, and we will look at what we can learn from other fields. We will propose ways of addressing the question in teaching and in research, and conclude with a call to action.
C1 [Berendt, Bettina] Katholieke Univ Leuven, Dept Comp Sci, Declarat Languages & Artificial Intelligence Grp, Leuven, Belgium.
   [Buechler, Marco] Univ Gottingen, Gottingen Ctr Digital Humanities, Gottingen, Germany.
   [Rockwell, Geoffrey] Univ Alberta, Dept Philosophy, Philosophy & Humanities Comp, Edmonton, AB, Canada.
RP Berendt, B (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Declarat Languages & Artificial Intelligence Grp, Leuven, Belgium.
EM bettina.berendt@cs.kuleuven.be; mbuechler@gcdh.de; grockwel@ualberta.ca
FU Flemish Agency for Innovation through Science and Technology (IWT);
   Fonds Wetenschappelijk Onderzoek-Vlaanderen (FWO); German Ministry of
   Education and Research (BMBF); Social Science and Humanities Research
   Council of Canada [100048, G068611N, 01UG1409]
FX We thank the Flemish Agency for Innovation through Science and
   Technology (IWT), the Fonds Wetenschappelijk Onderzoek-Vlaanderen (FWO),
   the German Ministry of Education and Research (BMBF), and the Social
   Science and Humanities Research Council of Canada for support through
   the projects SPION (Grant Number 100048), Data Mining for Privacy in
   Social Networks (Grant Number G068611N), the early career research group
   eTRAP (No. 01UG1409), and the NovelTM project.
CR [Anonymous], 2002, PINS MAS
   Ball J, 2014, NSA COLLECTS MILLION
   Berendt B, 2015, BIG DATA ITS REVOLUT
   Berendt B, 2014, ARTIF INTELL LAW, V22, P175, DOI 10.1007/s10506-013-9152-0
   Berger R, 2015, QUAL RES, V15, P219, DOI 10.1177/1468794112468475
   Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878
   Gehring P, 2012, WISSENSCHAFT DEMOKRA, P112
   Gellman B, 2013, INTERNET COMPANIES B
   Greenwald G., 2014, NO PLACE HIDE E SNOW
   Greenwald Glenn, 2013, GUARDIAN
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Harrison S, 2014, GUARDIAN COMMEN 0314
   Heine F, 2013, SPIEGEL ONLINE
   Jockers ML, 2013, TOP DIGIT HUM, P1
   Jr O'Harrow R, 2005, NO PLACE HIDE
   Kamishima Toshihiro, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P35, DOI 10.1007/978-3-642-33486-3_3
   Kammerer D, 2014, PRIME TROJANS BUSINE
   Kirschbaum E, 2014, SNOWDEN SAYS NSA ENG
   Kitchin R., 2014, DATA REVOLUTION BIG
   Lough T, 2014, INT REV INF ETHICS, V21, P45
   MacAskill E, 2013, GUARDIAN
   Markoff John, 2005, WHAT DORMOUSE SAID S
   Matthews D., 2013, WASHINGTON POST
   Mayer-Schonberger V., 2013, BIG DATA REVOLUTION
   Moretti Franco, 2007, GRAPHS MAPS TREES AB
   Morozov E., 2013, SAVE EVERYTHING CLIC
   Morozov E., 2013, MIT TECHNOLOGY REV
   Noller S, 2013, GUARDIAN
   Pedreshi Dino, 2008, P 14 ACM SIGKDD INT, P560
   Piatetsky G., 2014, KDNUGGETS
   Poitras L., 2014, CITIZENFOUR
   Priest Dana, 2011, TOP SECRET AM RISE N
   RISEN James, 2005, NY TIMES
   Rockwell G, 2014, PAPER SUBMITTED REV
   Romei A, 2014, KNOWL ENG REV, V29, P582, DOI 10.1017/S0269888913000039
   Schneier B., 2013, GUARDIAN
   Shelley MW, 1888, FRANKENSTEIN MODERN
   Shorrock Tim, 2008, SPIES HIRE SECRET WO
   Sweeney L, 2013, COMMUN ACM, V56, P44, DOI 10.1145/2447976.2447990
   Weber P, 2014, HERES WHAT THEY MEAN
   WINNER L, 1980, DAEDALUS, V109, P121
   Zwitter A, 2014, BIG DATA SOC, V1, DOI 10.1177/2053951714559253
NR 42
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0933-1875
EI 1610-1987
J9 KUNSTL INTELL
JI Kunstl. Intell.
PD JUN
PY 2015
VL 29
IS 2
BP 223
EP 232
DI 10.1007/s13218-015-0355-2
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA VA6CQ
UT WOS:000410149500016
DA 2019-03-21
ER

PT J
AU Russell, S
AF Russell, Stuart
TI Ethics of artificial intelligence
SO NATURE
LA English
DT Editorial Material
C1 Univ Calif Berkeley, Comp Sci, Berkeley, CA 94720 USA.
RP Russell, S (reprint author), Univ Calif Berkeley, Comp Sci, Berkeley, CA 94720 USA.
NR 0
TC 11
Z9 11
U1 16
U2 124
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 0028-0836
EI 1476-4687
J9 NATURE
JI Nature
PD MAY 28
PY 2015
VL 521
IS 7553
BP 415
EP 416
PG 2
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA CJ2AN
UT WOS:000355286600013
PM 26017428
OA Bronze
DA 2019-03-21
ER

PT J
AU Zeng, D
AF Zeng, Daniel
TI AI Ethics: Science Fiction Meets Technological Reality
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Editorial Material
C1 [Zeng, Daniel] Univ Arizona, Tucson, AZ 85721 USA.
   [Zeng, Daniel] Chinese Acad Sci, Beijing 100864, Peoples R China.
RP Zeng, D (reprint author), Univ Arizona, Tucson, AZ 85721 USA.
EM zengdaniel@gmail.com
NR 0
TC 1
Z9 1
U1 2
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
EI 1941-1294
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD MAY-JUN
PY 2015
VL 30
IS 3
BP 2
EP 5
PG 4
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA CJ2NU
UT WOS:000355322500001
DA 2019-03-21
ER

PT J
AU Laskaris, R
AF Laskaris, Ricardo
TI Moral Machines: Teaching Robots Right from Wrong
SO LIBRARY JOURNAL
LA English
DT Book Review
C1 [Laskaris, Ricardo] York Univ Lib, Steacie Sci & Engn Lib, Toronto, ON, Canada.
RP Laskaris, R (reprint author), York Univ Lib, Steacie Sci & Engn Lib, Toronto, ON, Canada.
CR Wallach W., 2008, MORAL MACHINES TEACH
NR 1
TC 0
Z9 0
U1 0
U2 6
PU REED BUSINESS INFORMATION
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010 USA
SN 0363-0277
J9 LIBR J
JI Libr. J.
PD APR 1
PY 2015
VL 140
IS 6
BP 45
EP 45
PG 1
WC Information Science & Library Science
SC Information Science & Library Science
GA CE9TO
UT WOS:000352186500038
DA 2019-03-21
ER

PT J
AU Van de Voort, M
   Pieters, W
   Consoli, L
AF Van de Voort, Marlies
   Pieters, Wolter
   Consoli, Luca
TI Refining the ethics of computer-made decisions: a classification of
   moral mediation by ubiquitous machines
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Ubiquitous computing; Moral reasoning; Technological mediation; Moral
   decisions; Human computer relations
AB In the past decades, computers have become more and more involved in society by the rise of ubiquitous systems, increasing the number of interactions between humans and IT systems. At the same time, the technology itself is getting more complex, enabling devices to act in a way that previously only humans could, based on developments in the fields of both robotics and artificial intelligence. This results in a situation in which many autonomous, intelligent and context-aware systems are involved in decisions that affect their environment. These relations between people, machines, and decisions can take many different forms, but thus far, a systematic account of machine-assisted moral decisions is lacking. This paper investigates the concept of machine-assisted moral decisions from the perspective of technological mediation. It is argued that modern machines do not only have morality in the sense of mediating the actions of humans, but that, by making their own decisions within their relations with humans, mediate morality itself. A classification is proposed to differentiate between four different types of moral relations. The moral aspects within the decisions these systems make are combined into three dimensions that describe the distinct characteristics of different types of moral mediation by machines. Based on this classification, specific guidelines for moral behavior can be provided for these systems.
C1 [Van de Voort, Marlies] Univ Twente EEMCS PS, NL-7500 AE Enschede, Netherlands.
   [Pieters, Wolter] Delft Univ Technol, NL-2600 GA Delft, Netherlands.
   [Pieters, Wolter] Univ Twente TBM ICT, NL-2600 GA Delft, Netherlands.
   [Consoli, Luca] Radboud Univ Nijmegen Philosophy & Sci Studies, Fac Sci, NL-6500 GL Nijmegen, Netherlands.
RP Van de Voort, M (reprint author), Univ Twente EEMCS PS, POB 217, NL-7500 AE Enschede, Netherlands.
EM marliesvdvoort@gmail.com; w.pieters@tudelft.nl; l.consoli@science.ru.nl
RI Consoli, Luca/B-5749-2008; Pieters, Wolter/M-8847-2017
OI Consoli, Luca/0000-0001-8604-1134; 
CR Akrich Madeleine, 1992, DESCRIPTION TECHNICA, P205
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83
   Coeckelbergh M, 2011, L N INST COMP SCI SO, V59, P126
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P209, DOI 10.1007/s10676-010-9235-5
   Consoli I. L., 2008, ANN THIJMGENOOTSCHAP
   Dechesne F, 2013, ETHICS INF TECHNOL, V15, P173, DOI 10.1007/s10676-013-9326-1
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   Fong T., 2003, SURVEY SOCIALLY INTE
   Friedman B, 2006, ADV MANAG INFORM SYS, V5, P348
   Gaver W.W, 1991, P SIGCHI C HUM FACT, P79, DOI DOI 10.1145/108844.108856
   Hildebrandt M., 2010, MINNESOTA J LAW SCI, V11, P497
   Ihde D., 1990, TECHNOLOGY LIFEWORLD
   Johnson D. G., 2008, INFORM TECHNOLOGY MO, P251
   Kuflik A., 1999, Ethics and Information Technology, V1, P173, DOI 10.1023/A:1010087500508
   Magnani L, 2008, FOUND SCI, V13, P99, DOI 10.1007/s10699-007-9116-5
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67
   Noorman M, 2012, STANFORD ENCY PHILOS
   Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354
   Pieters W, 2013, ETHICS INF TECHNOL, V15, P195, DOI 10.1007/s10676-013-9317-2
   Poslad P.S., 2009, UBIQUITOUS COMPUTING
   Ramos C, 2008, IEEE INTELL SYST, V23, P15, DOI 10.1109/MIS.2008.19
   van den Hoven J, 2007, INFORM SOC INNOVATIO, V233, P67
   Van den Hoven J, 2012, SCI ENG ETHICS, V18, P143, DOI 10.1007/s11948-011-9277-z
   Van den Hoven M. J., 1998, PUBLIC ADM INFORM AG, P97
   Verbeek PP, 2008, PHENOMENOL COGN SCI, V7, P387, DOI 10.1007/s11097-008-9099-x
   Verbeek PP, 2006, SCI TECHNOL HUM VAL, V31, P361, DOI 10.1177/0162243905285847
   Wallach W., 2009, MORAL MACHINES TEACH
NR 27
TC 4
Z9 4
U1 5
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD MAR
PY 2015
VL 17
IS 1
BP 41
EP 56
DI 10.1007/s10676-015-9360-2
PG 16
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA CC7MZ
UT WOS:000350553500004
OA Other Gold
DA 2019-03-21
ER

PT J
AU Driessen, C
   Heutinck, LFM
AF Driessen, Clemens
   Heutinck, Leonie F. M.
TI Cows desiring to be milked? Milking robots and the co-evolution of
   ethics and technology on Dutch dairy farms
SO AGRICULTURE AND HUMAN VALUES
LA English
DT Article
DE Milking robots; Dairy farming; Animal welfare; Labor quality;
   Co-evolution of ethics and technology; Human animal relations;
   Technology assessment; Automatic milking systems (AMS)
ID AUTOMATIC MILKING; ANIMAL-WELFARE; BEHAVIOR; SYSTEM; CULTURE; HEALTH;
   CATTLE
AB Ethical concerns regarding agricultural practices can be found to co-evolve with technological developments. This paper aims to create an understanding of ethics that is helpful in debating technological innovation by studying such a co-evolution process in detail: the development and adoption of the milking robot. Over the last decade an increasing number of milking robots, or automatic milking systems (AMS), has been adopted, especially in the Netherlands and a few other Western European countries. The appraisal of this new technology in ethical terms has appeared to be a complicated matter. Compared to using a conventional milking parlor, the use of an AMS entails in several respects a different practice of dairy farming, the ethical implications and evaluation of which are not self-evident but are themselves part of a dynamic process. It has become clear that with its use, the entire practice of dairy farming has been reorganized around this new device. With a robot, cows must voluntarily present themselves to be milked, whereby an ethical norm of (individual) freedom for cows can be seen to emerge together with this new technology. But adopting a robot also implies changes in what is considered to be a good farmer and an appropriate relation between farmer and cow. Through interviews, attending "farmers' network'' meetings in the Netherlands, and studying professional literature and dedicated dairy farming web forums, this paper traces the way that ethical concerns are a dynamic part of this process of rearranging a variety of elements of the practice of dairy farming.
C1 [Driessen, Clemens] Wageningen Univ, Cultural Geog Grp, NL-6708 PB Wageningen, Netherlands.
   [Heutinck, Leonie F. M.] Wageningen Univ, NL-8219 PH Wageningen, Netherlands.
RP Driessen, C (reprint author), Wageningen Univ, Cultural Geog Grp, Droevendaalsesteeg 3, NL-6708 PB Wageningen, Netherlands.
EM clemens.driessen@wur.nl
RI driessen, clemens/D-7685-2015
OI driessen, clemens/0000-0003-1695-1524
FU Netherlands Organization for Scientific Research (NWO) [253-20-013]
FX This paper presents results of the project "Ethical room for manoeuvre
   in livestock farming" that was funded by The Netherlands Organization
   for Scientific Research (NWO) project # 253-20-013. The authors in
   researching and writing this paper owe special thanks to: Michiel
   Korthals, Volkert Beekman, Marc Bracke, Hans Spoolder, Jan Bloemert,
   Kees de Koning, Kees van Reenen, Frank Lenssinck, Bert Philipsen,
   Carolien Ketelaar-de Lauwere, Zwier van der Vegte, members of the
   Oost-Overijsselse melkrobot netwerk and the Mobiele melkrobot netwerk,
   de Melkveeacademie; Teachers and farmers at PTC+ Oenskerk, De
   Boerengroep, Lars Keizerwaard, Douwe Kappers, Maarten Kea, editors
   Jeffrey Cole and Harvey James and four anonymous reviewers for their
   critical and encouraging comments.
CR Akrich M., 1992, SHAPING TECHNOLOGY B, P205, DOI DOI 10.1111/J.1365-2621.19891B07952.X
   [Anonymous], 2010, VEET
   [Anonymous], 2008, MELKVEEHOUDERS PRIKK
   [Anonymous], 2012, HOARDS DAIRYMAN 0321
   Arendzen I, 2000, ROBOTIC MILKING, P201
   Atkins P. J., 2010, LIQUID MAT HIST MILK
   Bieleman J., 2000, TECHNIEK NEDERLAND T, VIII, P211
   Bijker WE, 1992, SHAPING TECHNOLOGY B
   Boogaard BK, 2011, J AGR ENVIRON ETHIC, V24, P259, DOI 10.1007/s10806-010-9256-4
   Booij A., 2004, VEETEELT, P42
   Borgmann A., 2000, TECHNOLOGY GOOD LIFE, P341
   Brambell F.W.R., 1965, REPORT TECHNICAL COM, P2836
   Buller H, 2012, ANIM WELFARE, V21, P131, DOI 10.7120/096272812X13345905674042
   Crist E, 2004, ENVIRON ETHICS, V26, P5, DOI 10.5840/enviroethics200426138
   Crowell S., 2012, FARM AND DAIRY  0614
   Davies G, 2012, ENVIRON PLANN D, V30, P623, DOI 10.1068/d3211
   Davis K.L., 2002, NZ DAIRY EXPORTER, P54
   De Boer P.B., 1994, 4 MIN LANDB NAT VISS
   De Koning CJAM, 2004, AUTOMATIC MILKING BE, P27
   De Wilde R., 2000, VOORSPELLERS KRITIEK
   Debergh A., 2005, VEETEELT, V22, P50
   Debergh A., 2007, VEETEELT, V24, P26
   DeLaval, 2009, DELAVAL VMS VOL MILK
   Despret V, 2013, HIST THEORY, V52, P29, DOI 10.1111/hith.10686
   Dewey John, 2005, ART EXPERIENCE
   Dohmen W, 2010, J DAIRY SCI, V93, P4019, DOI 10.3168/jds.2009-3028
   Driessen C, 2012, SOC STUD SCI, V42, P797, DOI 10.1177/0306312712457110
   Driessen C, 2012, J AGR ENVIRON ETHIC, V25, P163, DOI 10.1007/s10806-010-9293-z
   FRASER D, 1995, ANIM WELFARE, V4, P103
   Grasbaal, 2009, MELKV HOUD PRIKK
   Hansen P., 2013, J RURAL STUD, V33, P119
   Haraway D. J., 2008, SPECIES MEET
   Harbers H, 2002, PRAGMATIST ETHICS TE, P143
   Hermans G. G. N., 2004, Automatic milking: a better understanding. Conference Proceedings, Lelystad, Netherlands, March 2004, P418
   Heutinck L. F. M., 2004, Automatic milking: a better understanding. Conference Proceedings, Lelystad, Netherlands, March 2004, P407
   Heutinck L.F.M., 2007, 7 C EUR SOC AGR FOOD, P249
   Hiemstra A., 2007, LAAT KOE BAAS ZIJN
   Hird MJ, 2010, ECOL ECON, V69, P737, DOI 10.1016/j.ecolecon.2008.10.011
   Hoefman R., 1998, BOERDERIJ VEEHOUDERI, V84, P18
   Hofs Y., 2010, VOLKSKRANT      0104
   Hogeveen H., 2000, ROB MILK P INT S HEL
   Holloway L., 2013, J RURAL STUD, V33, P131
   Holloway L, 2007, ENVIRON PLANN D, V25, P1041, DOI 10.1068/d77j
   Holloway L, 2014, AGR HUM VALUES, V31, P185, DOI 10.1007/s10460-013-9473-3
   Hopster H, 2002, J DAIRY SCI, V85, P3206, DOI 10.3168/jds.S0022-0302(02)74409-3
   Huiden F., 2009, BOERDERIJ, V94, P21
   Jacobs JA, 2012, J DAIRY SCI, V95, P2227, DOI 10.3168/jds.2011-4943
   James SR, 2009, ENVIRON VALUE, V18, P33, DOI 10.3197/096327109X404735
   Jasanoff S., 2013, STATES KNOWLEDGE COP
   Johnston CL, 2013, GEOGR COMPASS, V7, P139, DOI 10.1111/gec3.12028
   Ketelaar-De Lauwere CC, 1999, NETH J AGR SCI, V47, P1
   KetelaardeLauwere CC, 1996, APPL ANIM BEHAV SCI, V49, P199
   Keulartz J, 2004, SCI TECHNOL HUM VAL, V29, P3, DOI 10.1177/0162243903259188
   Kingmans R., 1999, BOERDERIJ VEEHOUDERI, V84, P8
   Klerkx L., 2012, FARMING SYSTEMS RES, P457, DOI DOI 10.1007/978-94-007-4503-2_20
   Klop A., 2004, VEETEELT, V21, P67
   Kruip TAM, 2002, J DAIRY SCI, V85, P2576, DOI 10.3168/jds.S0022-0302(02)74341-5
   Latour B., 1996, ARAMIS LOVE TECHNOLO
   Latour B, 1992, SHAPING TECHNOLOGY B, P225
   Lorimer J, 2013, GEOFORUM, V48, P249, DOI 10.1016/j.geoforum.2011.09.002
   Mandersloot F., 1991, PRAKTIJKONDERZOEK WA, V4, P28
   Meijering A., 2004, AUTOMATIC MILKING BE
   Millar KM, 2000, J AGR ENVIRON ETHIC, V12, P41, DOI 10.1023/A:1009548025408
   Mons G., 2007, AGRARISCH DAGBL 0323, P7
   Munksgaard L., 2004, Automatic milking: a better understanding. Conference Proceedings, Lelystad, Netherlands, March 2004, P286
   Noordhoff I., 2009, NRC HANDELSBLAD
   Ouweltjes W., 2004, Automatic milking: a better understanding. Conference Proceedings, Lelystad, Netherlands, March 2004, P433
   Prins R., 2006, VEET FOR
   Risan LC, 2005, ENVIRON PLANN D, V23, P787, DOI 10.1068/d359t
   Rodenburg J., TIME TECHNOLOGY ROBO
   Roe E, 2011, ANIM WELFARE, V20, P69
   Rossing W, 1985, 852 IMAG
   Ruis-Heutinck L.F.M., 2001, P 35 INT C ISAE DAV, P188
   Segerdahl P, 2007, J AGR ENVIRON ETHIC, V20, P167, DOI 10.1007/s10806-006-9028-3
   Smink E.C., 2006, MELKV FOR
   Stichting K.O.M., OVERVIEW LIVESTOCK N
   Stuart D, 2013, SOCIOL RURALIS, V53, P201, DOI 10.1111/soru.12005
   Svennersten-Sjaunja KM, 2008, J ANIM SCI, V86, P37, DOI 10.2527/jas.2007-0527
   Swierstra T, 2009, INT LIBR ETH LAW TEC, V3, P119, DOI 10.1007/978-90-481-2229-5_9
   Theunissen B, 2008, J HIST BIOL, V41, P637, DOI 10.1007/s10739-008-9153-0
   Thompson P.B., 2000, TECHNOLOGY GOOD LIFE, P166
   Van Adrichem Boogaert D.H., 1970, ONTWIKKELING NEDERLA
   Van der Knaap J., 2008, VEETEELT, V25, P80
   Van der Knaap J., 2003, VEETEELT, V20, P20
   Van der Knaap J., 2003, VEETEELT, V20, P74
   Van der Ploeg J. D., 2003, VIRTUAL FARMER PRESE
   Van Drie I., 2005, VEETEELT, V22, P64
   Van Drie I., 2003, VEETEELT, V20, P16
   Van Leeuwen R., 2012, SYNC BUSINESSTRENDS
   Van Raay C., 2003, VEETEELT, V20, P14
   Van Zessen T., 2007, VEETEELT, V24, P36
   Veissier I, 2008, APPL ANIM BEHAV SCI, V113, P279, DOI 10.1016/j.applanim.2008.01.008
   Ventura BA, 2013, J DAIRY SCI, V96, P6105, DOI 10.3168/jds.2012-6040
   VERHUE D, 2003, BURGEROORDELEN VEEHO
   von Keyserlingk MAG, 2013, J DAIRY SCI, V96, P5405, DOI 10.3168/jds.2012-6354
   Weisberg Z., 2009, J CRITICAL ANIMAL ST, V7, P22
   Weiss D, 2004, J ANIM SCI, V82, P563
   Whatmore S, 2002, HYBRID GEOGRAPHIES N
   Wiepkema P.R., 1993, GEDRAG WELZIJN DUURZ
   Wiktorsson H., 2004, Automatic milking: a better understanding. Conference Proceedings, Lelystad, Netherlands, March 2004, P371
   Wynsberghe A., 2012, THESIS U TWENTE
   Youker D., 2010, FARM DAIRY      0618
   Zellmer D., 2012, ROBOTIC MILKING SYST
NR 103
TC 11
Z9 11
U1 3
U2 95
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0889-048X
EI 1572-8366
J9 AGR HUM VALUES
JI Agric. Human Values
PD MAR
PY 2015
VL 32
IS 1
BP 3
EP 20
DI 10.1007/s10460-014-9515-5
PG 18
WC Agriculture, Multidisciplinary; History & Philosophy Of Science;
   Sociology
SC Agriculture; History & Philosophy of Science; Sociology
GA AZ0PJ
UT WOS:000347946900002
DA 2019-03-21
ER

PT J
AU Lu, C
AF Lu Chao
TI Robot Ethics in Western Science Fiction
SO FOREIGN LITERATURE STUDIES
LA Chinese
DT Article
DE ethical literary criticism; science fiction; robot ethics
AB Ethical literary criticism has natural close ties with science fiction, and robot ethics is an important research field. In Western literature, human's attitude toward robots has generally undergone three stages: refusing to accept them, confining them to the servant role, and blending human and robot into post-human Cyborg. On the one hand, the prospective description about robots in science fiction can predict the development of related technology, and promote people to rethink the ethical limitations; on the other hand, development in technology also affects the evolution of robot ethics in science fiction.
C1 Tianjin Normal Univ, Coll Literature, Tianjin 300387, Peoples R China.
RP Lu, C (reprint author), Tianjin Normal Univ, Coll Literature, Tianjin 300387, Peoples R China.
EM lvchao_821120@163.com
CR [Anonymous], 2004, FOREIGN LIT STUD, V5, P16
   Capek K. R. U. R., 2011, ROSSUMS UNIVERSAL RO
   Deitch Jeffrey, 1992, POST HUMAN
   HARAWAY D, 1985, SOCIALIST REV, V80, P65
   Hegel Georg, 1981, THE PHENOMENOLOGY OF, VI
   Lyotard Jean Francois, 2001, THE INHUMAN REFLECTI
   Piercy M, 1991, HE SHE AND IT
   Roberts Adam, 2005, THE HISTORY OF SCIEN
NR 8
TC 0
Z9 0
U1 3
U2 10
PU CENTRAL CHINA NORMAL UNIV
PI WUHAN
PA 152 LUOYU RD, WUHAN, 430079, PEOPLES R CHINA
SN 1003-7519
J9 FOREIGN LIT STUD
JI Foreign Lit. Stud.
PD FEB
PY 2015
VL 37
IS 1
BP 34
EP 40
PG 7
WC Literature
SC Literature
GA CD9LJ
UT WOS:000351419500005
DA 2019-03-21
ER

PT J
AU Kernaghan, K
AF Kernaghan, Kenneth
TI The rights and wrongs of robotics: Ethics and robots in public
   organizations
SO CANADIAN PUBLIC ADMINISTRATION-ADMINISTRATION PUBLIQUE DU CANADA
LA English
DT Article
ID MACHINES
AB Some electronics experts believe that robots, like present-day computers, will be commonplace. A diverse assortment of robots, with varying purposes, capacities, forms, and sizes, is emerging with significant implications for the policy, service and regulatory responsibilities of government. This paper explores three public policy fields - aging, health care and defence - where the use of robotics is already substantial or where it is projected to grow substantially and where significant ethical issues exist or are anticipated. Applying ethical theories to the use of robotics is difficult. In the near-term, the focus should be on the ethical standards and behaviour of those designing, manufacturing, programming and operating robots. Several key topics in contemporary public sector ethics, including personal moral responsibility, privacy and accountability, are central to the emerging field of robot ethics. This suggests developing an ethics regime for robotics and examining the need for laws and regulations governing its use.
   Sommaire Certains experts en electronique pensent que les robots, tout comme les ordinateurs d'aujourd'hui, seront bientot chose courante. Tout un assortiment de robots aux objectifs, capacites, formes et tailles variees, est en train de voir le jour, avec des repercussions considerables sur les responsabilites du gouvernement en matiere de politiques, de services et de reglementation. Cet article examine trois domaines de politique publique - le vieillissement, les soins de sante et la defense - dans lesquels l'utilisation de la robotique est deja considerable, ou prevue de s'accroitre enormement et oU d'importantes questions d'ethique existent ou sont anticipees. L'application des theories ethiques a l'utilisation de la robotique est un defi de taille. L'attention a court terme porte sur les normes d'ethique et le comportement des personnes qui interviennent dans la conception, la fabrication, la programmation et le fonctionnement des robots. Plusieurs sujets cles lies a l'ethique dans le secteur public contemporain, notamment la responsabilite morale personnelle, le respect de la vie privee et l'imputabilite, sont essentiels au domaine emergent de l'ethique de la robotique. Cela laisse entendre qu'il est souhaitable de developper un regime d'ethique pour la robotique et d'examiner le besoin d'avoir des lois et des reglements qui en gouvernent l'utilisation.
C1 Brock Univ, St Catharines, ON L2S 3A1, Canada.
RP Kernaghan, K (reprint author), Brock Univ, St Catharines, ON L2S 3A1, Canada.
CR Abney Keith, 2012, ROBOT ETHICS ETHICAL, P39
   Allen C, 2012, INTELL ROBOT AUTON, P55
   Anderson M, 2007, AI MAG, V28, P15
   [Anonymous], 2012, ECONOMIST
   Arkin Ronald, 2007, GOVERNING LETHAL B 3
   Asaro PM, 2006, INT REV INF ETHICS, V6, P9
   Asimov I., 1950, I ROBOT
   Asimov I, 1985, ROBOTS AND EMPIRE
   Bekey GA, 2012, INTELL ROBOT AUTON, P17
   Borenstein J, 2010, ETHICS INF TECHNOL, V12, P277, DOI 10.1007/s10676-010-9236-4
   Calo MR, 2012, INTELL ROBOT AUTON, P187
   Capurro R., 2009, ETHICS AND ROBOTICS
   Clarke R, 1994, ASIMOVS LAWS ROBOTIC
   Coeckelbergh M, 2010, ETHICAL THEORY MORAL, V13, P181, DOI 10.1007/s10677-009-9186-2
   Computing Community Consortium, 2009, ROADM US ROB INT ROB
   Crnkovic GD, 2012, ETHICS INF TECHNOL, V14, P61, DOI 10.1007/s10676-011-9278-2
   Datteri E, 2013, SCI ENG ETHICS, V19, P139, DOI 10.1007/s11948-011-9301-3
   Decker Michael, 2008, ARTIF INTELL, V22, P3315
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   Forlizzi J, 2004, HUM-COMPUT INTERACT, V19, P25, DOI 10.1207/s15327051hci1901&2_3
   Gates Bill, 2007, SCI AM, P58, DOI DOI 10.1038/SCIENTIFICAMERICAN0107-58
   Guizzo E., 2010, WORLD ROBOT POPULATI
   Hirose S, 1996, ROBOT AUTON SYST, V18, P101, DOI 10.1016/0921-8890(95)00074-7
   Holman D. F., 2013, FUTURE DRONES CANADA
   Howlader Daniel, 2011, SYNESIS J SCI TECHNO, V1-G, P6
   Isom J., 2005, BRIEF HIST ROBOTICS
   Levy D, 2012, INTELL ROBOT AUTON, P223
   Levy D, 2009, INT J SOC ROBOT, V1, P209, DOI 10.1007/s12369-009-0022-6
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Lin P, 2011, ATLANTIC
   Lin P., 2008, AUTONOMOUS MILITARY
   Lin P, 2011, ARTIF INTELL, V175, P942, DOI 10.1016/j.artint.2010.11.026
   Lokhorst GJ, 2012, INTELL ROBOT AUTON, P145
   Lovgren S., 2007, NATL GEOGRAPHIC NEWS
   Matthias Andreas, 2011, P TIL TING PERSPECTI
   Merchant Brian, 2013, MOTHERBOARD
   Moor J.H., 2009, PHILOS NOW, V17, P12
   Murphy RR, 2009, IEEE INTELL SYST, V24, P14, DOI 10.1109/MIS.2009.69
   NASA, 2011, ROB MAK ROUNDS
   Robotics Research Group, 2013, ROB HIST TIM
   Robotics VO, 2013, ROADMAP US ROBOTICS
   Roger K, 2012, CAN J AGING, V31, P87, DOI 10.1017/S0714980811000663
   Rosenberg RS, 2008, AI SOC, V22, P367, DOI 10.1007/s00146-007-0148-8
   Scheutz M, 2012, INTELL ROBOT AUTON, P205
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   Sharkey N, 2012, INTELL ROBOT AUTON, P111
   Sharkey N, 2012, GERONTOLOGY, V58, P282, DOI 10.1159/000329483
   Siciliano B., 2008, SPRINGER HDB ROBOTIC
   Singer Peter W., 2009, ISAAC ASIMOVS LAWS R
   Sparrow R, 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Stewart Jon, 2011, BBC NEWS TECHNOLOGY
   Sullins J. P., 2006, INT REV INFORM ETHIC, V6, P24
   Taylor R, 2008, SPRINGER HDB ROBOTIC, P1199, DOI DOI 10.1007/978-3-540-30301-5_53
   Tim Hornyak, 2013, MED ROBOT RP VITA GE
   Tonkens R, 2012, ETHICS INF TECHNOL, V14, P137, DOI 10.1007/s10676-012-9290-1
   Treasury Board of Canada Secretariat, 2011, GUID EXT US WEB 2 0
   Turcu Cristina, 2012, INT J CIRCUITS SYSTE, V6, P430
   Veruggio G, 2012, INTELL ROBOT AUTON, P347
   Wallach Wendell, 2012, ISSUES DEV ROBOTICS
   Wallach Wendell, 2011, LAW INNOVATION TECHN, V3, P185
   Warren Pete, 2006, GUARDIAN
   Whitby B, 2008, INTERACT COMPUT, V20, P326, DOI 10.1016/j.intcom.2008.02.002
   Whitby B, 2012, INTELL ROBOT AUTON, P233
NR 64
TC 5
Z9 5
U1 4
U2 37
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0008-4840
EI 1754-7121
J9 CAN PUBLIC ADMIN
JI Can. Public Adm.-Adm. Publique Can.
PD DEC
PY 2014
VL 57
IS 4
BP 485
EP 506
DI 10.1111/capa.12093
PG 22
WC Public Administration
SC Public Administration
GA AW4TU
UT WOS:000346274100001
DA 2019-03-21
ER

PT J
AU Schildmann, J
   Wascher, S
   Salloch, S
   Ritter, P
   Vollmann, J
AF Schildmann, J.
   Waescher, S.
   Salloch, S.
   Ritter, P.
   Vollmann, J.
TI Supporting ethical decision making in advanced cancer. Methods and first
   findings from the ETHICO (empirical-ethical interventions in oncology)
   project
SO ONCOLOGY RESEARCH AND TREATMENT
LA English
DT Meeting Abstract
C1 [Schildmann, J.; Waescher, S.; Salloch, S.; Vollmann, J.] Ruhr Univ Bochum, Inst Med Eth & Hist Med, Bochum, Germany.
   [Ritter, P.] Hellmig Krankenhaus, Clin Oncol Haematol & Palliat Care, Kamen, Germany.
NR 0
TC 0
Z9 0
U1 0
U2 2
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 2296-5270
EI 2296-5262
J9 ONCOL RES TREAT
JI Oncol. Res. Treat.
PD OCT
PY 2014
VL 37
SU 5
MA V751
BP 243
EP 243
PG 1
WC Oncology
SC Oncology
GA AR8HS
UT WOS:000343816900594
DA 2019-03-21
ER

PT J
AU McDowell, ZJ
AF McDowell, Zachary J.
TI The machine question: Critical perspectives on AI, robots, and ethics
SO NEW MEDIA & SOCIETY
LA English
DT Book Review
C1 [McDowell, Zachary J.] Univ Massachusetts Amherst, Amherst, MA 01003 USA.
RP McDowell, ZJ (reprint author), Univ Massachusetts Amherst, Amherst, MA 01003 USA.
CR Bogost I, 2012, ALIEN PHENOMENOLOGY
   Bryant Levi R., 2011, DEMOCRACY OBJECTS
   Derrida Jacques, 2008, ANIMAL THEREFORE I A
   Galloway A. R., 2012, INTERFACE EFFECT
   Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
   Haraway D. J., 2008, SPECIES MEET
   Kubrick S., 1968, 2001 SPACE ODYSSEY
   Oshii M, 1996, GHOST SHELL
   Scott Ridley, 1982, BLADE RUNNER
NR 9
TC 0
Z9 0
U1 2
U2 17
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1461-4448
EI 1461-7315
J9 NEW MEDIA SOC
JI New Media Soc.
PD SEP
PY 2014
VL 16
IS 6
BP 1041
EP 1043
DI 10.1177/1461444814535723d
PG 3
WC Communication
SC Communication
GA AP1EN
UT WOS:000341809600013
DA 2019-03-21
ER

PT J
AU Sorell, T
   Draper, H
AF Sorell, Tom
   Draper, Heather
TI Robot carers, ethics, and older people
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Robots; Ethics; Telecare; Assistive technology; Autonomy; Nature of
   care; ACCOMPANY
ID EVIDENCE BASE; TELECARE; FUTURE; HEALTH; HEART
AB This paper offers an ethical framework for the development of robots as home companions that are intended to address the isolation and reduced physical functioning of frail older people with capacity, especially those living alone in a noninstitutional setting. Our ethical framework gives autonomy priority in a list of purposes served by assistive technology in general, and carebots in particular. It first introduces the notion of "presence" and draws a distinction between humanoid multi-function robots and non-humanoid robots to suggest that the former provide a more sophisticated presence than the latter. It then looks at the difference between lower-tech assistive technological support for older people and its benefits, and contrasts these with what robots can offer. This provides some context for the ethical assessment of robotic assistive technology. We then consider what might need to be added to presence to produce care from a companion robot that deals with older people's reduced functioning and isolation. Finally, we outline and explain our ethical framework. We discuss how it combines sometimes conflicting values that the design of a carebot might incorporate, if informed by an analysis of the different roles that can be served by a companion robot.
C1 [Sorell, Tom] Univ Warwick, Coventry CV4 7AL, W Midlands, England.
   [Draper, Heather] Univ Birmingham, Sch Hlth & Populat Sci, Birmingham B152TT, W Midlands, England.
RP Draper, H (reprint author), Univ Birmingham, Sch Hlth & Populat Sci, 90 Vincent Dr, Birmingham B152TT, W Midlands, England.
EM T.E.Sorell@warwick.ac.uk; h.draper@bham.ac.uk
OI Draper, Heather/0000-0002-0020-4252
CR Alaszewski A., 2006, PILOTING TELECARE KE
   Bayer S, 2007, SYST DYNAM REV, V23, P61, DOI 10.1002/sdr.361
   Borenstein J, 2010, ETHICS INF TECHNOL, V12, P277, DOI 10.1007/s10676-010-9236-4
   Bowes A., 2006, SMART TECHNOLOGY COM
   Brownsell S, 2003, ASSISTIVE TECHNOLOGY
   Clark RA, 2007, BRIT MED J, V334, P942, DOI 10.1136/bmj.39156.536968.55
   Coeckelbergh M., 2012, CAPABILITY APPROACH, P77
   Coeckelbergh M., 2010, INT J SOCIAL ROBOTS, V1, P217
   Dang S, 2009, TELEMED J E-HEALTH, V15, P783, DOI 10.1089/tmj.2009.0028
   Decker M, 2008, AI SOC, V22, P315, DOI 10.1007/s00146-007-0151-0
   *DEP HLTH, 2008, HIGH QUAL CAR ALL NH
   Department of Health, 2010, BUILD NAT CAR SERV
   Department of Health, 2005, BUILD TEL ENGL
   Dixon RF, 2009, J TELEMED TELECARE, V15, P115, DOI 10.1258/jtt.2009.003003
   Doughty K, 2007, J ASSIST TECHNOL, V1, P6, DOI 10.1108/17549450200700012
   Draper H, 2002, BIOETHICS, V16, P335, DOI 10.1111/1467-8519.00292
   Draper H, 2013, BIOETHICS, V27, P365, DOI 10.1111/j.1467-8519.2012.01961.x
   Fisk MJ, 2003, SOCIAL ALARMS TELECA
   Garcia-Lizana F, 2007, J TELEMED TELECARE, V13, P62, DOI 10.1258/135763307780096140
   Greenhalgh T, 2012, BMJ OPEN, V2, DOI 10.1136/bmjopen-2012-001574
   Lim F. S., 2007, J TELEMED TELECARE, V13, P73, DOI DOI 10.1258/135763307783247257
   Misselhorn C., 2013, J GERONTOPSYCHOLOGY, V26, P121
   Murray E, 2011, IMPLEMENT SCI, V6, DOI 10.1186/1748-5908-6-6
   OECD, 2011, HLTH GLANC 2011 OECD, DOI 10.1787/health_glance-2011-52-en
   Pare G, 2007, J AM MED INFORM ASSN, V14, P269, DOI 10.1197/jamia.M2270
   Parks JA, 2010, HYPATIA, V25, P100, DOI 10.1111/j.1527-2001.2009.01086.x
   Percival J, 2006, CRIT SOC POLICY, V26, P888, DOI 10.1177/0261018306068480
   Perry J, 2009, J MED ETHICS, V35, P81, DOI 10.1136/jme.2008.024588
   Pols J, 2010, HEALTH CARE ANAL, V18, P374, DOI 10.1007/s10728-009-0140-1
   Poole T., 2006, WANLESS SOCIAL CARE
   Robinson L, 2007, HEALTH RISK SOC, V9, P389, DOI 10.1080/13698570701612774
   Rogers A, 2011, SOC SCI MED, V72, P1077, DOI 10.1016/j.socscimed.2011.01.031
   Savenstedt S, 2005, SCAND J CARING SCI, V19, P317, DOI 10.1111/j.1471-6712.2005.00346.x
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   Sorell T, 2012, AM J BIOETHICS, V12, P36, DOI 10.1080/15265161.2012.699137
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Stienstra J., 2012, NORDICHI 2012 C OCT
   Turkle S., 2006, AAAI TECHNOLOGY REPO
   Vallor S., 2011, PHILOS TECHNOLOGY, V24, P254
   van der Plas A, 2010, ACCOUNT RES, V17, P299, DOI 10.1080/08989621.2010.524078
   Woolham J, 2006, SAFE HOME EFFECTIVEN
NR 41
TC 31
Z9 31
U1 7
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD SEP
PY 2014
VL 16
IS 3
BP 183
EP 195
DI 10.1007/s10676-014-9344-7
PG 13
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA AO6YG
UT WOS:000341498200001
OA Other Gold
DA 2019-03-21
ER

PT J
AU Kert, SB
   Uz, C
   Gecii, Z
AF Kert, Serhat Bahachr
   Uz, Cigdem
   Gecii, Zeynep
TI Effectiveness of an Electronic Performance Support System on Computer
   Ethics and Ethical Decision-Making Education
SO EDUCATIONAL TECHNOLOGY & SOCIETY
LA English
DT Article
DE Media in education; Interactive learning environments; Pedagogical
   issues; Higher education; Computer ethics
ID ISSUES; MODEL
AB This study examined the effectiveness of an electronic performance support system (EPSS) on computer ethics education and the ethical decision-making processes. There were five different phases to this ten month study: (1) Writing computer ethics scenarios, (2) Designing a decision-making framework (3) Developing EPSS software (4) Using EPSS in a case-based computer ethics education process (5) Analyzing all of the data collected from the implementation. A total of 15 computer ethics scenarios were written by the researchers and revised in accordance with the opinions of 12 experts from different universities. Barger's (2008) ethical decision-making model was adapted to a flow chart for generating a decision-making framework for the system. Quantitative and qualitative research methods, multivariate analysis of variance and semi-structured interviews were used together to investigate the effectiveness of the system. The results showed that the EPSS that was developed improved the decision-making skills of the students in the experimental group who were faced with different computer ethics scenarios during the implementation of the study. To present a balanced view both positive and negative comments made by the students regarding the EPSS were recorded and are presented in the study.
C1 [Kert, Serhat Bahachr; Uz, Cigdem; Gecii, Zeynep] Yildiz Tekn Univ, Dept Comp Educ & Instruct Technol, Istanbul, Turkey.
RP Kert, SB (reprint author), Yildiz Tekn Univ, Dept Comp Educ & Instruct Technol, Istanbul, Turkey.
EM sbkert@gmail.com; uzcigdem@gmail.com; zgecu@yildiz.edu.tr
OI Gecu-Parmaksiz, Zeynep/0000-0001-5134-1575
CR Barger RN, 2008, COMPUTER ETHICS: A CASE-BASED APPROACH, P1, DOI 10.1017/CBO9780511804151
   Bastiaens T., 1997, TRAINING QUALITY, V5, P10
   Biggerstaff M. A., 2005, Journal of Technology in Human Services, V23, P245, DOI 10.1300/J017v023n03_06
   Bynum T. W., 2001, Ethics and Information Technology, V3, P109, DOI 10.1023/A:1011893925319
   Canadian Psychological Association, 1991, CANADIAN CODE OF ETH
   Coldwell J., 2000, SELECTED PAPERS FROM, P73
   Corey G., 1998, STEPS IN ETHICAL DEC
   Cottone RR, 2001, J COUNS DEV, V79, P39, DOI 10.1002/j.1556-6676.2001.tb01941.x
   Gorniak-Kocikowska K, 1996, SCI ENG ETHICS, V2, P177
   Gotterbam D., 1998, PROCEEDINGS OF THE C, P151
   Grant C., 2009, PAPER PRESENTED AT T
   Johnson D. G., 1999, PAPER PRESENTED AT T
   Kalota F., 2012, BRITISH JOURNAL OF E, V44, P442
   Kohlberg L, 1969, HDB SOCIALIZATION TH, P347
   Levin S., 1994, BASICS OF ELECTRONIC, P3
   Maner W., 1999, METAPHILOSOPHY, V33, P339
   Maner W., 1996, SCI ENG ETHICS, V2, P137, DOI DOI 10.1007/BF02583549
   MASON RO, 1986, MIS QUART, V10, P5, DOI 10.2307/248873
   Mattison M, 2000, SOC WORK, V45, P201, DOI 10.1093/sw/45.3.201
   Milheim W, 1997, BRIT J EDUC TECHNOL, V28, P103, DOI 10.1111/1467-8535.00014
   Moor J. H., 1998, Computers & Society, V28, P14
   MOOR JH, 1985, METAPHILOSOPHY, V16, P266, DOI 10.1111/j.1467-9973.1985.tb00173.x
   Nguyen F, 2008, PERFORM IMPROV Q, V21, P95, DOI 10.1002/piq.20017
   Raybould B., 1990, PERFORMANCE INSTRUCT, V29, P4, DOI DOI 10.1002/PFI.4160291004
   Robinson W., 2000, ETHICAL DECISION MAK
   Sleight D. A., 1993, TYPES OF ELECTRONIC
   Stamatellos G., 2007, COMPUTER ETHICS A GL
   Stephenson JA, 2007, ETHICS BEHAV, V17, P61, DOI 10.1080/10508420701310091
   Uysal O, 2013, BILGISAYAR ETIGI OGR
   van Schaik P, 2002, INNOV EDUC TEACH INT, V39, P289, DOI 10.1080/13558000210161043
   Welfel E. R., 2006, ETHICS IN COUNSELING
NR 31
TC 2
Z9 2
U1 0
U2 9
PU IEEE COMPUTER SOC, LEARNING  TECHNOLOGY TASK FORCE
PI PALMERSTON NORTH
PA BAG 11-222, MASSEY UNIVERSITY, PALMERSTON NORTH, NEW ZEALAND
SN 1436-4522
J9 EDUC TECHNOL SOC
JI Educ. Technol. Soc.
PD JUL
PY 2014
VL 17
IS 3
BP 320
EP 331
PG 12
WC Education & Educational Research
SC Education & Educational Research
GA AQ7BO
UT WOS:000342967800024
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Segedi, M
AF Segedi, Maja
TI Robot ethics: The ethical and social implications of robotics
SO JOURNAL OF EMPIRICAL RESEARCH ON HUMAN RESEARCH ETHICS
LA English
DT Book Review
C1 [Segedi, Maja] Univ Toronto, Toronto, ON M5S 1A1, Canada.
RP Segedi, M (reprint author), Univ Toronto, Toronto, ON M5S 1A1, Canada.
CR LIN KAP, 2012, ROBOT ETHICS ETHICAL
NR 1
TC 0
Z9 0
U1 1
U2 19
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1556-2646
EI 1556-2654
J9 J EMPIR RES HUM RES
JI J. Empir. Res. Hum. Res. Ethics
PD JUL
PY 2014
VL 9
IS 3
BP 91
EP 92
DI 10.1177/1556264614540588
PG 2
WC Ethics; Medical Ethics
SC Social Sciences - Other Topics; Medical Ethics
GA AN6MY
UT WOS:000340709800013
DA 2019-03-21
ER

PT J
AU Tanner, S
   Schleger, HA
   Meyer-Zehnder, B
   Schnurrer, V
   Reiter-Theil, S
   Pargger, H
AF Tanner, S.
   Schleger, H. Albisser
   Meyer-Zehnder, B.
   Schnurrer, V.
   Reiter-Theil, S.
   Pargger, H.
TI Clinical everyday ethics-support in handling moral distress? Evaluation
   of an ethical decision-making model for interprofessional clinical teams
SO MEDIZINISCHE KLINIK-INTENSIVMEDIZIN UND NOTFALLMEDIZIN
LA German
DT Article
DE Situational ethics; Decision making; Interprofessional relations;
   Interview; Evaluation
ID CRITICAL-CARE; NURSES; COLLABORATION; PERCEPTIONS; PHYSICIANS
AB High-tech medicine and cost rationing provoke moral distress up to burnout syndromes. The consequences are severe, not only for those directly involved but also for the quality of patient care and the institutions. The multimodal model METAP (Modular, Ethical, Treatment, Allocation, Process) was developed as clinical everyday ethics to support the interprofessional ethical decision-making process. The distinctive feature of the model lays in education concerning ethics competence in dealing with difficult treatment decisions. METAP has been evaluated for quality testing.
   The research question of interest was whether METAP supports the handling of moral distress. The evaluation included 3 intensive care units and 3 geriatric units. In all, 33 single and 9 group interviews were held with 24 physicians, 44 nurses, and 9 persons from other disciplines. An additional questionnaire was completed by 122 persons (return rate 57 %).
   Two-thirds of the interview answers and 55 % of the questionnaire findings show that clinical everyday ethics supports the handling of moral distress, especially for interdisciplinary communication and collaboration and for the explanation and evaluation of treatment goals. METAP does not provide support for persons who are rarely confronted with ethical problems or have not applied the model long enough yet.
   To a certain degree, moral distress is unavoidable and must be addressed as an interprofessional problem. Herein, clinical everyday ethics may provide targeted support for ethical decision-making competence.
C1 [Tanner, S.; Schleger, H. Albisser; Meyer-Zehnder, B.; Schnurrer, V.; Reiter-Theil, S.] Univ Basel, Inst Bio & Med Eth, Univ Spital, Univ Psychiat Kliniken, CH-4056 Basel, Switzerland.
   [Meyer-Zehnder, B.; Pargger, H.] Univ Spital Basel, Dept Anasthesie Operat Intens Behandlung Praklin, Basel, Switzerland.
RP Tanner, S (reprint author), Univ Basel, Inst Bio & Med Eth, Univ Spital, Univ Psychiat Kliniken, Schanzenstr 13, CH-4056 Basel, Switzerland.
EM sabinetanner3@gmail.com
CR Albisser Schleger H, 2012, KLINISCHE ETHIK META
   Albisser Schleger H, 2013, ETHIK KLINI IN PRESS
   American Association of Critical Care Nurses (AACN), 2014, 4 RIS MOR DISTR
   Badger JM, 2005, AM J CRIT CARE, V14, P513
   Beckstrand RL, 2005, AM J CRIT CARE, V14, P395
   Corley MC, 2002, NURS ETHICS, V9, P636, DOI 10.1191/0969733002ne557oa
   Epstein EG, 2009, J CLIN ETHIC, V20, P330
   Fins JJ, 1999, J PAIN SYMPTOM MANAG, V17, P6, DOI 10.1016/S0885-3924(98)00109-2
   Hamric AB, 2007, CRIT CARE MED, V35, P422, DOI 10.1097/01.CCM.0000254722.50608.2D
   Kalvemark S, 2004, SOC SCI MED, V58, P1075, DOI 10.1016/S0277-9536(03)00279-X
   Lamnek S, 2005, GRUPPENDISKUSSION TH
   Loss J, 2007, PRAVENT GESUNDHEIT, V2, P199, DOI 10.1007/s11553-007-0079-8
   Mayring P., 2000, QUALITATIVE INHALTSA
   Meltzer LS, 2004, AM J CRIT CARE, V13, P202
   Mitchell PH, 2004, MED CARE, V42, P4, DOI 10.1097/01.mlr.0000109122.92479.fe
   Mobley Melinda J, 2007, Intensive Crit Care Nurs, V23, P256, DOI 10.1016/j.iccn.2007.03.011
   Papathanassoglou EDE, 2012, AM J CRIT CARE, V21, pE41, DOI 10.4037/ajcc2012205
   Pauly BM, 2012, HEC FORUM, V24, P1, DOI 10.1007/s10730-012-9176-y
   Piers RD, 2012, J AM MED DIR ASSOC, V13, pe7
   Piers RD, 2011, JAMA-J AM MED ASSOC, V306, P2694, DOI 10.1001/jama.2011.1888
   Puntillo K A, 2001, Am J Crit Care, V10, P216
   Puntillo KA, 2006, CRIT CARE MED, V34, P332
   Raines M L, 2000, JONAS Healthc Law Ethics Regul, V2, P29, DOI 10.1097/00128488-200002010-00006
   Reiter-Theil S, 2011, BIOETHICS, V25, P403, DOI 10.1111/j.1467-8519.2011.01915.x
   Reiter-Theil S, 2011, ETHIK MED, V23, P93, DOI 10.1007/s00481-010-0098-4
   Rice EM, 2008, J NURS MANAGE, V16, P360, DOI 10.1111/j.1365-2834.2007.00798.x
   Schwenzer KJ, 2006, CRIT CARE MED, V34, P2967, DOI 10.1097/01.CCM.0000248879.19054.73
   van der Dam S, 2013, SOC SCI MED, V83, P125, DOI 10.1016/j.socscimed.2013.01.024
   Veer AJ de, 2012, INT J NURS STUD
   Wilkinson Judith M, 1988, Nurs Forum, V23, P16, DOI 10.1111/j.1744-6198.1987.tb00794.x
NR 30
TC 8
Z9 8
U1 0
U2 17
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 2193-6218
J9 MED KLIN-INTENSIVMED
JI Med. Klin.-Intensivmed Notfallmed.
PD JUN
PY 2014
VL 109
IS 5
BP 354
EP 363
DI 10.1007/s00063-013-0327-y
PG 10
WC Medicine, General & Internal
SC General & Internal Medicine
GA AK6ON
UT WOS:000338547100010
PM 24652508
DA 2019-03-21
ER

PT J
AU Headrick, D
AF Headrick, Dan
TI The Ethics and Law of Robots
SO RESEARCH-TECHNOLOGY MANAGEMENT
LA English
DT Editorial Material
EM dan.headrick1@gmail.com
NR 0
TC 1
Z9 1
U1 0
U2 4
PU INDUSTRIAL RESEARCH INST, INC
PI ARLINGTON
PA 2300 CLARENDON BLVD, STE 400, ARLINGTON, VA 22201 USA
SN 0895-6308
EI 1930-0166
J9 RES TECHNOL MANAGE
JI Res.-Technol. Manage.
PD MAY-JUN
PY 2014
VL 57
IS 3
BP 6
EP 7
PG 2
WC Business; Engineering, Industrial; Management
SC Business & Economics; Engineering
GA AI8XY
UT WOS:000337211500003
DA 2019-03-21
ER

PT J
AU Bogue, R
AF Bogue, Robert
TI Robot ethics and law Part two: law
SO INDUSTRIAL ROBOT-AN INTERNATIONAL JOURNAL
LA English
DT Article
DE Robots; Law; Legislation; Liability
AB Purpose - This is the second part of a two-part paper which aims to provide an insight into the ethical and legal issues surrounding certain classes of robot. This part is concerned with law.
   Design/methodology/approach - Following an introduction, this paper first describes the European RoboLaw project and then considers legal issues and activities relating to civilian airborne drones, driverless road vehicles and assistive robots. It concludes with a short discussion.
   Findings - The legal issues associated with many classes of robot are the topic of much debate, and efforts are underway to create appropriate legislative frameworks. A project is presently seeking to create a framework for the development of a Europe-wide "Robolaw" and in certain cases, laws are already being formulated to accommodate recent robotic developments. These deliberations are rapidly gaining pace and are now also considering future generations of highly autonomous and intelligent robots.
   Originality/value - This paper provides an insight into the highly topical and complex issue of robot law.
EM robbogue@aol.com
NR 0
TC 1
Z9 1
U1 2
U2 25
PU EMERALD GROUP PUBLISHING LIMITED
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 0143-991X
EI 1758-5791
J9 IND ROBOT
JI Ind. Robot
PY 2014
VL 41
IS 5
BP 398
EP 402
DI 10.1108/IR-04-2014-0332
PG 5
WC Engineering, Industrial; Robotics
SC Engineering; Robotics
GA AR1FI
UT WOS:000343330300002
DA 2019-03-21
ER

PT J
AU Bogue, R
AF Bogue, Robert
TI Robot ethics and law Part one: ethics
SO INDUSTRIAL ROBOT-AN INTERNATIONAL JOURNAL
LA English
DT Article
DE Robots; Ethics; Roboethics; Autonomy; Drones
AB Purpose - This first part of a two-part paper aims to provide an insight into the ethical and legal issues associated with certain classes of robot. This part is concerned with ethics.
   Design/methodology/approach - Following an introduction, this paper first considers the ethical deliberations surrounding robots used in warfare and healthcare. It then addresses the issue of robot truth and deception and subsequently discusses some on-going deliberations and possible ways forward. Finally, brief conclusions are drawn.
   Findings - Robot ethics are the topic of wide-ranging debate and encompass such diverse applications as military drones and robotic carers. Many ethical considerations have been raised including philosophical issues such as moral behaviour and truth and deception. Preliminary research suggests that some of these concerns may be ameliorated through the use of software which encompasses ethical principles. It is widely recognised that a multidisciplinary approach is required and there is growing evidence of this.
   Originality/value - This paper provides an insight into the highly topical and complex issue of robot ethics.
EM robbogue@aol.com
NR 0
TC 1
Z9 1
U1 2
U2 26
PU EMERALD GROUP PUBLISHING LIMITED
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 0143-991X
EI 1758-5791
J9 IND ROBOT
JI Ind. Robot
PY 2014
VL 41
IS 4
BP 335
EP 339
DI 10.1108/IR-04-2014-0328
PG 5
WC Engineering, Industrial; Robotics
SC Engineering; Robotics
GA AP0VP
UT WOS:000341784300002
DA 2019-03-21
ER

PT J
AU Brundage, M
AF Brundage, Miles
TI Limitations and risks of machine ethics
SO JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE machine ethics; risk; artificial general intelligence
AB Many authors have proposed constraining the behaviour of intelligent systems with 'machine ethics' to ensure positive social outcomes from the development of such systems. This paper critically analyses the prospects for machine ethics, identifying several inherent limitations. While machine ethics may increase the probability of ethical behaviour in some situations, it cannot guarantee it due to the nature of ethics, the computational limitations of computational agents and the complexity of the world. In addition, machine ethics, even if it were to be 'solved' at a technical level, would be insufficient to ensure positive social outcomes from intelligent systems.
C1 Arizona State Univ, Consortium Sci Policy & Outcomes, Tempe, AZ 85287 USA.
RP Brundage, M (reprint author), Arizona State Univ, Consortium Sci Policy & Outcomes, Tempe, AZ 85287 USA.
EM miles.brundage@asu.edu
CR Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   Allen Colin, 2010, MORAL MACHINES TEACH
   Allenby B., 2011, NEW SCI, V2812, P28
   Allenby Brad, 2009, IEEE INT S SUST SYST
   Anderson M., 2011, MACHINE ETHICS
   [Anonymous], 2012, LOS HUM CAS KILL ROB
   Arkin R., 2009, GOVERNING LETHAL BEH
   Berker S, 2009, PHILOS PUBLIC AFF, V37, P293, DOI 10.1111/j.1088-4963.2009.01164.x
   Berlin Isaiah, 1991, CROOKED TIMBER HUMAN
   Boehm Ch, 2012, MORAL ORIGINS EVOLUT
   Bringsjord S., 2011, MACHINE ETHICS, P361
   Bringsjord S, 2009, UNETHICAL RULE BOUND
   Bringsjord S., 2012, PHILOS MAG, V57, P90
   Bringsjord S., 2012, TOPOI
   Cloos C., 2005, UTILIBOT PROJECT AUT
   Crouch W., 2012, MOST IMPORTANT UNSOL
   Cushman F. A., 2012, MORAL PSYCHOL HDB, P47
   Darwin C, 1871, DESCENT MAN SELECTIO
   Deghani M., 2011, MACHINE ETHICS, P422
   Freeman T, 2009, USING COMPASSION RES
   Gert B, 2007, COMMON MORALITY DECI
   Gigerenzer G, 2010, TOP COGN SCI, V2, P528, DOI 10.1111/j.1756-8765.2010.01094.x
   Goertzel B, 2006, APPARENT LIMITATIONS
   Gomila A, 2009, HDB RES SYNTHETIC EM, P166
   GOWANS C.W, 1987, MORAL DILEMMAS
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81
   Guarini M., 2011, MACHINE ETHICS, P316
   Haidt J, 2012, RIGHTEOUS MIND WHY G
   Hanson R., 2001, J ARTIFICIAL INTELLI
   Helbing D., 2010, SYSTEMIC RISKS SOC E
   Horgan T, 2009, ETHICAL THEORY MORAL, V12, P25, DOI 10.1007/s10677-008-9142-6
   Klein C, 2011, NEUROETHICS-NETH, V4, P143, DOI 10.1007/s12152-010-9077-1
   Lenman J, 2000, PHILOS PUBLIC AFF, V29, P342, DOI 10.1111/j.1088-4963.2000.00342.x
   Mackworth A., 2011, MACHINE ETHICS, P335
   Matthias A., 2011, LAW INNOVATION TECHN, V3, P279
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   McLaren B. N., 2011, MACHINE ETHICS, P297
   Muller VC, 2012, COGN COMPUT, V4, P212, DOI 10.1007/s12559-012-9129-4
   Omohundro SM, 2008, FRONT ARTIF INTEL AP, V171, P483
   Parfit Derek, 2011, ON WHAT MATTERS, VOne
   Pojman L.P, 2005, ETHICS DISCOVERING R
   Pontier MA, 2012, LECT NOTES ARTIF INT, V7637, P442, DOI 10.1007/978-3-642-34654-5_45
   Powers T, 2011, MACHINE ETHICS, P464
   Reynolds C. J., 2005, COMP ETH PHIL ENQ
   Ross W. D., 1988, RIGHT GOOD
   Sarewitz D, 2008, NATURE, V456, P871, DOI 10.1038/456871a
   Savulescu J, 2012, UNFIT FUTURE NEED MO
   Shaw W.H., 1999, CONT ETHICS TAKING A
   Shulman C., 2010, OMOHUNDROS BASIC AI
   Shulman C., 2009, P AP CAP 2009, P23
   Sinnott-Armstrong W., 1988, MORAL DILEMMAS PHILO
   Sotala Kaj, 2013, 20132 MACH INT RES I
   Taleb N.N., 2007, BLACK SWAN
   Tarleton N, 2010, COHERENT EXTRAPOLATE
   Tosic P., 2005, P 3 EUR WORKSH MULT, P415
   Wallach W., 2010, MORAL MACHINES TEACH
   Wang P, 2006, APPL LOG SER, V34, P3
   Waser M., 2011, LECT NOTES COMPUTER, V6830, P153
   Williams B., 1973, UTILITARIANISM
   Williams B., 1973, PROBLEMS SELF
   WOLF S, 1982, J PHILOS, V79, P419, DOI 10.2307/2026228
   Yudkowsky E., 2007, ARTIFICIAL GEN INTEL, P389
   Yudkowsky E., 2011, P 4 C ART GEN INT AG, P388
   Yudkowsky Eliezer, 2001, CREATING FRIENDLY AI
NR 64
TC 5
Z9 5
U1 7
U2 51
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0952-813X
EI 1362-3079
J9 J EXP THEOR ARTIF IN
JI J. Exp. Theor. Artif. Intell.
PY 2014
VL 26
IS 3
SI SI
BP 355
EP 372
DI 10.1080/0952813X.2014.895108
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA AJ9EF
UT WOS:000338009300005
DA 2019-03-21
ER

PT J
AU Scheutz, M
AF Scheutz, Matthias
TI What Is Robot Ethics?
SO IEEE ROBOTICS & AUTOMATION MAGAZINE
LA English
DT Editorial Material
CR Briggs G., 2012, P C SOC ROB, P238
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Veruggio G., 2011, IEEE ROBOT AUTOMAT M, V18
NR 3
TC 5
Z9 5
U1 2
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1070-9932
EI 1558-223X
J9 IEEE ROBOT AUTOM MAG
JI IEEE Robot. Autom. Mag.
PD DEC
PY 2013
VL 20
IS 4
BP 20
EP +
DI 10.1109/MRA.2013.2283184
PG 2
WC Automation & Control Systems; Robotics
SC Automation & Control Systems; Robotics
GA 274YK
UT WOS:000328641900006
DA 2019-03-21
ER

PT J
AU Guarini, M
AF Guarini, Marcello
TI Introduction: Machine Ethics and the Ethics of Building Intelligent
   Machines
SO TOPOI-AN INTERNATIONAL REVIEW OF PHILOSOPHY
LA English
DT Article
C1 Univ Windsor, Windsor, ON N9B 3P4, Canada.
RP Guarini, M (reprint author), Univ Windsor, Windsor, ON N9B 3P4, Canada.
EM mguarini@uwindsor.ca
CR Anderson M, 2011, MACHINE ETHICS, P7
   Anderson M., 2011, MACHINE ETHICS
   Anderson M., 2011, MACHINE ETHICS, P1
   Anderson M, 2007, AI MAG, V28, P15
   Anderson S.L., 2011, MACHINE ETHICS, P21
   Danielson P., 1992, ARTIFICIAL MORALITY
   Dennett Daniel, 1978, BRAINSTORMS PHILOS E
   Guarini M., 2011, MACHINE ETHICS, P316
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Turing A., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433
   Veruggio G, 2012, INTELL ROBOT AUTON, P347
   Wallach W., 2009, MORAL MACHINES TEACH
NR 12
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0167-7411
J9 TOPOI-INT REV PHILOS
JI Topoi-Int. Rev. Philos.
PD OCT
PY 2013
VL 32
IS 2
BP 213
EP 215
DI 10.1007/s11245-013-9183-x
PG 3
WC Philosophy
SC Philosophy
GA 221CI
UT WOS:000324634600011
OA Bronze
DA 2019-03-21
ER

PT J
AU Coeckelbergh, M
AF Coeckelbergh, Mark
TI The machine question: critical perspectives on AI, robots, and ethics
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Book Review
C1 [Coeckelbergh, Mark] Univ Twente, Dept Philosophy, NL-7500 AE Enschede, Netherlands.
RP Coeckelbergh, M (reprint author), Univ Twente, Dept Philosophy, POB 217, NL-7500 AE Enschede, Netherlands.
EM m.coeckelbergh@utwente.nl
OI Coeckelbergh, Mark/0000-0001-9576-1002
CR Benso S., 2000, FACE THINGS DIFFEREN
   BIRCH TH, 1993, ENVIRON ETHICS, V15, P313, DOI 10.5840/enviroethics19931544
   Calerco Matthew, 2008, ZOOGRAPHIES QUESTION
   Coeckelbergh M, 2012, GROWING MORAL RELATIONS: CRITIQUE OF MORAL STATUS ASCRIPTION, P1, DOI 10.1057/9781137025968
   Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
   Haraway D. J., 2008, SPECIES MEET
   Torrance S., 2012, S MACH QUEST AI ETH
NR 7
TC 1
Z9 1
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD SEP
PY 2013
VL 15
IS 3
BP 235
EP 238
DI 10.1007/s10676-012-9305-y
PG 4
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 209GV
UT WOS:000323744300007
DA 2019-03-21
ER

PT J
AU Hellstrom, T
AF Hellstrom, Thomas
TI On the moral responsibility of military robots
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Moral responsibility; Robots; Military robots; Autonomy; Robot ethics
AB This article discusses mechanisms and principles for assignment of moral responsibility to intelligent robots, with special focus on military robots. We introduce the concept autonomous power as a new concept, and use it to identify the type of robots that call for moral considerations. It is furthermore argued that autonomous power, and in particular the ability to learn, is decisive for assignment of moral responsibility to robots. As technological development will lead to robots with increasing autonomous power, we should be prepared for a future when people blame robots for their actions. It is important to, already today, investigate the mechanisms that control human behavior in this respect. The results may be used when designing future military robots, to control unwanted tendencies to assign responsibility to the robots. Independent of the responsibility issue, the moral quality of robots' behavior should be seen as one of many performance measures by which we evaluate robots. How to design ethics based control systems should be carefully investigated already now. From a consequentialist view, it would indeed be highly immoral to develop robots capable of performing acts involving life and death, without including some kind of moral framework.
C1 Umea Univ, Dept Comp Sci, Umea, Sweden.
RP Hellstrom, T (reprint author), Umea Univ, Dept Comp Sci, Umea, Sweden.
EM thomash@cs.umu.se
CR ABIresearch, 2011, MIL ROB MARK EXC 8 B
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83
   Aristotle, 1985, NICOMACHEAN ETHICS
   Arkin R., 2009, GOVERNING LETHAL BEH
   Arkin RC, 2009, IEEE TECHNOL SOC MAG, V28, P30, DOI 10.1109/MTS.2009.931858
   Asaro P. M., 2006, IRIE INT REV INFORM, V6
   BECHTEL W, 1985, METAPHILOSOPHY, V16, P296, DOI 10.1111/j.1467-9973.1985.tb00176.x
   Bone E, 2003, UNMANNED AERIAL VEHI
   Connolly William E, 1974, TERMS POLITICAL DISC
   Dennett D. C., 1997, HALS LEGACY 2001S CO
   Dennett Daniel Clement, 1973, ESSAYS FREEDOM ACTIO
   Dodig-Crnkovic G., 2008, FRONTIERS ARTIFICIAL, V173
   Eshleman Andrew, 2009, MORAL RESPONSIBILITY
   Franklin S., 1997, Intelligent Agents III. Agent Theories, Architectures, and Languages. ECAI '96 Workshop (ATAL) Proceedings, P21
   Friedman B., 1990, MORAL RESPONSIBILITY
   Friedman B., 1997, REASONING COMPUTERS
   Friedman B., 1995, C COMP C HUM FACT CO, P226, DOI 10.1145/223355.223537
   GlobalSecurity, 2012, TALON SMALL MOB ROB
   Grossman N., 2007, GEORGETOWN J INT LAW, V38, P323
   Hertzberg  J., 2008, SPRINGER HDB ROBOTIC, P207, DOI 10.1007/978-3-540-30301-5_10
   Hildebrand A., 2009, SAMSUNG TECHWINS LAT
   Hinds PJ, 2004, HUM-COMPUT INTERACT, V19, P151, DOI 10.1207/s15327051hci1901&2_7
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5
   Kim T., 2006, P 15 IEEE INT S ROB, P80
   Lin P., 2008, AUTONOMOUS MILITARY
   Mataric M.J., 2008, SPRINGER HDB ROBOTIC, P891, DOI DOI 10.1007/9783-540-30301-5_39
   Matthias A., 2004, Ethics and Information Technology, V6, P175, DOI 10.1007/s10676-004-3422-1
   Miller KW, 2011, IT PROF, V13, P57, DOI 10.1109/MITP.2011.46
   Moon Y, 1998, INT J HUM-COMPUT ST, V49, P79, DOI 10.1006/ijhc.1998.0199
   Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354
   QineticQ, 2012, MAARS MOD ADV ARM RO
   Riedel F. W., 2010, J HOPKINS APL TECHNI, V29
   Samsung, 2012, SGR 1
   Sheridan TB, 1992, TELEROBOTICS AUTOMAT
   Singer P. W., 2009, NEW ATLANTIS
   Singer P. W., 2009, WIRED WAR ROBOTICS R
   Singer P. W., 2009, JFQ JOINT FORCE Q, V1, P104
   Sofge E., 2009, AM ROBOT ARMY ARE UN
   Sparrow R, 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X
   Stahl B. C., 2004, RESPONSIBLE MANAGEME
   Strawson P. F., 1974, FREEDOM RESENTMENT F
   Sutton RS, 1998, REINFORCEMENT LEARNI
   Thorndike E. L., 1911, ANIMAL INTELLIGENCE
   U.S. Air Force, 2006, REAP MON GIV MQ 9 UN
   U.S. Navy, 2011, MK 15 PHAL CLOS IN W
   United States Air Force, 2009, UNM AIRCR SYST FLIGH
   Walzer M, 2006, JUST UNJUST WARS MOR
   Wezeman S, 2007, UAVS UCAVS DEV EUROP
   Yamauchi B, 2004, P SPIE, V5422
   Yamauchi B., 2002, P 23 ARM SCI C US AR
   Young IM, 2010, RESPONSIBILITY IN CONTEXT: PERSPECTIVES, P53, DOI 10.1007/978-90-481-3037-5_5
NR 51
TC 18
Z9 19
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD JUN
PY 2013
VL 15
IS 2
SI SI
BP 99
EP 107
DI 10.1007/s10676-012-9301-2
PG 9
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 173FA
UT WOS:000321062300004
DA 2019-03-21
ER

PT J
AU Singh, I
AF Singh, Ilina
TI Not robots: children's perspectives on authenticity, moral agency and
   stimulant drug treatments
SO JOURNAL OF MEDICAL ETHICS
LA English
DT Article
ID ATTENTION DEFICIT/HYPERACTIVITY DISORDER; ADHD; PREVALENCE
AB In this article, I examine children's reported experiences with stimulant drug treatments for attention deficit hyperactivity disorder in light of bioethical arguments about the potential threats of psychotropic drugs to authenticity and moral agency. Drawing on a study that involved over 150 families in the USA and the UK, I show that children are able to report threats to authenticity, but that the majority of children are not concerned with such threats. On balance, children report that stimulants improve their capacity for moral agency, and they associate this capacity with an ability to meet normative expectations. I argue that although under certain conditions stimulant drug treatment may increase the risk of a threat to authenticity, there are ways to minimise this risk and to maximise the benefits of stimulant drug treatment. Medical professionals in particular should help children to flourish with stimulant drug treatments, in good and in bad conditions.
C1 Kings Coll London, Dept Social Sci Hlth & Med, London WC2R 2LS, England.
RP Singh, I (reprint author), Kings Coll London, Dept Social Sci Hlth & Med, Kings Bldg, London WC2R 2LS, England.
EM i.a.singh@lse.ac.uk
OI Singh, Ilina/0000-0003-4497-3587
FU Wellcome Trust [08029]
FX Thanks to the VOICES study research assistants, our clinical
   collaborators and the UK MHRN. Huge gratitude to the children, parents,
   relatives and doctors who participated in the study. Special thanks to
   Hanna Pickard and the OCN reading group for insightful comments and
   careful reading of drafts. Thanks also to Brocher meeting participants
   for helpful discussions on authenticity. VOICES is funded by a Wellcome
   Trust university award no. 08029.
CR Bronfenbrenner U., 1979, ECOLOGY HUMAN DEV
   CONRAD P, 1992, ANNU REV SOCIOL, V18, P209, DOI 10.1146/annurev.so.18.080192.001233
   Conrad Peter, 2007, MEDICALIZATION SOC
   DeGrazia D, 2005, HUMAN IDENTITY BIOET
   Elliott C., 1993, ENHANCING HUMAN TRAI
   Elliott C, 2003, BETTER WELL AM MED M
   Erler A, 2012, J APPL PHILOS, V29, P257, DOI 10.1111/j.1468-5930.2012.00562.x
   *FOR MENT CAP WELL, 2008, FIN PROJ REP
   Fukuyama Francis, 2002, OUR POSTHUMAN FUTURE
   Horwitz A., 2002, CREATING MENTAL ILLN
   Karp D.A., 2006, IS IT ME MY MEDS LIV
   KRAMER PD, 1993, LISTENING PROZAC
   Kureishi H, 2012, NY TIMES
   Levy N, 2011, J APPL PHILOS, V28, P308, DOI 10.1111/j.1468-5930.2011.00532.x
   Luhrmann TM, 2000, 2 KINDS ANTHR LOOKS
   Parens E, 2005, HASTINGS CENT REP, V35, P34, DOI 10.2307/3528804
   Polanczyk G, 2007, AM J PSYCHIAT, V164, P942, DOI 10.1176/appi.ajp.164.6.942
   Pres. Counc. Bioeth, 2003, THER BIOT PURS HAPP
   Scheffler RM, 2007, HEALTH AFFAIR, V26, P450, DOI 10.1377/hlthaff.26.2.450
   Shonkoff JP, 2011, EARLY CHILDHOOD ADVE, DOI [10.1542/peds.2011-2662, DOI 10.1542/PEDS.2011-2662]
   Singh I, 2005, AM J BIOETHICS, V5, P34, DOI 10.1080/15265160590945129
   Singh I, 2007, MEDICATING MODERN AM
   Singh I, 2011, SOC SCI MED, V73, P889, DOI 10.1016/j.socscimed.2011.03.049
   Vasconcelos MM, 2003, ARQ NEURO-PSIQUIAT, V61, P67, DOI 10.1590/S0004-282X2003000100012
   Zito Julie M, 2008, Child Adolesc Psychiatry Ment Health, V2, P26, DOI 10.1186/1753-2000-2-26
NR 25
TC 27
Z9 29
U1 1
U2 16
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0306-6800
J9 J MED ETHICS
JI J. Med. Ethics
PD JUN
PY 2013
VL 39
IS 6
BP 359
EP 366
DI 10.1136/medethics-2011-100224
PG 8
WC Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical
SC Social Sciences - Other Topics; Medical Ethics; Social Issues;
   Biomedical Social Sciences
GA 148SI
UT WOS:000319267200002
PM 22930677
OA Other Gold, Green Published
DA 2019-03-21
ER

PT J
AU Rose, S
AF Rose, Steven
TI Commentary on Singh: Not Robots: children's perspectives on
   authenticity, moral agency and stimulant drug treatments
SO JOURNAL OF MEDICAL ETHICS
LA English
DT Editorial Material
C1 Open Univ, Dept Life Hlth & Chem Sci, Milton Keynes MK7 6AA, Bucks, England.
RP Rose, S (reprint author), Open Univ, Dept Life Hlth & Chem Sci, Milton Keynes MK7 6AA, Bucks, England.
EM s.p.r.rose@open.ac.uk
CR Alderson P., 2004, ETHICS SOCIAL RES CO
   Rose Steven, 1984, NOT IN OUR GENES
   Singh I, 2013, J MED ETHICS, V39, P359, DOI 10.1136/medethics-2011-100224
   Wender PH, 1971, MINIMAL BRAIN DYSFUN
NR 4
TC 2
Z9 2
U1 1
U2 3
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0306-6800
J9 J MED ETHICS
JI J. Med. Ethics
PD JUN
PY 2013
VL 39
IS 6
BP 371
EP 371
DI 10.1136/medethics-2012-100961
PG 1
WC Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical
SC Social Sciences - Other Topics; Medical Ethics; Social Issues;
   Biomedical Social Sciences
GA 148SI
UT WOS:000319267200005
PM 23143998
DA 2019-03-21
ER

PT J
AU Bancroft, TD
AF Bancroft, Tyler D.
TI Ethical Aspects of Computational Neuroscience
SO NEUROETHICS
LA English
DT Article
DE Ethics; Computational neuroscience; Simulation; Neuroethics;
   Organizational invariance
ID SPIKING NEURONS; MODEL; CONSCIOUSNESS; PAIN
AB Recent research in computational neuroscience has demonstrated that we now possess the ability to simulate neural systems in significant detail and on a large scale. Simulations on the scale of a human brain have recently been reported. The ability to simulate entire brains (or significant portions thereof) would be a revolutionary scientific advance, with substantial benefits for brain science. However, the prospect of whole-brain simulation comes with a set of new and unique ethical questions. In the present paper, we briefly outline certain of those problems and emphasize the need to begin considering the ethical aspects of computational neuroscience.
C1 Wilfrid Laurier Univ, Dept Psychol, Waterloo, ON N2L 3C5, Canada.
RP Bancroft, TD (reprint author), Wilfrid Laurier Univ, Dept Psychol, 75 Univ Ave West, Waterloo, ON N2L 3C5, Canada.
EM banc6110@mylaurier.ca
CR Block N., 1997, NATURE CONSCIOUSNESS
   Burd L, 1998, J MED ETHICS, V24, P118, DOI 10.1136/jme.24.2.118
   Chalmers D. J., 1995, CONSCIOUS EXPERIENCE, P309
   Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Izhikevich EM, 2008, P NATL ACAD SCI USA, V105, P3593, DOI 10.1073/pnas.0712231105
   Kozlov A, 2009, P NATL ACAD SCI USA, V106, P20027, DOI 10.1073/pnas.0906722106
   Moravec H., 1988, MIND CHILDREN
   Pakkenberg B, 1997, J COMP NEUROL, V384, P312, DOI 10.1002/(SICI)1096-9861(19970728)384:2<312::AID-CNE10>3.0.CO;2-K
   Schnitzler A, 2000, J CLIN NEUROPHYSIOL, V17, P592, DOI 10.1097/00004691-200011000-00005
   SEARLE John, 1999, MIND LANGUAGE SOC
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00005756
   Singer W, 1998, PHILOS T ROY SOC B, V353, P1829, DOI 10.1098/rstb.1998.0335
   Singer W, 2001, ANN NY ACAD SCI, V929, P123
   Treede RD, 1999, PAIN, V79, P105, DOI 10.1016/S0304-3959(98)00184-5
   Turing A., 1950, MIND, V59, P455
NR 16
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1874-5490
J9 NEUROETHICS-NETH
JI Neuroethics
PD APR
PY 2013
VL 6
IS 2
BP 415
EP 418
DI 10.1007/s12152-012-9163-7
PG 4
WC Ethics; Medical Ethics; Social Sciences, Biomedical
SC Social Sciences - Other Topics; Medical Ethics; Biomedical Social
   Sciences
GA 131GA
UT WOS:000317979500013
DA 2019-03-21
ER

PT J
AU Dzwonkowska, D
AF Dzwonkowska, Dominika
TI The Machine Question: Critical Perspectives on AI, Robots, and Ethics
SO INTERNATIONAL PHILOSOPHICAL QUARTERLY
LA English
DT Book Review
C1 [Dzwonkowska, Dominika] Cardinal Stefan Wyszynski Univ, Warsaw, Poland.
RP Dzwonkowska, D (reprint author), Cardinal Stefan Wyszynski Univ, Warsaw, Poland.
CR Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
NR 1
TC 1
Z9 1
U1 1
U2 7
PU PHILOSOPHY DOCUMENTATION CENTER
PI CHARLOTTESVILLE
PA PO BOX 7147, CHARLOTTESVILLE, VA 22906-7147 USA
SN 0019-0365
J9 INT PHILOS QUART
JI Int. Philos. Q.
PD MAR
PY 2013
VL 53
IS 1
BP 91
EP 93
DI 10.5840/ipq201353110
PG 3
WC Philosophy
SC Philosophy
GA 139MO
UT WOS:000318587000009
DA 2019-03-21
ER

PT J
AU Gottlieb, JD
AF Gottlieb, Jeffrey D.
TI The Machine Question: Critical Perspectives on AI, Robots, and Ethics.
SO ETHICS & BEHAVIOR
LA English
DT Book Review
C1 [Gottlieb, Jeffrey D.] Florida State Univ, Tallahassee, FL 32306 USA.
RP Gottlieb, JD (reprint author), Florida State Univ, Tallahassee, FL 32306 USA.
CR Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
   Kubrick S, 1968, 2001 SPACE ODYSSEY M
   Proyas A., 2004, I ROBOT MOTION PICTU
NR 3
TC 0
Z9 0
U1 2
U2 9
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND
SN 1050-8422
J9 ETHICS BEHAV
JI Ethics Behav.
PD MAR 1
PY 2013
VL 23
IS 2
BP 163
EP 166
DI 10.1080/10508422.2012.756707
PG 4
WC Ethics; Psychology, Multidisciplinary
SC Social Sciences - Other Topics; Psychology
GA 097QK
UT WOS:000315488400006
DA 2019-03-21
ER

PT J
AU van Wynsberghe, A
AF van Wynsberghe, Aimee
TI A method for integrating ethics into the design of robots
SO INDUSTRIAL ROBOT-AN INTERNATIONAL JOURNAL
LA English
DT Article
DE Robot ethics; Value-sensitive design; Care robots; Ethics and design;
   Design and robots; Robots; Ethics
ID CARE
AB Purpose - With the rapid and pervasive introduction of robots into human environments, ethics scholars along with roboticists are asking how ethics can be applied to the discipline of robotics. The purpose of this paper is to provide a concrete example of incorporating ethics into the design process of a robot in healthcare.
   Design/methodology/approach - The approach for including ethics in the design process of care robots used in this paper is called the Care-Centered Value Sensitive Design (CCVSD) approach. The CCVSD approach presented here provides both an outline of the components demanding ethical attention as well as a step-by-step manner in which such considerations may proceed in a prospective manner throughout the design process of a robot. This begins from the moment of idea generation and continues throughout the design of various prototypes. In this paper, this approach's utility and prospective methodology are illustrated by proposing a novel care robot, the "wee-bot", for the collection and testing of urine samples in a hospital context.
   Findings - The results of applying the CCVSD approach inspired the design of a novel robot for the testing of urine in pediatric oncology patients - the "wee-bot" robot - and showed that it is possible to successfully incorporate ethics into the design of a care robot by exploring and prescribing design requirements. In other words, the use of the CCVSD approach allowed for the translation of ethical values into technical design requirements as was shown in this paper.
   Practical implications - This paper provides a practical solution to the question of how to incorporate ethics into the design of robots and bridges the gap between the work of roboticists and robot ethicists so that they may work together in the design of a novel care robot. Social implications - In providing a solution to the issue of how to address ethical issues in the design of robots, the aim is to mitigate issues of societal concern regarding the design, development and implementation of robots in healthcare.
   Originality/value - This paper is the first and only presentation of a concrete prospective methodology for including ethics into the design of robots. While the example given here is tailored to the healthcare context, the approach can be adjusted to fit another context and/or robot design.
C1 Univ Twente, Dept Philosophy, NL-7500 AE Enschede, Netherlands.
RP van Wynsberghe, A (reprint author), Univ Twente, Dept Philosophy, POB 217, NL-7500 AE Enschede, Netherlands.
EM aimeevanrobot@gmail.com
CR Asaro P., 2006, INT REV INFORM ETHIC, V6, P8
   Coeckelbergh M, 2010, ETHICAL THEORY MORAL, V13, P181, DOI 10.1007/s10677-009-9186-2
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   Friedman B, 2006, ADV MANAG INFORM SYS, V5, P348
   Kawamoto H., 2002, P 8 INT C COMP HELP, P196
   Kazerooni H., 2008, SPRINGER HDB ROBOTIC, P773
   Le Dante C.A., 2009, VALUES LIVED EXPERIE, P1141
   Lin P, 2012, INTELL ROBOT AUTON, P1
   Lo AC, 2010, NEW ENGL J MED, V362, P1772, DOI 10.1056/NEJMoa0911341
   Meadows M.S., 2011, WE ROBOT SKYWALKERS
   Mutlu B., 2008, P HRI 08
   Nicklin Wendy, 2002, Can J Nurs Leadersh, V15, P11
   Nissenbaum H., 2001, IEEE COMPUTER
   Onishi M, 2007, IEEE INT CONF ROBOT, P3128, DOI 10.1109/ROBOT.2007.363950
   Saenz A., 2010, INCREDIBLE TUG ROBOT
   Satoh H, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P498, DOI 10.1109/ROBIO.2009.5420697
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6
   Sharkey N., 2011, ROBOT ETHICS ETHICAL, P267
   Singer P. W., 2009, WIRED WAR ROBOTICS R
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Tronto J. C., 1993, MORAL BOUNDARIES POL
   Tronto JC, 2010, ETHICS SOC WELF, V4, P158, DOI 10.1080/17496535.2010.484259
   Vallor S., 2011, PHILOS TECHNOLOGY, V24, P251, DOI DOI 10.1007/S13347-011-0015-X
   van Tilburg CM, 2006, QUAL SAF HEALTH CARE, V15, P58, DOI 10.1136/qshc.2005.014902
   van Wynsberghe A., 2012, DESIGNING ROBOTS CAR
   van Wynsberghe A., 2012, J SCI ENG ETHICS, V4
   van Wynsberghe A., 2008, J MED ETHICS, V34
   Verbeek Peter Paul, 2011, MORALIZING TECHNOLOG
   Veruggio G., 2008, SPRINGER HDB ROBOTIC, P1499
   Wallach W., 2010, MORAL MACHINES TEACH
NR 30
TC 4
Z9 4
U1 2
U2 28
PU EMERALD GROUP PUBLISHING LIMITED
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 0143-991X
J9 IND ROBOT
JI Ind. Robot
PY 2013
VL 40
IS 5
BP 433
EP 440
DI 10.1108/IR-12-2012-451
PG 8
WC Engineering, Industrial; Robotics
SC Engineering; Robotics
GA 226MJ
UT WOS:000325040100004
DA 2019-03-21
ER

PT J
AU Kahn, PH
   Gary, HE
   Shen, S
AF Kahn, Peter H., Jr.
   Gary, Heather E.
   Shen, Solace
TI Social and Moral Relationships with Robots: Genetic Epistemology in an
   Exponentially Increasing Technological World
SO HUMAN DEVELOPMENT
LA English
DT Editorial Material
C1 [Kahn, Peter H., Jr.; Gary, Heather E.; Shen, Solace] Univ Washington, Seattle, WA 98195 USA.
RP Kahn, PH (reprint author), Univ Washington, Dept Psychol, Box 351525, Seattle, WA 98195 USA.
EM pkahn@u.washington.edu
CR Gertler J., 2012, US UNMANNED AERIAL S
   Kahn Jr P.H., CHILD DEV P IN PRESS
   Kahn Jr P. H., 2012, P 7 ANN ACM IEEE INT, P33, DOI [DOI 10.1145/2157689.2157696, 10.1145/2157689.2157696]
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033
   Kahn PH, 2011, ACMIEEE INT CONF HUM, P159, DOI 10.1145/1957656.1957710
   KAHN PH, 2002, C HUM FACT COMP SYST, P632, DOI DOI 10.1145/506443.50
   KILLEN M, 1990, J GENET PSYCHOL, V151, P395, DOI 10.1080/00221325.1990.9914626
   Kohlberg L, 1969, HDB SOCIALIZATION TH, P347
   Kurzweil R., 2005, SINGULARITY IS NEAR
   NUCCI LP, 2001, ED MORAL DOMAIN
   PIAGET J, 1969, MORAL JUDGMENT CHILD
   Piaget J., 1971, GENETIC EPISTEMOLOGY
   Scheffler Samuel, 1992, HUMAN MORALITY
   Shiomi M, 2007, IEEE INTELL SYST, V22, P25, DOI 10.1109/MIS.2007.37
   Smetana JG, 2006, HANDBOOK OF MORAL DEVELOPMENT, P119
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Tanaka F, 2007, P NATL ACAD SCI USA, V104, P17954, DOI 10.1073/pnas.0707769104
   Turiel E., 1983, DEV SOCIAL KNOWLEDGE
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 19
TC 2
Z9 2
U1 0
U2 4
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0018-716X
J9 HUM DEV
JI Hum. Dev.
PY 2013
VL 56
IS 1
BP 1
EP 4
DI 10.1159/000345544
PG 4
WC Psychology, Developmental
SC Psychology
GA 087IO
UT WOS:000314755100001
OA Bronze
DA 2019-03-21
ER

PT J
AU Anderson, K
   Waxman, M
AF Anderson, Kenneth
   Waxman, Matthew
TI Law and Ethics for Robot Soldiers
SO POLICY REVIEW
LA English
DT Article
C1 [Anderson, Kenneth] American Univ, Washington, DC 20016 USA.
   [Waxman, Matthew] Columbia Law Sch, New York, NY USA.
RP Anderson, K (reprint author), American Univ, Washington, DC 20016 USA.
NR 0
TC 4
Z9 4
U1 0
U2 10
PU HOOVER INST
PI STANFORD
PA STANFORD UNIV, STANFORD, CA 94305-601 USA
SN 0146-5945
J9 POLICY REV
JI Policy Rev.
PD DEC-JAN
PY 2012
IS 176
BP 35
EP 49
PG 15
WC Political Science
SC Government & Law
GA 049JW
UT WOS:000311980300003
DA 2019-03-21
ER

PT J
AU Sullins, JP
AF Sullins, John P.
TI Robots, Love, and Sex: The Ethics of Building a Love Machine
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Affective computing; artificial companions; artificial emotions;
   robotics
ID SELF; EXPANSION; CLOSENESS; MODEL
AB This paper will explore the ethical impacts of the use of affective computing by engineers and roboticists who program their machines to mimic and manipulate human emotions in order to evoke loving or amorous reactions from their human users. We will see that it does seem plausible that some people might buy a love machine if it were created, but it is argued here that principles from machine ethics have a role to play in the design of these machines. This is best achieved by applying what is known about the philosophy of love, the ethics of loving relationships, and the philosophical value of the erotic in the early design stage of building robust artificial companions. The paper concludes by proposing certain ethical limits on the manipulation of human psychology when it comes to building sex robots and in the simulation of love in such machines. In addition, the paper argues that the attainment of erotic wisdom is an ethically sound goal and that it provides more to loving relationships than only satisfying physical desire. This fact may limit the possibility of creating a machine that can fulfill all that one should want out of erotic love unless a machine can be built that would help its user attain this kind of love.
C1 Sonoma State Univ, Dept Philosophy, Rohnert Pk, CA 94928 USA.
RP Sullins, JP (reprint author), Sonoma State Univ, Dept Philosophy, 1801 East Cotati Ave, Rohnert Pk, CA 94928 USA.
EM john.sullins@sonoma.edu
CR [Anonymous], 2012, CONTINUOUS IOS
   Aron A, 1999, SOC COGNITION, V17, P140, DOI 10.1521/soco.1999.17.2.140
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   ARON A, 1991, J PERS SOC PSYCHOL, V60, P241, DOI 10.1037//0022-3514.60.2.241
   Aron EN, 1996, PERS RELATIONSHIP, V3, P45, DOI 10.1111/j.1475-6811.1996.tb00103.x
   Breazeal C., 1999, P 1999 AUT AG WORKSH, P18
   Breazeal C., 2004, HUMANOID ROBOTS COOP
   Breazeal C. L., 2002, DESIGNING SOCIABLE R
   Brooks RA, 2002, FLESH MACHINES
   Buck R, 2002, PSYCHOL REV, V109, P739, DOI 10.1037//0033-295X.109.4.739
   Buck R., 1997, EMPATHIC ACCURACY, P17
   BUCK R, 1991, ALTRUISM REV PERSONA, V12, P149
   Coeckelbergh M, 2009, INT J SOC ROBOT, V1, P217, DOI 10.1007/s12369-009-0026-2
   Cook SDN, 2008, PHILOSOPHY AND DESIGN: FROM ENGINEERING TO ARCHITECTURE, P259, DOI 10.1007/978-1-4020-6591-0_20
   Davis MH, 1997, EMPATHIC ACCURACY, P144
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   Fehr B., 1994, PERS RELATIONSHIP, V1, P301
   Fehr B., 1991, J PERS SOC PSYCHOL, V60, P424
   Gaudin Sharon, 2010, COMPUTERWORLD
   GILBERT DT, 1986, J PERS SOC PSYCHOL, V50, P269, DOI 10.1037//0022-3514.50.2.269
   Kanda T, 2001, IEEE INT CONF ROBOT, P4166, DOI 10.1109/ROBOT.2001.933269
   Kanda T, 2004, P IEEE RSJ INT C INT, P2215
   Kanda T, 2005, COMMUNICATION ROBOTS
   Lazurus R. S., 1988, J PERS SOC PSYCHOL, V54, P466
   Levy D., 2007, LOVE SEX ROBOTS EVOL
   Menzel P, 2000, ROBOSAPIENS EVOLUTIO
   Meston CM, 2007, ARCH SEX BEHAV, V36, P477, DOI 10.1007/s10508-007-9175-2
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Mori M, 1974, BUDDHA ROBOT ROBOT E
   Ortigue S, 2008, MED HYPOTHESES, V71, P941, DOI 10.1016/j.mehy.2008.07.016
   PLATO, 2001, SYMPOSIUM
   Samani H. A., 2010, P 19 IEEE INT S ROB
   Samani H. A., 2010, P IEEE RSJ INT C INT
   SAMANI HA, 2011, P 3 INT C HUM ROB PE, P118
   Scheutz M., 2009, P IEEE INT C ROB AUT
   Scheutz Matthias, 2006, P 1 ACM INT C HUM RO, P226, DOI [10.1145/1121241.1121281, DOI 10.1145/1121241.1121281]
   Singer Irving, 2001, EXPLORATIONS LOVE SE
   Snell J., 2005, PSYCHOL ED INTERDISC, V42, P49
   Sullins JP, 2008, PHILOSOPHY AND DESIGN: FROM ENGINEERING TO ARCHITECTURE, P143, DOI 10.1007/978-1-4020-6591-0_11
   Turing A., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433
   Turkle S., 2011, ALONE TOGETHER WHY W
   Wilks Y., 2010, CLOSE ENGAGEMENTS AR
NR 42
TC 17
Z9 17
U1 2
U2 44
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD OCT-DEC
PY 2012
VL 3
IS 4
BP 398
EP 409
DI 10.1109/T-AFFC.2012.31
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA 207YX
UT WOS:000323642000004
DA 2019-03-21
ER

PT J
AU Guarini, M
AF Guarini, Marcello
TI Conative Dimensions of Machine Ethics: A Defense of Duty
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Desire-obligation conflict; duty; ethics; machine ethics;
   obligation-obligation conflict
AB Immanuel Kant is one of the giants of moral theorizing in the western philosophical tradition. He developed a view of moral imperatives and duty that continues to inspire thought up to the present. In a thought-provoking series of papers, Anthony Beavers argues that Kant's conception of morality will not be applicable to machines. In other words, it will turn out that when we design machines at a level of sophistication such that ethical constraints must be built into their behavior, Kant's understanding of morality will not be helpful. Specifically, the notion of duty as involving some sort of internal conflict can be jettisoned. The argument in this paper is that there are aspects of duty that can be preserved for machine ethics. The goal will not be to defend any of the details of Kant's position. Rather, it is to motivate some ways of thinking about duty that may be useful for machine ethics.
C1 [Guarini, Marcello] Univ Windsor, Dept Philosophy, Fac Arts & Social Sci, Windsor, ON N9B 3P4, Canada.
RP Guarini, M (reprint author), Univ Windsor, Dept Philosophy, Fac Arts & Social Sci, 401 Sunset, Windsor, ON N9B 3P4, Canada.
EM mguarini@uwindsor.ca
CR Beavers A., DIGITAL ETHICS RES P
   Beavers A., P ASS PRACT PROF ETH, P2099
   Beavers AF, 2012, INTELL ROBOT AUTON, P333
   Dennett Daniel, 1978, BRAINSTORMS PHILOS E
   Fodor J., 2008, LOT2 LANGUAGE THOUGH
   Kant I., 1996, CRITIQUE PRACTICAL R
   Kant Immanuel, 1993, GROUNDING METAPHYSIC
   Pollock J., 1989, BUILD PERSON PROLEGO, P3
   Pollock JL, 1995, COGNITIVE CARPENTRY
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77
   Sinnott-Armstrong W., 2011, STANFORD ENCY PHILOS
NR 11
TC 1
Z9 1
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD OCT-DEC
PY 2012
VL 3
IS 4
BP 434
EP 442
DI 10.1109/T-AFFC.2012.27
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
SC Computer Science
GA 207YX
UT WOS:000323642000007
DA 2019-03-21
ER

PT J
AU [Anonymous]
AF [Anonymous]
TI Robot Ethics: The Ethical and Social Implications of Robotics
SO FUTURIST
LA English
DT Book Review
CR Lin P, 2012, INTELL ROBOT AUTON, P1
NR 1
TC 0
Z9 0
U1 1
U2 12
PU WORLD FUTURE SOC
PI BETHESDA
PA 7910 WOODMONT AVE, STE 450, BETHESDA, MD 20814 USA
SN 0016-3317
J9 FUTURIST
JI Futurist
PD JUL-AUG
PY 2012
VL 46
IS 4
BP 55
EP 55
PG 1
WC Social Issues
SC Social Issues
GA 956QD
UT WOS:000305103300019
DA 2019-03-21
ER

PT J
AU Kahn, PH
   Kanda, T
   Ishiguro, H
   Freier, NG
   Severson, RL
   Gill, BT
   Ruckert, JH
   Shen, S
AF Kahn, Peter H., Jr.
   Kanda, Takayuki
   Ishiguro, Hiroshi
   Freier, Nathan G.
   Severson, Rachel L.
   Gill, Brian T.
   Ruckert, Jolina H.
   Shen, Solace
TI "Robovie, You'll Have to Go into the Closet Now": Children's Social and
   Moral Relationships With a Humanoid Robot
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE beliefs about robots; human-robot interaction; mental models of robots;
   responses to autonomy; robots with children
ID INTERACTIVE ROBOTS; FIELD
AB Children will increasingly come of age with personified robots and potentially form social and even moral relationships with them. What will such relationships look like? To address this question, 90 children (9-, 12-, and 15-year-olds) initially interacted with a humanoid robot, Robovie, in 15-min sessions. Each session ended when an experimenter interrupted Robovie's turn at a game and, against Robovie's stated objections, put Robovie into a closet. Each child was then engaged in a 50-min structural-developmental interview. Results showed that during the interaction sessions, all of the children engaged in physical and verbal social behaviors with Robovie. The interview data showed that the majority of children believed that Robovie had mental states (e.g., was intelligent and had feelings) and was a social being (e.g., could be a friend, offer comfort, and be trusted with secrets). In terms of Robovie's moral standing, children believed that Robovie deserved fair treatment and should not be harmed psychologically but did not believe that Robovie was entitled to its own liberty (Robovie could be bought and sold) or civil rights (in terms of voting rights and deserving compensation for work performed). Developmentally, while more than half the 15-year-olds conceptualized Robovie as a mental, social, and partly moral other, they did so to a lesser degree than the 9- and 12-year-olds. Discussion focuses on how (a) children's social and moral relationships with future personified robots may well be substantial and meaningful and (b) personified robots of the future may emerge as a unique ontological category.
C1 [Kahn, Peter H., Jr.; Severson, Rachel L.; Ruckert, Jolina H.; Shen, Solace] Univ Washington, Dept Psychol, Seattle, WA 98195 USA.
   [Kanda, Takayuki; Ishiguro, Hiroshi] Adv Telecommun Res Inst, Intelligent Robot & Commun Labs, Keihanna Sci City, Japan.
   [Ishiguro, Hiroshi] Osaka Univ, Grad Sch Engn, Osaka, Japan.
   [Freier, Nathan G.] Univ Washington, Informat Sch, Seattle, WA 98195 USA.
   [Gill, Brian T.] Seattle Pacific Univ, Dept Math, Seattle, WA USA.
RP Kahn, PH (reprint author), Univ Washington, Dept Psychol, Box 351525, Seattle, WA 98195 USA.
EM pkahn@uw.edu
RI Kanda, Takayuki/I-5843-2016; Severson, Rachel/I-7700-2012
OI Kanda, Takayuki/0000-0002-9546-5825; Severson,
   Rachel/0000-0002-6677-6747
CR Bartholow BD, 2006, J EXP SOC PSYCHOL, V42, P532, DOI 10.1016/j.jesp.2005.08.006
   Breazeal C. L., 2002, DESIGNING SOCIABLE R
   Buber Martin, 1996, I THOU
   Clark H. H., 2008, P 3 ACM IEEE INT C H, P393, DOI 10.1145/1349822.1349877
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Friedman B., 2003, P SIGCHI C HUM FACT, V5, P273, DOI DOI 10.1145/642611.642660
   HELWIG CC, 1995, CHILD DEV, V66, P152, DOI 10.1111/j.1467-8624.1995.tb00862.x
   Jipson JL, 2007, CHILD DEV, V78, P1675, DOI 10.1111/j.1467-8624.2007.01095.x
   Kahn P.H., 1999, HUMAN RELATIONSHIP N
   Kahn P. H., 2008, P 3 ACM IEEE INT C H, P97, DOI DOI 10.1145/1349822.1349836
   Kahn P. H., 2010, CODING MANUAL ROBOVI
   Kahn PH, 2007, INTERACT STUD, V8, P363
   Kahn PH, 2006, INTERACT STUD, V7, P405, DOI 10.1075/is.7.3.13kah
   KAHN PH, 1992, CHILD DEV, V63, P416, DOI 10.2307/1131489
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Killen M., 1995, EARLY EDUC DEV, V6, P1
   Kohlberg L., 1984, ESSAYS MORAL DEV, V2
   Melson GF, 2009, J APPL DEV PSYCHOL, V30, P92, DOI 10.1016/j.appdev.2008.10.011
   Nucci L. P, 2001, ED MORAL DOMAIN, DOI [10.1017/CBO9780511605987, DOI 10.1017/CBO9780511605987]
   Piaget J, 1932, MORAL JUDGMENT CHILD
   Rawls J., 1971, THEORY JUSTICE
   Regan T., 1983, CASE ANIMAL RIGHTS
   SCAIFE M, 1995, BRIT J DEV PSYCHOL, V13, P367, DOI 10.1111/j.2044-835X.1995.tb00686.x
   Searle J. R., 1984, MINDS BRAINS SCI
   Severson R. L., 2010, THESIS U WASHINGTON
   Severson RL, 2010, J APPL DEV PSYCHOL, V31, P249, DOI 10.1016/j.appdev.2010.02.003
   Shiomi M., 2006, P 1 ACM SIGCHI SIGAR, P305, DOI [10.1145/1121241.1121293, DOI 10.1145/1121241.1121293]
   Shweder R. A., 1987, EMERGENCE MORALITY Y, P1, DOI DOI 10.1017/CBO9781139173728.005
   Smetana J., 2006, HDB MORAL DEV
   Smetana JG, 2006, HANDBOOK OF MORAL DEVELOPMENT, P119
   Stanton C. M., 2008, P 3 ACM IEEE INT C H, P271, DOI DOI 10.1145/1349822.1349858
   Tanaka F, 2007, P NATL ACAD SCI USA, V104, P17954, DOI 10.1073/pnas.0707769104
   TAYLOR M, 1993, DEV PSYCHOL, V29, P276, DOI 10.1037/0012-1649.29.2.276
   Taylor M., 1999, IMAGINARY COMPANIONS
   Turiel E., 2006, HDB CHILD PSYCHOL, V3, P789, DOI DOI 10.1002/AB.20268
   Turiel E., 1983, DEV SOCIAL KNOWLEDGE
   Vygotsky L. S., 1978, MIND SOC
   WAINRYB C, 1995, CHILD DEV, V66, P390, DOI 10.2307/1131585
   WALTERS ML, 2005, P IEEE RAS INT C HUM, P450
   Wang L., 2010, P 5 ACM IEEE INT C H, P359, DOI DOI 10.1145/1734454.1734578
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
   Weiss A, 2010, ACMIEEE INT CONF HUM, P23, DOI 10.1109/HRI.2010.5453273
   Williams B., 1985, ETHICS LIMITS PHILOS
NR 43
TC 77
Z9 77
U1 3
U2 22
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
J9 DEV PSYCHOL
JI Dev. Psychol.
PD MAR
PY 2012
VL 48
IS 2
BP 303
EP 314
DI 10.1037/a0027033
PG 12
WC Psychology, Developmental
SC Psychology
GA 901IU
UT WOS:000300961400002
PM 22369338
DA 2019-03-21
ER

PT J
AU Allenby, B
AF Allenby, Braden
TI Robot Ethics: The Ethical and Social Implications of Robotics
SO NATURE
LA English
DT Book Review
C1 [Allenby, Braden] Arizona State Univ, Tempe, AZ 85287 USA.
RP Allenby, B (reprint author), Arizona State Univ, Tempe, AZ 85287 USA.
EM braden.allenby@asu.edu
CR Lin P, 2012, INTELL ROBOT AUTON, P1
NR 1
TC 1
Z9 1
U1 0
U2 17
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 0028-0836
J9 NATURE
JI Nature
PD JAN 5
PY 2012
VL 481
IS 7379
BP 26
EP 27
DI 10.1038/481026a
PG 2
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA 872VD
UT WOS:000298836900014
OA Bronze
DA 2019-03-21
ER

PT J
AU Suarez-Obando, F
   Vasquez, AO
AF Suarez-Obando, Fernando
   Ordonez Vasquez, Adriana
TI Ethical aspects of medical informatics: principles for use and
   appropriate user of computational systems in clinical health care
SO ACTA BIOETHICA
LA Spanish
DT Article
DE medical informatics; ethics; attitude towards computers
ID PHYSICIAN ORDER ENTRY; IMPACT; ENVIRONMENT; RECORDS
AB Medical Informatics (MI) studies the intersection among computer technology, medicine and the influence of electronic clinical history and the intelligent systems for diagnosis support in clinical decision making. The inadequate use of technology may divert the purposes of MI towards an inadequate use by third parties involved in clinical health care, such as health care managers or insurance agents. The principles for "use and appropriate user for MI applications" as base are proposed to manage suitably computational technology in health care. The development of these principles must be based in the evaluation of their applications, emphasizing that the evaluation must be carried out with the same considerations as other types of medical or surgical interventions.
C1 [Suarez-Obando, Fernando] Univ Pitttsburgh, Dept Biomed Informat, Pittsburgh, PA 15213 USA.
   [Ordonez Vasquez, Adriana] Pontificia Univ Javeriana, Fac Med, Inst Genet Humana, Bogota, Colombia.
RP Suarez-Obando, F (reprint author), Univ Pitttsburgh, Dept Biomed Informat, Pittsburgh, PA 15213 USA.
EM fes15@pitt.edu
OI Suarez-Obando, Fernando/0000-0001-6336-5347
CR Bartos Christa E, 2008, AMIA Annu Symp Proc, P36
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Bernstam EV, 2010, J BIOMED INFORM, V43, P104, DOI 10.1016/j.jbi.2009.08.006
   Black AD, 2011, PLOS MED, V8, DOI 10.1371/journal.pmed.1000387
   Blaya JA, 2011, J AM MED INFORM ASSN, V18, P11, DOI 10.1136/jamia.2010.005280
   Blumenthal D, 2010, NEW ENGL J MED, V363, P501, DOI 10.1056/NEJMp1006114
   Bowes WA, 2010, STUD HEALTH TECHNOL, V160, P86, DOI 10.3233/978-1-60750-588-4-86
   Cooper KL, 2011, HEALTH TECHNOL ASSES, V15, P1, DOI 10.3310/hta15040
   Curioso Walter H., 2010, Rev. perú. med. exp. salud publica, V27, P449, DOI 10.1590/s1726-46342010000300020
   Gartman EJ, 2009, CURR OPIN CRIT CARE, V15, P578, DOI 10.1097/MCC.0b013e328332f50c
   Gomes R, 2008, STUD HEALTH TECHNOL, V136, P765
   Goodman Kenneth W, 2005, Acta bioeth., V11, P121, DOI 10.4067/S1726-569X2005000200002
   Griffiths KL, 2007, J OCCUP REHABIL, V17, P743, DOI 10.1007/s10926-007-9108-x
   Haas S, 2011, INT J MED INFORM, V80, P26
   Han YY, 2005, PEDIATRICS, V116, P1506, DOI 10.1542/peds.2005-1287
   Hayrinen K, 2008, INT J MED INFORM, V77, P291, DOI 10.1016/j.ijmedinf.2007.09.001
   Hodgman SB, 2008, PROF CASE MANAG, V13, P19
   Israelski Edmond W, 2004, Jt Comm J Qual Saf, V30, P689
   Karsh BT, 2010, J AM MED INFORM ASSN, V17, P617, DOI 10.1136/jamia.2010.005637
   Kelley TF, 2011, J NURS SCHOLARSHIP, V43, P154, DOI 10.1111/j.1547-5069.2011.01397.x
   Khajouei R, 2010, METHOD INFORM MED, V49, P3, DOI 10.3414/ME0630
   Li Julie, 2010, Open Med Inform J, V4, P202, DOI 10.2174/1874431101004010202
   Main C, 2010, HEALTH TECHNOL ASSES, V14, P1, DOI 10.3310/hta14480
   Malin B, 2007, STUD HEALTH TECHNOL, V129, P320
   MANNING RC, 1987, PHILOS STUD, V51, P19, DOI 10.1007/BF00353960
   Meingast Marci, 2006, Conf Proc IEEE Eng Med Biol Soc, V1, P5453
   MILLER RA, 1990, J MED PHILOS, V15, P581, DOI 10.1093/jmp/15.6.581
   Miller RA., 2010, YB MED INFORM, V121-36, P0943
   Morrison J, 2008, AAOHN J, V56, P373, DOI 10.3928/08910162-20080901-06
   Pandey B, 2009, COMPUT BIOL MED, V39, P215, DOI 10.1016/j.compbiomed.2008.12.008
   Peute LW, 2010, INT J MED INFORM, V79, P58
   Podichetty V, 2004, AM J MED SCI, V328, P94, DOI 10.1097/00000441-200408000-00005
   Ramesh AN, 2004, ANN ROY COLL SURG, V86, P334, DOI 10.1308/147870804290
   Rodrigues RJ, 2003, J MED INTERNET RES, V5, DOI 10.2196/jmir.5.1.e4
   Shekelle Paul G, 2006, Evid Rep Technol Assess (Full Rep), P1
   Wang D, 2011, HEALTH TECHNOL ASSES, V15, P1, DOI 10.3310/hta15050
   Weir CR, 2003, METHOD INFORM MED, V42, P61
   Wilcox AB, 2011, J AM MED INFORM ASS
   WRAITH SM, 1976, AM J HOSP PHARM, V33, P1304, DOI 10.1093/ajhp/33.12.1304
   Yu F, 2009, PHARMACOEPIDEM DR S, V18, P751, DOI 10.1002/pds.1777
   Zlabek JA, 2011, J AM MED INFORM ASSN, V18, P169, DOI 10.1136/jamia.2010.007229
NR 41
TC 1
Z9 1
U1 0
U2 18
PU UNIV CHILE, CENTRO INTERDISCIPLINARIO ESTUDIOS BIOETICA
PI SANTIAGO
PA DIAGONAL PARAGUAY #265, TORRE 15, PISO 8, SANTIAGO, 00000, CHILE
SN 1726-569X
J9 ACTA BIOETH
JI Acta Bioet.
PY 2012
VL 18
IS 2
BP 199
EP 208
DI 10.4067/S1726-569X2012000200008
PG 10
WC Ethics; Medical Ethics; Social Sciences, Biomedical
SC Social Sciences - Other Topics; Medical Ethics; Biomedical Social
   Sciences
GA 173YJ
UT WOS:000321119200008
OA DOAJ Gold
DA 2019-03-21
ER

PT J
AU Virk, GS
AF Virk, Gurvinder S.
TI Robot ethics
SO INDUSTRIAL ROBOT-AN INTERNATIONAL JOURNAL
LA English
DT Editorial Material
C1 Univ Gavle, Gavle, Sweden.
RP Virk, GS (reprint author), Univ Gavle, Gavle, Sweden.
EM gurvinder.virk@hig.se
NR 0
TC 0
Z9 0
U1 0
U2 4
PU EMERALD GROUP PUBLISHING LIMITED
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 0143-991X
J9 IND ROBOT
JI Ind. Robot
PY 2012
VL 39
IS 3
BP 224
EP 225
DI 10.1108/01439911211217152
PG 2
WC Engineering, Industrial; Robotics
SC Engineering; Robotics
GA 958TK
UT WOS:000305263400002
DA 2019-03-21
ER

PT J
AU Damm, L
AF Damm, Lisa
TI Moral Machines: Teaching Robots Right from Wrong
SO PHILOSOPHICAL PSYCHOLOGY
LA English
DT Book Review
C1 [Damm, Lisa] Univ Pittsburgh, Ctr Philosophy Sci, Pittsburgh, PA 15260 USA.
RP Damm, L (reprint author), Univ Pittsburgh, Ctr Philosophy Sci, 817 Cathedral Learning, Pittsburgh, PA 15260 USA.
EM lmdamm@gmail.com
CR Doris J. M., 2002, LACK CHARACTER PERSO
   Harman Gilbert, 1999, P ARISTOTELIAN SOC, V99, P315, DOI DOI 10.1111/1467-9264.00062
   Sinnott-Armstrong W., 2008, MORAL PSYCHOL, V1
   Wallach W., 2008, MORAL MACHINES TEACH
NR 4
TC 0
Z9 0
U1 0
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND
SN 0951-5089
J9 PHILOS PSYCHOL
JI Philos. Psychol.
PY 2012
VL 25
IS 1
BP 149
EP 153
DI 10.1080/09515089.2011.583029
PG 5
WC Ethics; Psychology, Multidisciplinary
SC Social Sciences - Other Topics; Psychology
GA 874BH
UT WOS:000298929500009
DA 2019-03-21
ER

PT J
AU Lin, P
   Abney, K
   Bekey, G
AF Lin, Patrick
   Abney, Keith
   Bekey, George
TI Robot ethics: Mapping the issues for a mechanized world
SO ARTIFICIAL INTELLIGENCE
LA English
DT Review
DE Robot; Robotics; Ethics; Society; Philosophy; Psychology; Law; Policy;
   Safety; Error
AB As with other emerging technologies, advanced robotics brings with it new ethical and policy challenges. This paper will describe the flourishing role of robots in society-from security to sex-and survey the numerous ethical and social issues, which we locate in three broad categories: safety & errors, law & ethics, and social impact. We discuss many of these issues in greater detail in our forthcoming edited volume on robot ethics from MIT Press. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lin, Patrick; Bekey, George] Calif Polytech State Univ San Luis Obispo, Dept Philosophy, San Luis Obispo, CA 93407 USA.
   [Abney, Keith] Calif Polytech State Univ San Luis Obispo, Coll Engn, San Luis Obispo, CA 93407 USA.
   [Abney, Keith] Univ So Calif, Viterbi Sch Engn, Los Angeles, CA 90089 USA.
RP Lin, P (reprint author), Calif Polytech State Univ San Luis Obispo, Dept Philosophy, 1 Grand Ave, San Luis Obispo, CA 93407 USA.
EM palin@calpoly.edu; kabney@calpoly.edu; gbekey@calpoly.edu
CR Abramson Jeff, 2008, ARMS CONTR ASS OTT C
   Agarwal A, 2009, FERTIL STERIL, V92, P1318, DOI 10.1016/j.fertnstert.2008.08.022
   Allhoff F, 2010, WHAT IS NANOTECHNOLO
   [Anonymous], 2010, KARR IR NEW JET POW
   [Anonymous], 2008, JAP HOP EMPL ROB 202
   Arkin R. C., 2007, GITGVU0711
   Asimov I., 2004, I ROBOT
   Asimov Isaac, 1985, ROBOTS EMPIRE
   Asimov Isaac, 1957, NAKED SUN
   Asimov Isaac, 1978, ENCY SCI FICTION
   Bekey GA, 2005, AUTONOMOUS ROBOTS BI
   Benner SA, 2010, BMC BIOL, V8, DOI 10.1186/1741-7007-8-77
   Bumiller Elisabeth, 2010, NY TIMES        0825
   Cabo M. Ryan, 2010, ROBOT ETHIC IN PRESS
   Capek K., 2004, ROSSUMS UNIVERSAL RO
   Davidson Keay, 2003, SAN FRANCISCO C 0815
   Dick Philip K, 1968, DO ANDROIDS DREAM EL
   Fulbright Yvonne, 2010, MEET ROXXXY WOMAN YO
   Gates Bill, 2007, SCI AM, P58, DOI DOI 10.1038/SCIENTIFICAMERICAN0107-58
   Geipel Gary, 2003, GLOBAL AGING GLOBAL
   Gorman Christine, 1997, TIME MAGAZINE   0721
   Guizzo Erico, 2010, IEEE SPECTRUM   0414
   Hsu Jeremy, 2009, LIVE SCI        0521
   Kiska Tim, 1983, PHILADELPHIA IN 0811, pA
   Lear L., 1997, R CARSON WITNESS NAT
   Levy D., 2007, LOVE SEX ROBOTS EVOL
   Lin Patrick, 2008, AUTONOMOUS MILITARY
   Lin Patrick, 2009, ETHICS ROBOTICS
   Lin Patrick, ROBOT ETHIC IN PRESS
   Madrigal Alexis, 2010, ATLANTIC        0804
   MOOR JH, 1985, METAPHILOSOPHY, V16, P266, DOI 10.1111/j.1467-9973.1985.tb00173.x
   O'Donoghue Amy Joi, 2010, DESERET NEWS    0822
   Rosenberg Mitch, 2009, SURPRISING BENEFITS
   Schactman Noah, 2007, WIRED           1018
   Schoenberger Chana, 2008, FORBES          0525
   Sharkey N, 2008, 2084 BIG ROBOT IS WA
   Sharma VP, 2010, CURR SCI INDIA, V98, P1376
   Singer P. W., 2009, WIRED WAR ROBOTICS R
   Singer Peter W., 2009, WILSON Q         WIN
   United Nations, 1983, CONV CERT CONV WEAP
   US Environmental Protection Agency, 2007, ASB BAN PHAS OUT
   Veruggio G., 2006, EURON ROBOETHICS ROA
   Wallach W., 2009, MORAL MACHINES TEACH
   Warwick Kevin, 2010, SPECIAL ISSUE ROBOT, V12
   Wilson Daniel H., 2005, SURVIVE ROBOT UPRISI
   Zucchino David, 2010, LOS ANGELES TIM 0706
NR 46
TC 23
Z9 23
U1 2
U2 38
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD APR
PY 2011
VL 175
IS 5-6
SI SI
BP 942
EP 949
DI 10.1016/j.artint.2010.11.026
PG 8
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 753ZB
UT WOS:000289818600003
OA Bronze
DA 2019-03-21
ER

PT J
AU Hurley, C
AF Hurley, Ciaran
TI A model to support the ethical elements of decisions made by advanced
   level practitioners
SO NURSING IN CRITICAL CARE
LA English
DT Editorial Material
ID CRITICAL-CARE; PRINCIPLES
C1 Sheffield Hallam Univ, Fac Hlth & Wellbeing, Sheffield S10 2BP, S Yorkshire, England.
RP Hurley, C (reprint author), Sheffield Hallam Univ, Fac Hlth & Wellbeing, Mercury House,38 Collegiate Crescent, Sheffield S10 2BP, S Yorkshire, England.
EM c.hurley@shu.ac.uk
CR Allmark P, 2005, J ADV NURS, V51, P618, DOI 10.1111/j.1365-2648.2005.03542.x
   Beauchamp T. L., 2009, PRINCIPLES BIOMEDICA
   Cookson R, 2000, J MED ETHICS, V26, P323, DOI 10.1136/jme.26.5.323
   Craig J. V., 2007, EVIDENCE BASED PRACT
   Department of Constitutional Affairs, 2007, MENT CAP ACT 2005 CO
   Department of Health, 2010, ADV LEV NURS POS STA
   Department of Health, 2000, NHS PLAN PLAN INV PL
   GILLON R, 1994, BRIT MED J, V309, P184, DOI 10.1136/bmj.309.6948.184
   Gillon R, 1986, PHILOS MED ETHICS
   Hurley C, 2010, NURS CRIT CARE, V15, P227, DOI 10.1111/j.1478-5153.2010.00416.x
   Hurley Ciaran, 2008, Nurs Crit Care, V13, P181, DOI 10.1111/j.1478-5153.2008.00287.x
   White SM, 2006, ANAESTHESIA, V61, P381, DOI 10.1111/j.1365-2044.2006.04533.x
   White Stuart M, 2008, Nurs Crit Care, V13, P1, DOI 10.1111/j.1478-5153.2007.00260.x
NR 13
TC 2
Z9 2
U1 0
U2 2
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1362-1017
EI 1478-5153
J9 NURS CRIT CARE
JI Nurs. Crit. Care
PD MAR-APR
PY 2011
VL 16
IS 2
BP 53
EP 54
DI 10.1111/j.1478-5153.2011.00445.x
PG 2
WC Nursing
SC Nursing
GA 796SZ
UT WOS:000293073800002
PM 21299756
DA 2019-03-21
ER

PT J
AU Pimple, KD
AF Pimple, Kenneth D.
TI Computing Ethics Surrounded by Machines
SO COMMUNICATIONS OF THE ACM
LA English
DT Editorial Material
C1 [Pimple, Kenneth D.] Indiana Univ Bloomington, Poynter Ctr, Study Eth Inst, Bloomington, IN 47405 USA.
   [Pimple, Kenneth D.] Indiana Univ Bloomington, Poynter Ctr, Amer Inst, Bloomington, IN 47405 USA.
   [Pimple, Kenneth D.] Indiana Univ, Ctr Bioeth, Bloomington, IN 47405 USA.
RP Pimple, KD (reprint author), Indiana Univ Bloomington, Poynter Ctr, Study Eth Inst, Bloomington, IN 47405 USA.
EM pimple@indiana.edu
CR NISSENBAUM H, 1994, COMMUN ACM, V37, P72, DOI 10.1145/175222.175228
NR 1
TC 2
Z9 2
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 0001-0782
J9 COMMUN ACM
JI Commun. ACM
PD MAR
PY 2011
VL 54
IS 3
BP 29
EP 31
DI 10.1145/1897852.1897864
PG 3
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
SC Computer Science
GA 755NG
UT WOS:000289938200018
DA 2019-03-21
ER

PT J
AU Lichocki, P
   Kahn, PH
   Billard, A
AF Lichocki, Pawel
   Kahn, Peter H., Jr.
   Billard, Aude
TI The Ethical Landscape of Robotics Bringing Ethics into the Design and
   Use of Robots
SO IEEE ROBOTICS & AUTOMATION MAGAZINE
LA English
DT Article
DE Senior citizens; Robot sensing systems; Positron emission tomography;
   Anthropomorphism; Humans; Pediatrics
ID MACHINE ETHICS; THERAPY; CARE; CHILDREN; SCIENCE; FUTURE; AGENCY
C1 [Lichocki, Pawel] Ecole Polytech Fed Lausanne, Lab Intelligent Syst, CH-1015 Lausanne, Switzerland.
   [Kahn, Peter H., Jr.] Univ Washington, Dept Psychol, Seattle, WA 98195 USA.
   [Billard, Aude] Ecole Polytech Fed Lausanne, Learning Algorithms & Syst Lab, CH-1015 Lausanne, Switzerland.
RP Lichocki, P (reprint author), Ecole Polytech Fed Lausanne, Lab Intelligent Syst, CH-1015 Lausanne, Switzerland.
EM pawel.lichocki@epfl.ch; pkahn@u.washington.edu; aude.billard@epfl.ch
CR ALFEDAGHI SS, 2008, P 2 IEEE INT C DIG E, P482
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83
   ANDERSON M, 2005, P AAAI FALL S MACH E, P1
   ANDERSON M, 2006, P 18 C INN APPL ART, P1759
   Anderson M, 2007, AI MAG, V28, P15
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64
   Anderson M, 2008, STUD COMPUT INTELL, V107, P233
   Anderson SL, 2008, AI SOC, V22, P477, DOI 10.1007/s00146-007-0094-5
   Arkin R., 2008, P 3 ACM IEEE INT C H, P121
   ARKIN RC, 2008, P 1 C ART GEN INT, P51
   ARKIN RC, 2008, P TECHN WART C STANF
   ARKOUDAS K, 2005, P AAAI FALL S MACH E, P17
   Asaro P., 2008, JUST COULD ROBOT WAR, P50
   ASARO P, 2007, P WORKSH ROB IEEE IN
   Asimov I., 1942, ASTOUNDING SCI FICTI
   Blum D, 2002, LOVE GOON PARK H HAR
   Bostrom N., 2002, J EVOL TECHNOL, V9
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82
   CANNING J, P ASS UNM VEH SYST I
   CHANG RWS, 1989, CRIT CARE MED, V17, P1091, DOI 10.1097/00003246-198911000-00001
   Chellas B. F., 1980, MODAL LOGIC INTRO
   Curuklu B, 2010, ACMIEEE INT CONF HUM, P85, DOI 10.1109/HRI.2010.5453259
   Dautenhahn Kerstin, 2009, Applied Bionics and Biomechanics, V6, P369, DOI 10.1080/11762320903123567
   Dautenhahn K, 2004, PRAGMAT COGN, V12, P1, DOI DOI 10.1075/PC.12.1.03DAU
   Dautenhahn K, 2004, P 13 IEEE INT WORKSH, P17
   DENNETT D, 1996, HAL KILLS WHOS BLAME, pCH16
   Feil-Seifer D., 2008, P 7 INT C INT DES CH, P49, DOI DOI 10.1145/1463689.1463716
   Forlizzi J, 2004, HUM-COMPUT INTERACT, V19, P25, DOI 10.1207/s15327051hci1901&2_3
   *FOST INC, 2010, TALON FAM MIL TACT E
   FRIEDMAN B, 1992, J SYST SOFTWARE, V17, P7, DOI 10.1016/0164-1212(92)90075-U
   Friedman B., 2003, P SIGCHI C HUM FACT, V5, P273, DOI DOI 10.1145/642611.642660
   Friedman B., 1995, P C HUM FACT COMP SY, P226
   Fujita M, 2001, INT J ROBOT RES, V20, P781, DOI 10.1177/02783640122068092
   FUJITA Y, 2005, NIPPON ROBOTTO GAKKA, V23, P1
   *GEN AT AER, 2010, PRED B
   Gips J., 1995, ETHICAL ROBOT, P243
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81
   Guo SS, 2009, SCIENCE, V323, P876, DOI 10.1126/science.323.5916.876a
   Harnad S., 2000, Journal of Logic, Language and Information, V9, P425, DOI 10.1023/A:1008315308862
   Himma KE, 2009, ETHICS INF TECHNOL, V11, P19, DOI 10.1007/s10676-008-9167-5
   Honarvar AR, 2010, 2010 INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING: IC4E 2010, PROCEEDINGS, P230, DOI 10.1109/IC4E.2010.136
   HONARVAR AR, 2009, P 8 IEEE INT C COMP, P290
   Ingram B, 2010, ACMIEEE INT CONF HUM, P103, DOI 10.1109/HRI.2010.5453245
   *INT COMM RED CROS, 1977, PROT ADD GEN CONV 12
   International Federation of Robotics, 2010, EX SUMM WORLD ROB 20
   Ishiguio H, 2006, P 11 INT C INT US IN, P2
   Ishiguro H, 2006, CONNECT SCI, V18, P319, DOI 10.1080/09540090600873953
   Kahn P. H., 2002, P CHI 02 HUM FACT CO, P632
   Kahn Paul W, 2002, PHILOS PUBLIC POLICY, V22, P2
   Kahn PH, 2010, ACMIEEE INT CONF HUM, P123, DOI 10.1109/HRI.2010.5453235
   KAHN PH, 2004, P 13 INT WORKSH ROB, P545
   Kahn PH., 2004, P C HUM FACT COMP SY, P1449
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Kant Immanuel, 1993, GROUNDING METAPHYSIC
   KEEFER M, 2003, SCI TECHNOLOGY ED LI, V19, P241
   KIDD C, 2006, P 2006 IEEE INT C RO, P1050
   Kozima H, 2007, PROG BRAIN RES, V164, P385, DOI 10.1016/S0079-6123(07)64021-7
   Kurzweil R., 2005, SINGULARITY IS NEAR
   LEIBNIZ GW, 1984, PAST MASTERS
   Lin P., 2009, ETHICS ROBOTICS, P49
   Maner W, 2002, METAPHILOSOPHY, V33, P339, DOI 10.1111/1467-9973.00231
   Marino D, 2006, INT REV INF ETHICS, V6, P46
   MASON WA, 1975, DEV PSYCHOBIOL, V8, P197, DOI 10.1002/dev.420080305
   Matthias A., 2004, Ethics and Information Technology, V6, P175, DOI 10.1007/s10676-004-3422-1
   Mavridis N., 2009, P 4 ACM IEEE INT C H, P273
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67
   Melson G. F., 2005, P CHI C HUM FACT COM, P1649
   Melson GF, 2009, J SOC ISSUES, V65, P545, DOI 10.1111/j.1540-4560.2009.01613.x
   Miller KW, 2010, IT PROF, V12, P51, DOI 10.1109/MITP.2010.32
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80
   Mudry PA, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P563, DOI 10.1109/ROMAN.2008.4600726
   Murphy RR, 2009, IEEE INTELL SYST, V24, P14, DOI 10.1109/MIS.2009.69
   Osada J., 2006, P 2006 ACM SIGCHI IN
   Pal S.K., 2004, FDN SOFT CASE BASED
   Petersen S, 2007, J EXP THEOR ARTIF IN, V19, P43, DOI 10.1080/09528130601116139
   PRESSLER D, 2010, STUPID LITTLE ROBOT
   RAO AS, 1995, P 1 INT C MULT SYST, P312
   Rawls J., 1999, THEORY JUSTICE
   RICKS DJ, 2010, P 2010 IEEE INT C RO, P4354
   Robins B., 2005, Universal Access in the Information Society, V4, P105, DOI 10.1007/s10209-005-0116-3
   Rzepka R., 2005, P AAAI FALL S MACH E, P85
   Schmitt M. N, 1999, YALE HUM RTS DEV LJ, V2, P143
   Sharkey N., 2009, COMPUTER, V42, P113
   Sharkey N. E., 2008, RUSI DEFENCE SYSTEMS, V11, P86
   Sharkey N, 2008, IEEE INTELL SYST, V23, P14, DOI 10.1109/MIS.2008.60
   Sharkey N, 2010, INTERACT STUD, V11, P161, DOI 10.1075/is.11.2.o1sha
   Sharkey N, 2009, IEEE TECHNOL SOC MAG, V28, P16, DOI 10.1109/MTS.2009.931865
   Sharkey N, 2008, SCIENCE, V322, P1800, DOI 10.1126/science.1164582
   SHIBATA T, 1997, P IEEE INT C SYST MA, V3, P2269
   Skyrms B., 1999, CHOICE CHANCE INTRO
   Solum L B, 1992, NC L REV, V70, P1231
   Sparrow R., 2002, Ethics and Information Technology, V4, P305, DOI 10.1023/A:1021386708994
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6
   Stanton C.M., 2008, P 3 ACM IEEE INT C H, P271, DOI DOI 10.1145/1349822.1349858
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23
   Surgeon General's Office, 2006, MENT HLTH ADV TEAM M
   TAPUS A, 2009, P 4 ACM IEEE INT C H, P297
   Tonkens R, 2009, MIND MACH, V19, P421, DOI 10.1007/s11023-009-9159-1
   United Nations, 1989, TREAT SER, V1577, P3
   VERUGGIO G, 2005, WORKSH ROB ETH IEEE
   Veruggio G., 2006, P 6 IEEE RAS INT C H, P612
   Veruggio G, 2006, INT REV INF ETHICS, V6, P2
   Wada K, 2005, IEEE INT CONF ROBOT, P2785
   Wada K, 2008, IEEE ENG MED BIOL, V27, P53, DOI 10.1109/MEMB.2008.919496
   Wada K, 2007, IEEE T ROBOT, V23, P972, DOI 10.1109/TRO.2007.906261
   Walzer Michael, 2000, JUST UNJUST WARS
   Wiegel V, 2009, INT J SOC ROBOT, V1, P233, DOI 10.1007/s12369-009-0023-5
NR 107
TC 18
Z9 18
U1 1
U2 26
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1070-9932
J9 IEEE ROBOT AUTOM MAG
JI IEEE Robot. Autom. Mag.
PD MAR
PY 2011
VL 18
IS 1
BP 39
EP 50
DI 10.1109/MRA.2010.940151
PG 12
WC Automation & Control Systems; Robotics
SC Automation & Control Systems; Robotics
GA 753TR
UT WOS:000289803100011
DA 2019-03-21
ER

PT J
AU Powers, TM
AF Powers, Thomas M.
TI Incremental Machine Ethics Adaptation of Programmed Constraints
SO IEEE ROBOTICS & AUTOMATION MAGAZINE
LA English
DT Article
DE Ethics; Humans; Service robots; Pediatrics; Law; Senior citizens
C1 Univ Delaware, Newark, DE 19716 USA.
RP Powers, TM (reprint author), Univ Delaware, Newark, DE 19716 USA.
EM tpowers@udel.edu
OI Powers, Thomas M/0000-0002-2484-4721
CR Allison G. T., 1971, ESSENCE DECISION EXP
   Arkin R., 2009, GOVERNING LETHAL BEH
   ARROW KJ, 1964, POLIT SCI QUART, V79, P584, DOI 10.2307/2146703
   Braybrooke D., 1963, STRATEGY DECISION
   Davidson D., 2001, ESSAYS ACTIONS EVENT
   FORESTER J, 1984, PUBLIC ADMIN REV, V44, P23, DOI 10.2307/975658
   Hayes M, 2001, LIMITS POLICY CHANGE
   HERBERT HS, 1957, MODELS MAN SOCIAL RA
   Hughes Thomas P., 1989, SOCIAL CONSTRUCTION
   JOHNSON D, 2008, INFORM TECHNOLOGY MO
   Knott JH, 2003, J PUBL ADM RES THEOR, V13, P341, DOI 10.1093/jopart/mug023
   Kohlberg L, 1981, ESSAYS MORAL DEV, V1
   lindblom c. e., 1965, INTELLIGENCE DEMOCRA
   LINDBLOM CE, 1979, PUBLIC ADMIN REV, V39, P517, DOI 10.2307/976178
   LINDBLOM CE, 1959, PUBLIC ADMIN REV, V19, P79, DOI 10.2307/973677
   LUSTICK I, 1980, AM POLIT SCI REV, V74, P342, DOI 10.2307/1960631
   PREMFORS R, 1981, BRIT J POLIT SCI, V11, P201, DOI 10.1017/S000712340000257X
   Searle J. R., 1984, MINDS BRAINS SCI
   Smith Brian Cantwell, 1985, ACM SIGCAS COMPUTERS, V14-15, P18
   Wallach W., 2009, MORAL MACHINES TEACH
   Wildavsky A., 1964, POLITICS BUDGETARY P
NR 21
TC 12
Z9 12
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1070-9932
J9 IEEE ROBOT AUTOM MAG
JI IEEE Robot. Autom. Mag.
PD MAR
PY 2011
VL 18
IS 1
BP 51
EP 58
DI 10.1109/MRA.2011.940275
PG 8
WC Automation & Control Systems; Robotics
SC Automation & Control Systems; Robotics
GA 753TR
UT WOS:000289803100012
DA 2019-03-21
ER

PT J
AU Loughlin, C
AF Loughlin, Clive
TI Robot ethics and bad workmen
SO INDUSTRIAL ROBOT-AN INTERNATIONAL JOURNAL
LA English
DT Editorial Material
NR 0
TC 0
Z9 0
U1 0
U2 0
PU EMERALD GROUP PUBLISHING LIMITED
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 0143-991X
J9 IND ROBOT
JI Ind. Robot
PY 2011
VL 38
IS 2
BP 111
EP 111
PG 1
WC Engineering, Industrial; Robotics
SC Engineering; Robotics
GA 750ZW
UT WOS:000289588100001
DA 2019-03-21
ER

PT J
AU Collins, N
AF Collins, Nick
TI Trading Faures: Virtual Musicians and Machine Ethics
SO LEONARDO MUSIC JOURNAL
LA English
DT Article
ID SOMETIMES; AGENTS; ROBOT; HARD
AB Increased maturity in modeling human musicianship leads to many interesting artistic achievements and challenges. This article takes the opportunity to reflect on future situations in which virtual musicians are traded like baseball cards, associated content-creator and autonomous musical agent rights, and the musical and moral conundrums that may result. Although many scenarios presented here may seem far-fetched with respect to the current level of artificial intelligence, it remains prudent and artistically stimulating to consider them. Accepting basic human curiosity and research teleology, it is salutary to consider the more distant consequences of our actions with respect to aesthetics and ethics.
C1 Univ Sussex, Dept Informat, Brighton BN1 9QJ, E Sussex, England.
RP Collins, N (reprint author), Univ Sussex, Dept Informat, Brighton BN1 9QJ, E Sussex, England.
EM N.Collins@sussex.ac.uk
CR Barfield W, 2005, PRESENCE-TELEOP VIRT, V14, P741, DOI 10.1162/105474605775196607
   BARFIELD W, 2006, AKRON LAW REV, P649
   BONADA J, 2007, IEEE SIGNAL PROC MAR
   BURNS J, 2010, CELEBRITY IMAGE RIGH
   Collins N, 2007, CAMB COMPANION MUSIC, P1, DOI 10.1017/CCOL9780521868617
   Collins N., 2009, INTRO COMPUTER MUSIC
   COLLINS N, 2008, P INT COMP MUS C BEL
   Cope David, 2005, COMPUTER MODELS MUSI
   DEGREY A, 2004, WE WILL BE ABLE LIVE
   Gibson W, 1996, IDORU
   HARO M, 2010, 5 AUD MOSTL C C INT
   HSU B, 2010, COMMUNICATION   1212
   KAPUR A, 2010, COMMUNICATION   1123
   Kapur Ajay, 2005, P INT COMP MUS C ICM
   KATZ M, 2004, CAPTURING SOUND TECH, P67
   Klapuri A., 2006, SIGNAL PROCESSING ME
   Lastowka FG, 2004, CALIF LAW REV, V92, P1, DOI 10.2307/3481444
   Lessig L., 2004, FREE CULTURE NATURE
   Mancini M, 2007, IEEE T AUDIO SPEECH, V15, P1833, DOI 10.1109/TASL.2007.899256
   Matrix Sidney Eve, 2006, CYBERPOP DIGITAL LIF
   McCutcheon MA, 2007, POP MUSIC, V26, P259, DOI 10.1017/S0261143007001225
   MICHAELS S, 2009, GUARDIAN        0910
   Miller P, 2008, SOUND UNBOUND SAMPLI
   MURRAY R, 2009, GUITAR HERO KURT COB
   Nakano T., 2009, P SMC 2009, P343
   PARKER R, 2004, A DEGREY 1 PERSON LI
   Reidsma D, 2008, COMPUTERS ENTERTAINM, V6, P1
   Reynolds Simon, 2005, RIP IT START AGAIN
   ROWE R, 1997, P INT COMP MUS C THE
   Russell S.J, 2003, ARTIFICIAL INTELLIGE
   Sartor G, 2009, ARTIF INTELL LAW, V17, P253, DOI 10.1007/s10506-009-9081-0
   SILVERBERG R, 1989, CONGLOMEROID COCKTAI, P152
   SINGER E, 1996, INT S EL ART
   Stout Rowland, 2008, ROUTLEDGE COMPANION, P851
   TAYLOR R, 2005, P NIME VANC
   Thimbleby H, 2008, INTERACT COMPUT, V20, P338, DOI 10.1016/j.intcom.2008.02.006
   Vonnegut Kurt, 1952, PLAYER PIANO
   WERDE B, 2003, NY TIMES        1123
   Whitby B, 2008, INTERACT COMPUT, V20, P326, DOI 10.1016/j.intcom.2008.02.002
   WORLD IS MINE LIVE H
NR 40
TC 2
Z9 2
U1 2
U2 9
PU MIT PRESS
PI CAMBRIDGE
PA 55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA
SN 0961-1215
J9 LEONARDO MUSIC J
JI Leonardo Music J.
PY 2011
VL 21
BP 35
EP 39
DI 10.1162/LMJ_a_00059
PG 5
WC Music
SC Music
GA 853PR
UT WOS:000297438700011
DA 2019-03-21
ER

PT J
AU Sokol, DK
AF Sokol, Daniel K.
TI Ethics Man Of interviews and examination machines
SO BRITISH MEDICAL JOURNAL
LA English
DT Editorial Material
C1 Univ London Imperial Coll Sci Technol & Med, London SW7 2AZ, England.
RP Sokol, DK (reprint author), Univ London Imperial Coll Sci Technol & Med, London SW7 2AZ, England.
EM daniel.sokol@talk21.com
NR 0
TC 0
Z9 0
U1 0
U2 0
PU B M J PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0959-535X
J9 BRIT MED J
JI Br. Med. J.
PD DEC 1
PY 2010
VL 341
AR c6899
DI 10.1136/bmj.c6899
PG 2
WC Medicine, General & Internal
SC General & Internal Medicine
GA 691OU
UT WOS:000285091500018
DA 2019-03-21
ER

PT J
AU Beavers, AF
AF Beavers, Anthony F.
TI Moral machines: teaching robots right from wrong
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Book Review
C1 [Beavers, Anthony F.] Univ Evansville, Evansville, IN USA.
RP Beavers, AF (reprint author), Univ Evansville, Evansville, IN USA.
EM tb2@evansville.edu
CR BEAVERS AF, MORAL MACHINES TEACH
NR 1
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD DEC
PY 2010
VL 12
IS 4
SI SI
BP 357
EP 358
DI 10.1007/s10676-010-9237-3
PG 2
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 683WS
UT WOS:000284509600006
DA 2019-03-21
ER

PT J
AU Wiegel, V
AF Wiegel, Vincent
TI moral machines: teaching robots right from wrong
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Book Review
C1 [Wiegel, Vincent] Delft Univ Technol, Sect Philosophy, NL-2600 GA Delft, Netherlands.
RP Wiegel, V (reprint author), Delft Univ Technol, Sect Philosophy, POB 5015, NL-2600 GA Delft, Netherlands.
EM v.wiegel@tudelft.nl
CR Wallace W., 2009, MORAL MACHINES TEACH
NR 1
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD DEC
PY 2010
VL 12
IS 4
SI SI
BP 359
EP 361
DI 10.1007/s10676-010-9239-1
PG 3
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 683WS
UT WOS:000284509600007
OA Other Gold
DA 2019-03-21
ER

PT J
AU Buechner, J
AF Buechner, Jeff
TI Review of moral machines: teaching robots right from wrong
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Book Review
C1 [Buechner, Jeff] Rutgers State Univ, Dept Philosophy, Newark, NJ 07102 USA.
   [Buechner, Jeff] CUNY, Grad Ctr, Saul Kripke Ctr, New York, NY USA.
RP Buechner, J (reprint author), Rutgers State Univ, Dept Philosophy, Newark, NJ 07102 USA.
EM buechner@rci.rutgers.edu
CR Joy Bill, 2000, WIRED, V8
   McCarthy J., 1969, MACH INTELL, V4, P463, DOI DOI 10.1016/B978-0-934613-03-3.50033-7
   MCDERMOTT D, 2008, 2008 N AM C COMP PHI
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80
   Shoham Y., 1988, REASONING CHANGE
   WALLACE W, 2009, REV MORAL MACHINES T
NR 6
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD DEC
PY 2010
VL 12
IS 4
SI SI
BP 363
EP 370
DI 10.1007/s10676-010-9238-2
PG 8
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 683WS
UT WOS:000284509600008
DA 2019-03-21
ER

PT J
AU Coeckelbergh, M
AF Coeckelbergh, Mark
TI Robot rights? Towards a social-relational justification of moral
   consideration
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Moral consideration; Artificially intelligent robots; Ethics of
   robotics; Rights; Relations; Social ecology
ID ARTIFICIAL AGENTS; SCIENCE; ETHICS
AB Should we grant rights to artificially intelligent robots? Most current and near-future robots do not meet the hard criteria set by deontological and utilitarian theory. Virtue ethics can avoid this problem with its indirect approach. However, both direct and indirect arguments for moral consideration rest on ontological features of entities, an approach which incurs several problems. In response to these difficulties, this paper taps into a different conceptual resource in order to be able to grant some degree of moral consideration to some intelligent social robots: it sketches a novel argument for moral consideration based on social relations. It is shown that to further develop this argument we need to revise our existing ontological and social-political frameworks. It is suggested that we need a social ecology, which may be developed by engaging with Western ecology and Eastern worldviews. Although this relational turn raises many difficult issues and requires more work, this paper provides a rough outline of an alternative approach to moral consideration that can assist us in shaping our relations to intelligent robots and, by extension, to all artificial and biological entities that appear to us as more than instruments for our human purposes.
C1 Univ Twente, Dept Philosophy, NL-7500 AE Enschede, Netherlands.
RP Coeckelbergh, M (reprint author), Univ Twente, Dept Philosophy, POB 217, NL-7500 AE Enschede, Netherlands.
EM m.coeckelbergh@utwente.nl
OI Coeckelbergh, Mark/0000-0001-9576-1002
CR Asaro PM, 2006, INT REV INF ETHICS, V6, P9
   ASIMOV I, 1942, RUNAROUND        MAR
   Berger P.L., 1966, SOCIAL CONSTRUCTION
   Breazeal C, 2003, ROBOT AUTON SYST, V42, P167, DOI 10.1016/S0921-8890(02)00373-1
   BROOKS R, 2000, TIME            0619
   Calverley DJ, 2006, CONNECT SCI, V18, P403, DOI 10.1080/09540090600879711
   Clark J., 1997, CAPITALISM NATURE SO, V8, P3
   Coeckelbergh M, 2009, AI SOC, V24, P181, DOI 10.1007/s00146-009-0208-3
   Coeckelbergh M, 2009, INT J SOC ROBOT, V1, P217, DOI 10.1007/s12369-009-0026-2
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P235, DOI 10.1007/s10676-010-9221-y
   Dautenhahn K, 2005, IEEE RSJ INT C INT R
   Dombrowski D. A., 1997, BABIES BEASTS ARGUME
   Ess C., 2005, ETHICS INF TECHNOL, V7, P1, DOI 10.1007/s10676-005-0454-0
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   Floridi L, 2008, METAPHILOSOPHY, V39, P651, DOI 10.1111/j.1467-9973.2008.00573.x
   Gilligan C., 1982, DIFFERENT VOICE PSYC
   GRUEN L, 2003, MORAL STATUS ANIMALS
   Hacker-Wright J, 2007, PHILOSOPHY, V82, P449, DOI 10.1017/S0031819107000058
   Hursthouse R., 1999, HUME STUDIES, V25, P67
   Kant I., 1785, GROUNDWORK METAPHYSI
   Kittay Eva Feder, 1999, LOVES LABOR ESSAYS W
   Kurzweil R., 2005, SINGULARITY IS NEAR
   Latour B., 2005, REASSEMBLING SOCIAL
   Latour B., 2004, POLITICS NATURE BRIN
   Latour Bruno, 1993, WE HAVE NEVER BEEN M
   Leopold A, 1949, SAND COUNTY ALMANAC
   Levy D, 2009, INT J SOC ROBOT, V1, P209, DOI 10.1007/s12369-009-0022-6
   MacIntyre Alasdair, 1999, DEPENDENT RATIONAL A
   MacIntyre Alasdair C., 1984, VIRTUE STUDY MORAL T
   MARX K, 1844, COLLECTED WORKS
   MCNALLY P, 1998, FUTURES, V20, P119
   Midgley M., 1984, ANIMALS WHY THEY MAT
   Mill J. S., 1863, UTILITARIANISM
   Noddings N., 1984, CARING FEMININE APPR
   NORDAHL R, 1987, CAN J POLIT SCI, V20, P755, DOI 10.1017/S000842390005040X
   Nussbaum M., 2006, FRONTIERS JUSTICE DI
   Nussbaum M. C., 2000, WOMEN HUMAN DEV CAPA
   Regan T., 1983, CASE ANIMAL RIGHTS
   Ruddick Sara, 1989, MATERNAL THINKING PO
   Sartre J. P., 1943, BEING NOTHINGNESS ES
   Searle J., 1995, CONSTRUCTION SOCIAL
   Searle J. R., 2006, ANTHROPOL THEOR, V6, P12, DOI DOI 10.1177/1463499606061731
   Sharkey N, 2008, SCIENCE, V322, P1800, DOI 10.1126/science.1164582
   Singer Peter, 1975, ANIMAL LIBERATION
   Singer Peter, 1993, PRACTICAL ETHICS
   Taylor Charles, 1989, SOURCES SELF MAKING
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8
   *UK GOVT, 2006, ROB RIGHTS UT DREAM
   United Nations, UN DECL HUM RIGHTS
   Veruggio G., 2006, EURON ROBOETHICS ROA
   Wallach W., 2008, MORAL MACHINES TEACH
   Warren M. A., 1997, MORAL STATUS OBLIGAT
   Whitby B, 2008, INTERACT COMPUT, V20, P326, DOI 10.1016/j.intcom.2008.02.002
NR 53
TC 41
Z9 42
U1 6
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD SEP
PY 2010
VL 12
IS 3
SI SI
BP 209
EP 221
DI 10.1007/s10676-010-9235-5
PG 13
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 636YM
UT WOS:000280781400002
OA Other Gold
DA 2019-03-21
ER

PT J
AU Coeckelbergh, M
AF Coeckelbergh, Mark
TI Moral appearances: emotions, robots, and human morality
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Robot morality; Human morality; Emotions; Rule-following; Mental states;
   Feelings; Appearance
AB Can we build 'moral robots'? If morality depends on emotions, the answer seems negative. Current robots do not meet standard necessary conditions for having emotions: they lack consciousness, mental states, and feelings. Moreover, it is not even clear how we might ever establish whether robots satisfy these conditions. Thus, at most, robots could be programmed to follow rules, but it would seem that such 'psychopathic' robots would be dangerous since they would lack full moral agency. However, I will argue that in the future we might nevertheless be able to build quasi-moral robots that can learn to create the appearance of emotions and the appearance of being fully moral. I will also argue that this way of drawing robots into our social-moral world is less problematic than it might first seem, since human morality also relies on such appearances.
C1 Univ Twente, Dept Philosophy, NL-7500 AE Enschede, Netherlands.
RP Coeckelbergh, M (reprint author), Univ Twente, Dept Philosophy, POB 217, NL-7500 AE Enschede, Netherlands.
EM m.coeckelbergh@utwente.nl
OI Coeckelbergh, Mark/0000-0001-9576-1002
CR [Anonymous], 1995, POETIC JUSTICE LIT I
   ASIMOV I, 1942, ASTOUNDING SCI FICTI, P94
   Damasio A., 1994, DESCARTES ERROR EMOT
   de Sousa R, 1987, RATIONALITY EMOTION
   Foot Philippa, 2002, VIRTUES VICES
   Goldie P, 2000, EMOTIONS PHILOS EXPL
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872
   James W., 1884, MIND, V9, P188, DOI DOI 10.1093/MIND/OS-IX.34.188
   Kennett J, 2002, PHILOS QUART, V52, P340, DOI 10.1111/1467-9213.00272
   Merleau-Ponty M, 1945, PHENOMENOLOGIE PERCE
   Nussbaum M., 1990, LOVES KNOWLEDGE
   Nussbaum M., 2001, UPHEAVALS THOUGHT IN
   Nussbaum Martha C, 1994, THERAPY DESIRE THEOR
   Prinz J. J, 2004, GUT REACTIONS PERCEP
   SOLOMON R, 1980, EXPLAINING EMOTIONS, P81
   Turing A.M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433
   Wallach W., 2008, MORAL MACHINES TEACH
NR 17
TC 20
Z9 20
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD SEP
PY 2010
VL 12
IS 3
SI SI
BP 235
EP 241
DI 10.1007/s10676-010-9221-y
PG 7
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 636YM
UT WOS:000280781400004
DA 2019-03-21
ER

PT J
AU Wallach, W
AF Wallach, Wendell
TI Robot minds and human ethics: the need for a comprehensive model of
   moral decision making
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Moral psychology; Moral agent; Machine ethics; Moral philosophy;
   Decision making; Moral judgment; Virtues; Computers; Emotions; Robots
ID GENETICAL EVOLUTION; JUDGMENT/
AB Building artificial moral agents (AMAs) underscores the fragmentary character of presently available models of human ethical behavior. It is a distinctly different enterprise from either the attempt by moral philosophers to illuminate the "ought" of ethics or the research by cognitive scientists directed at revealing the mechanisms that influence moral psychology, and yet it draws on both. Philosophers and cognitive scientists have tended to stress the importance of particular cognitive mechanisms, e.g., reasoning, moral sentiments, heuristics, intuitions, or a moral grammar, in the making of moral decisions. However, assembling a system from the bottom-up which is capable of accommodating moral considerations draws attention to the importance of a much wider array of mechanisms in honing moral intelligence. Moral machines need not emulate human cognitive faculties in order to function satisfactorily in responding to morally significant situations. But working through methods for building AMAs will have a profound effect in deepening an appreciation for the many mechanisms that contribute to a moral acumen, and the manner in which these mechanisms work together. Building AMAs highlights the need for a comprehensive model of how humans arrive at satisfactory moral judgments.
C1 [Wallach, Wendell] Yale Univ, Inst Social & Policy Studies, Interdisciplinary Ctr Bioeth, New Haven, CT 06520 USA.
RP Wallach, W (reprint author), 7 Loeffler Rd, Bloomfield, CT 06002 USA.
EM wendell.wallach@yale.edu
CR Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   ALLEN C, 2002, COGNITIVE EMOTIVE ET, V1
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64
   Anderson M, 2006, IEEE INTELL SYST, V21, P10, DOI 10.1109/MIS.2006.70
   AXELROD R, 1981, SCIENCE, V211, P1390, DOI 10.1126/science.7466396
   BENTHAM J, 2008, INTRO PRINCIPLES MOR
   Danielson P., 1992, ARTIFICIAL MORALITY
   DARLEY JM, 1973, J PERS SOC PSYCHOL, V27, P100, DOI 10.1037/h0034449
   DEWAAL F, 1996, GOOD NATURED EVOLUTI
   Flack JC, 2000, J CONSCIOUSNESS STUD, V7, P1
   Franklin S, 2003, J CONSCIOUSNESS STUD, V10, P47
   Franklin S., 2006, IDPT 2006 P INT DES
   GIGERENZER G, 2010, TOPICS IN PRESS
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872
   GREENWALD AG, 1995, PSYCHOL REV, V102, P4, DOI 10.1037/0033-295X.102.1.4
   Haidt J, 2001, PSYCHOL REV, V108, P814, DOI 10.1037//0033-295X.108.4.814
   HAIDT J, 2003, HDB AFFECTIVE SCI, P852
   HAMILTON WD, 1964, J THEOR BIOL, V7, P17, DOI 10.1016/0022-5193(64)90039-6
   HAMILTON WD, 1964, J THEOR BIOL, V7, P1, DOI 10.1016/0022-5193(64)90038-4
   Hauser M., 2006, MORAL MINDS NATURE D
   Hume D, 2009, TREATISE HUMAN NATUR
   ISEN AM, 1972, J PERS SOC PSYCHOL, V21, P384, DOI 10.1037/h0032317
   Kohlberg L., 1984, ESSAYS MORAL DEV, V2
   Kohlberg L., 1981, ESSAYS MORAL DEV, V1
   Lapsley D. K., 2004, MORAL DEV SELF IDENT
   Mikhail J., 2000, THESIS CORNELL U
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   MOORE G. E., 2008, PRINCIPIA ETHICA
   Nucci L, 2008, EDUC PSYCHOL HANDB, pIX
   Rawls J., 1999, THEORY JUSTICE
   Sanfey AG, 2003, SCIENCE, V300, P1755, DOI 10.1126/science.1082976
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00005756
   Simon H., 1957, BEHAV MODEL RATIONAL
   Simon H., 1982, MODELS BOUNDED RATIO, V1
   Simon Herbert A, 1982, MODELS BOUNDED RATIO, V2
   Singer P., 1990, ANIMAL LIBERATION
   SMITH, 2004, THEORY MORAL SENTIME
   TORRANCE S, 2008, ARTIF INTELL, V22, P34
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124
   Uleman James S, 1989, UNINTENDED THOUGHT
   Wallach W., 2009, MORAL MACHINES TEACH
   WALLACH W, 2010, TOPICS IN PRESS
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0
   Warden M., 1972, JUDGMENT REASONING C
   Wilson E.O., 1975, P1
   YUDKOWSKY E, 2001, WHAT IS FRIENDLY AI
NR 46
TC 26
Z9 26
U1 10
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD SEP
PY 2010
VL 12
IS 3
SI SI
BP 243
EP 250
DI 10.1007/s10676-010-9232-8
PG 8
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 636YM
UT WOS:000280781400005
DA 2019-03-21
ER

PT J
AU Danielson, P
AF Danielson, Peter
TI Designing a machine to learn about the ethics of robotics: the N-reasons
   platform
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Ethical decision making; Empirical philosophy; Robot ethics; Surveys
AB We can learn about human ethics from machines. We discuss the design of a working machine for making ethical decisions, the N-Reasons platform, applied to the ethics of robots. This N-Reasons platform builds on web based surveys and experiments, to enable participants to make better ethical decisions. Their decisions are better than our existing surveys in three ways. First, they are social decisions supported by reasons. Second, these results are based on weaker premises, as no exogenous expertise (aside from that provided by the participants) is needed to seed the survey. Third, N-Reasons is designed to support experiments so we can learn how to improve the platform. We sketch experimental results that show the platform is a success as well as pointing to ways it can be improved.
C1 Univ British Columbia, W Maurice Young Ctr Appl Eth, Vancouver, BC V6T 1Z2, Canada.
RP Danielson, P (reprint author), Univ British Columbia, W Maurice Young Ctr Appl Eth, 227-6356 Agr Rd, Vancouver, BC V6T 1Z2, Canada.
EM pad@ethics.ubc.ca
CR AHMAD R, 2008, PUBLIC UNDERSTANDING
   Danielson P, 2002, P NATL ACAD SCI USA, V99, P7237, DOI 10.1073/pnas.082079899
   DANIELSON P, 2001, ETHICS ROBOTS OPEN E
   Danielson P., 2007, ETHICS LIFE SCI, P315
   DANIELSON P, 1999, ETHICS INF TECHNOL, V1, P77
   DANIELSON P, 1996, CHAOS SOC, V18, P329
   DANIELSON P, 2009, PHILOS ENG IN PRESS
   DANIELSON P, 1998, MODELING RATIONALITY, V7, P423
   Danielson P., 1992, ARTIFICIAL MORALITY
   DANIELSON PA, 2009, 5 INT DNA SAMPL C BA
   DANIELSON PA, 2009, N DAME PHILOS REV
   Danielson P, 2009, NATURE, V457, P540, DOI 10.1038/457540a
   Dryzek JS, 2003, BRIT J POLIT SCI, V33, P1, DOI 10.1017/S000712340300001
   LIN P, 2008, AUTONOMOUS MILTARY R
   MESOUDI A, 2007, PARALLEL ETHICAL WOR
   Mesoudi A, 2008, THEOR BIOSCI, V127, P229, DOI 10.1007/s12064-008-0027-y
   ORMANDY E, 2008, GEN CAN INT S VANC
   Salganik MJ, 2006, SCIENCE, V311, P854, DOI 10.1126/science.1121066
   Skyrms B., 1996, EVOLUTION SOCIAL CON
   Thaler Richard, 2009, NUDGE IMPROVING DECI
   Wallach W., 2008, MORAL MACHINES TEACH
NR 21
TC 16
Z9 16
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD SEP
PY 2010
VL 12
IS 3
SI SI
BP 251
EP 261
DI 10.1007/s10676-009-9214-x
PG 11
WC Ethics; Information Science & Library Science; Philosophy
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA 636YM
UT WOS:000280781400006
DA 2019-03-21
ER

PT J
AU Miljeteig, I
   Johansson, KA
   Sayeed, SA
   Norheim, OF
AF Miljeteig, I.
   Johansson, K. A.
   Sayeed, S. A.
   Norheim, O. F.
TI End-of-life decisions as bedside rationing. An ethical analysis of life
   support restrictions in an Indian neonatal unit
SO JOURNAL OF MEDICAL ETHICS
LA English
DT Article
ID PRETERM BIRTH; ECONOMIC CONSEQUENCES; HEALTH-CARE; COST; INTERVENTIONS;
   IMPACT; INFANTS; ILLNESS; POLICY; INCOME
AB Introduction Hundreds of thousands of premature neonates born in low-income countries are implicitly denied treatment each year. Studies from India show that treatment is rationed even for neonates born at 32 gestational age weeks (GAW), and multiple external factors influence treatment decisions. Is withholding of life-saving treatment for children born between 28 and 32 GAW acceptable from an ethical perspective?
   Method A seven-step impartial ethical analysis, including outcome analysis of four accepted priority criteria: severity of disease, treatment effect, cost effectiveness and evidence for neonates born at 28 and 32 GAW.
   Results The ethical analysis sketches out two possibilities: (a) It is not ethically permissible to limit treatment to neonates below 32 GAW when assigning high weight to health maximisation and overall health equality. Neonates below 32 GAW score high on severity of disease and efficiency and cost-effectiveness of treatment if one gives full weight to early years of a newborn life. It is in the child's best interest to be treated. (b) It can be considered ethically permissible if high weight is assigned to reducing inequality of welfare and maximising overall welfare and/or not granting full weight to early years of newborns is considered acceptable. From an equity-motivated health and welfare perspective, we would not accept (b), as it relies on accepting the lack of proper welfare policies for the poor and disabled in India.
   Conclusion Explicit priority processes in India for financing neonatal care are needed. If premature neonates are perceived as worth less than other patient groups, the reasons should be explored among a broad range of stakeholders.
C1 [Miljeteig, I.; Johansson, K. A.; Norheim, O. F.] Univ Bergen, Dept Publ Hlth & Primary Hlth Care, N-5020 Bergen, Norway.
   [Miljeteig, I.; Johansson, K. A.; Norheim, O. F.] Univ Bergen, Ctr Int Hlth, N-5020 Bergen, Norway.
   [Sayeed, S. A.] Harvard Univ, Childrens Hosp Boston, Div Newborn Med, Div Med Eth,Med Sch,Program Eth & Hlth, Boston, MA 02115 USA.
RP Miljeteig, I (reprint author), Univ Bergen, Dept Publ Hlth & Primary Hlth Care, Kalfarveien 31, N-5020 Bergen, Norway.
EM ingrid.miljeteig@isf.uib.no
OI Norheim, Ole F./0000-0002-5748-5956
FU University of Bergen; Norwegian Research Council (Norheim)
FX University of Bergen, Norway and the Young Investigator Grant, Norwegian
   Research Council (Norheim). The researchers are independent of funders.
CR Adhikari SR, 2009, HEALTH POLICY PLANN, V24, P129, DOI 10.1093/heapol/czn052
   Aggarwal Rajiv, 2003, Indian Journal of Pediatrics, V70, P51, DOI 10.1007/BF02722745
   [Anonymous], 2008, LANCET, V372, P508
   BALAKRISHNAN S, 2005, INDIAN J CRIT CARE M, V9, P2
   Chakravarti U, 2008, INDIAN J GEND STUD, V15, P341, DOI 10.1177/097152150801500207
   Clements KM, 2007, PEDIATRICS, V119, pE866, DOI 10.1542/peds.2006-1729
   Daniels N, 2008, JUST HLTH
   Darmstadt GL, 2008, HEALTH POLICY PLANN, V23, P101, DOI 10.1093/heapol/czn001
   Darmstadt GL, 2005, LANCET, V365, P977, DOI 10.1016/S0140-6736(05)71088-6
   Dror DM, 2008, INDIAN J MED RES, V127, P347
   Goldenberg RL, 2008, LANCET, V371, P75, DOI 10.1016/S0140-6736(08)60074-4
   Haws RA, 2007, HEALTH POLICY PLANN, V22, P193, DOI 10.1093/heapol/czm009
   Korvenranta E, 2009, PEDIATRICS, V124, P128, DOI 10.1542/peds.2008-1378
   Kruk ME, 2009, HEALTH AFFAIR, V28, P1056, DOI 10.1377/hlthaff.28.4.1056
   Kuhse Helga, 1985, SHOULD BABY LIVE PRO
   KYMLICKA W, 1993, BIOETHICS, V7, P1, DOI 10.1111/j.1467-8519.1993.tb00268.x
   Mangham LJ, 2009, PEDIATRICS, V123, pE312, DOI 10.1542/peds.2008-1827
   McIntyre D, 2006, SOC SCI MED, V62, P858, DOI 10.1016/j.socscimed.2005.07.001
   Miljeteig I, 2006, DEV WORLD BIOETH, V6, P23, DOI 10.1111/j.1471-8847.2006.00133.x
   Miljeteig I, 2009, PEDIATRICS, V124, pE322, DOI 10.1542/peds.2008-3227
   *MIN SOC JUST EMP, 2001, GOV IND
   MURRAY C, 1996, GLOBAL BURDEN DIS, P57
   *NAT NEON FOR NNPD, 2004, NAT NEON PER DAT HUM
   Norheim OF, 2002, HEALTH CARE ANAL, V10, P309, DOI 10.1023/A:1022955909060
   NUSSBAUM M, 2000, HUMAN DEV CAPABILITE
   Persad G, 2009, LANCET, V373, P423, DOI 10.1016/S0140-6736(09)60137-9
   Russell RB, 2007, PEDIATRICS, V120, pE1, DOI 10.1542/peds.2006-2386
   Sharma BR, 2005, MED SCI LAW, V45, P161, DOI 10.1258/rsmmsl.45.2.161
   Srivastava NM, 2009, BMC HEALTH SERV RES, V9, DOI 10.1186/1472-6963-9-61
   Strech D, 2008, J MED PHILOS, V33, P80, DOI 10.1093/jmp/jhm007
   Tsuchiya A, 2000, HEALTH ECON, V9, P57, DOI 10.1002/(SICI)1099-1050(200001)9:1<57::AID-HEC484>3.0.CO;2-N
   Ubel PA, 1997, ANN INTERN MED, V126, P74, DOI 10.7326/0003-4819-126-1-199701010-00010
   *UN CHILDR FUND, 2008, STAT AS PAS CHILDR 2
   World Health Organization, 2003, MAN NEWB PROBL GUID
NR 34
TC 9
Z9 9
U1 0
U2 1
PU B M J PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0306-6800
J9 J MED ETHICS
JI J. Med. Ethics
PD AUG
PY 2010
VL 36
IS 8
BP 473
EP 478
DI 10.1136/jme.2010.035535
PG 6
WC Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical
SC Social Sciences - Other Topics; Medical Ethics; Social Issues;
   Biomedical Social Sciences
GA 630YO
UT WOS:000280313000006
PM 20663764
DA 2019-03-21
ER

PT J
AU van der Plas, A
   Smits, M
   Wehrmann, C
AF van der Plas, Arjanna
   Smits, Martijntje
   Wehrmann, Caroline
TI Beyond Speculative Robot Ethics: A Vision Assessment Study on the Future
   of the Robotic Caretaker
SO ACCOUNTABILITY IN RESEARCH-POLICIES AND QUALITY ASSURANCE
LA English
DT Article
DE healthcare; long-term care; methodology; robots; visions; vision
   assessment
AB In this article we develop a dialogue model for robot technology experts and designated users to discuss visions on the future of robotics in long-term care. Our vision assessment study aims for more distinguished and more informed visions on future robots. Surprisingly, our experiment also led to some promising co-designed robot concepts in which jointly articulated moral guidelines are embedded. With our model, we think to have designed an interesting response on a recent call for a less speculative ethics of technology by encouraging discussions about the quality of positive and negative visions on the future of robotics.
C1 [Smits, Martijntje] Rathenau Inst, NL-2593 HW The Hague, Netherlands.
   [van der Plas, Arjanna] TNO Informat & Commun Technol, Delft, Netherlands.
   [Wehrmann, Caroline] Delft Univ Technol, Delft, Netherlands.
RP Smits, M (reprint author), Rathenau Inst, Anna van Saksenlaan 51, NL-2593 HW The Hague, Netherlands.
EM m.smits@rathenau.nl
CR Asimov I., 1950, I ROBOT
   Bostrom N., 2006, REV CONT PHILOS, V5, P66
   Butter M., 2008, ROBOTICS HEALTHCARE
   *CBS, 2009, DOSS VERGR
   DECKER M, 1997, GRAUE REIHE, V8
   Decker M, 2008, AI SOC, V22, P315, DOI 10.1007/s00146-007-0151-0
   DORRESTEIN S, 2010, MORALICIDE NIEUWE MO
   Grunwald A., 2000, VISION ASSESSMENT SH
   GRUNWALD A, 2004, EU US SEMINAR NEW TE
   Grunwald A, 2007, FUTURES, V39, P380, DOI 10.1016/j.futures.2006.08.001
   HEERINK M, 2006, P ICOST BELF UK
   HEGEL F, 2007, 16 IEEE INT C ROB HU
   LAU YY, 2009, SURFACE EXPLORATION
   LEVY D, 2009, INT J SOCIAL ROBOTIC, V1, P3
   Mambrey P., 2000, VISION ASSESSMENT SH, P33
   Nordmann A, 2009, NAT NANOTECHNOL, V4, P273, DOI 10.1038/nnano.2009.26
   OHNISHI N, 2006, NY TIMES        0402
   Roelofsen A, 2008, TECHNOL FORECAST SOC, V75, P334, DOI 10.1016/j.techfore.2007.01.004
   SER (Sociaal-Economische Raad), 2008, LANGD ZORG VERZ TOEK
   SINGER P, 2009, GUARDIAN        1214
   Singer P, 2009, WIRED WAR
   Smaling A., 2008, DIALOOG EMPATHIE MET
   Smits M, 2006, TECHNOL SOC, V28, P489, DOI 10.1016/j.techsoc.2006.09.008
   TEPPER A, 1993, BEHAV INFORM TECHNOL, V12, P336, DOI 10.1080/01449299308924398
   VANDENBERG B, 2010, MORALICIDE
   VANDERPLAS A, 2010, ROBOTIC CARETAKER DE
   VERBEEK PP, 2009, FILOSOFIE MENS TECHN
NR 27
TC 6
Z9 6
U1 1
U2 9
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0898-9621
J9 ACCOUNT RES
JI Account. Res.
PY 2010
VL 17
IS 6
SI SI
BP 299
EP 315
AR PII 929385493
DI 10.1080/08989621.2010.524078
PG 17
WC Medical Ethics
SC Medical Ethics
GA 678WV
UT WOS:000284114800003
PM 21069593
DA 2019-03-21
ER

PT J
AU Weng, YH
AF Weng, Yueh-Hsuan
TI Beyond Robot Ethics: On a Legislative Consortium for Social Robotics
SO ADVANCED ROBOTICS
LA English
DT Article
DE Robot ethics; robot policy; robot law; social system design; social
   robotics
AB As robots are increasingly integrated into human society, associated problems will resemble or merge with those in other fields - we can refer to this phenomenon as the 'robot sociability problem'. In this paper, the author first analyzes the dynamic relationship between robot ethics, robotics and robot law, and then proposes a 'practical robots' approach for solving the robot sociability problem. As this approach is based on legal regulations, the author posits that a functional platform such as a 'legislative consortium for social robotics' is crucial at the initial stage for social robotics development. In conclusion, the author discusses how a legislative consortium for social robotics will be a useful approach for solving the robot sociability problem, especially emerging structural legislative problems that are related to autonomous robots. (C) Koninklijke Brill NV, Leiden and The Robotics Society of Japan, 2010
C1 [Weng, Yueh-Hsuan] Peking Univ, Sch Law, Beijing 100871, Peoples R China.
   [Weng, Yueh-Hsuan] Yushan Studio Artificial Intelligence & Law, Beijing 100871, Peoples R China.
RP Weng, YH (reprint author), Peking Univ, Sch Law, Beijing 100871, Peoples R China.
EM weng.yuehhsuan@gmail.com
CR [Anonymous], 2007, SAF GUID NEXT GEN RO
   *AS SHIMB, 2010, ROB SAF STAND PLANN
   BLECH J, 2007, SPIEGEL ONLINE INT
   Computing Community Consortium, 2009, ROADM US ROB INT ROB
   *EUR ROB RES NETW, 2006, ROB ROADM REL 1 1
   Robot Policy Council, 2005, ROB POL MIDDL REP MA
   SATO T, 2007, CREST ANN RES REPORT
   Sim HB, 2007, IEEE INT C ROB AUT W
   Veruggio G., 2005, IEEE INT C ROB AUT W
   Weng Y-H., 2007, P 11 INT C ART INT L, P205, DOI 10.1145/1276318.1276358
   WENG YH, 2009, IEEE INT C ROB AUT W
   Weng YH, 2009, INT J SOC ROBOT, V1, P267, DOI 10.1007/s12369-009-0019-1
   *WIKT, SOC
   ZYGA L, 2009, LIVING SAFELY ROBOTS
NR 14
TC 4
Z9 4
U1 1
U2 7
PU VSP BV
PI LEIDEN
PA BRILL ACADEMIC PUBLISHERS, PO BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 0169-1864
J9 ADV ROBOTICS
JI Adv. Robot.
PY 2010
VL 24
IS 13
BP 1919
EP 1926
DI 10.1163/016918610X527220
PG 8
WC Robotics
SC Robotics
GA 679GY
UT WOS:000284151100008
DA 2019-03-21
ER

PT J
AU Sabanovic, S
AF Sabanovic, Selma
TI It takes a village to construct a robot A socially situated perspective
   on the ethics of robot design
SO INTERACTION STUDIES
LA English
DT Editorial Material
C1 Indiana Univ, Sch Informat & Comp, Bloomington, IN 47408 USA.
RP Sabanovic, S (reprint author), Indiana Univ, Sch Informat & Comp, 919 E 10th St, Bloomington, IN 47408 USA.
EM selmas@indiana.edu
CR CLANCEY WJ, 1997, SITUATED COGNITION H
   DiSalvo C, 2008, P 10 ANN C PART DES, P41
   Forlizzi J, 2004, HUM-COMPUT INTERACT, V19, P25, DOI 10.1207/s15327051hci1901&2_3
   Hamner E., 2008, P AAAI SPRING S US A, P38
   Lave J., 1988, COGNITION PRACTICE M
   Liamputtong P., 2007, RES VULNERABLE GUIDE
   MUMFORD L, 1964, TECHNOL CULT, V5, P1, DOI 10.2307/3101118
   Nardi B. A., 2000, INFORM ECOLOGIES USI
   SABANOVIC S, 2009, P AAAI 2009 SPRING S, P41
   Sharkey N, 2010, INTERACT STUD, V11, P161, DOI 10.1075/is.11.2.o1sha
   Suchman L, 2007, LEARN DOING, P1, DOI 10.2277/ 052167588X
   TANAKA F, 2007, P NATL ACAD SCI USA, V104, P17054
   Wada K, 2009, J ADV COMPUT INTELL, V13, P386, DOI 10.20965/jaciii.2009.p0386
   Wenger E., 1998, COMMUNITIES PRACTICE
   WILLIAMS R, 1996, RES POLICY, V25, P856
NR 15
TC 3
Z9 3
U1 0
U2 0
PU JOHN BENJAMINS PUBLISHING COMPANY
PI AMSTERDAM
PA PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS
SN 1572-0373
J9 INTERACT STUD
JI Interact. Stud.
PY 2010
VL 11
IS 2
BP 257
EP 262
DI 10.1075/is.11.2.13sab
PG 6
WC Communication; Linguistics
SC Communication; Linguistics
GA 634WC
UT WOS:000280615600013
DA 2019-03-21
ER

PT J
AU Tonkens, R
AF Tonkens, Ryan
TI A Challenge for Machine Ethics
SO MINDS AND MACHINES
LA English
DT Article
DE Machine Ethics; Artificial moral agents; Kantian morality; Ethical
   consistency
ID ROBOTS
AB That the successful development of fully autonomous artificial moral agents (AMAs) is imminent is becoming the received view within artificial intelligence research and robotics. The discipline of Machines Ethics, whose mandate is to create such ethical robots, is consequently gaining momentum. Although it is often asked whether a given moral framework can be implemented into machines, it is never asked whether it should be. This paper articulates a pressing challenge for Machine Ethics: To identify an ethical framework that is both implementable into machines and whose tenets permit the creation of such AMAs in the first place. Without consistency between ethics and engineering, the resulting AMAs would not be genuine ethical robots, and hence the discipline of Machine Ethics would be a failure in this regard. Here this challenge is articulated through a critical analysis of the development of Kantian AMAs, as one of the leading contenders for being the ethic that can be implemented into machines. In the end, however, the development of Kantian artificial moral machines is found to be anti-Kantian. The upshot of all this is that machine ethicists need to look elsewhere for an ethic to implement into their machines.
C1 York Univ, Toronto, ON M3J 2R7, Canada.
RP Tonkens, R (reprint author), York Univ, Toronto, ON M3J 2R7, Canada.
EM tonkens@yorku.ca
CR Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83
   Anderson M, 2007, MIND MACH, V17, P1, DOI 10.1007/s11023-007-9053-7
   Anderson M, 2006, IEEE INTELL SYST, V21, P10, DOI 10.1109/MIS.2006.70
   Andersoni DF, 2007, J PSYCHOSOM OBST GYN, V28, P26
   Boden MA, 1994, DIMENSIONS CREATIVIT
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   Calverley DJ, 2008, AI SOC, V22, P523, DOI 10.1007/s00146-007-0092-7
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   GIPS J, 2005, CREATING ETHICAL ROB
   Gips J., 1995, ANDROID EPISTEMOLOGY, P243
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5
   KANT I., 1797, METAPHYSICS MORALS
   Kant I., 1785, FUNDAMENTAL PRINCIPL
   Kant Immanuel, 1997, LECT ETHICS
   McCarthy J, 2000, J EXP THEOR ARTIF IN, V12, P341, DOI 10.1080/09528130050111473
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67
   Mill JS, 1871, UTILITARIANISM
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80
   Nadeau J. E., 2006, THINKING ANDROID EPI, P241
   O'Neill Onora, 1989, CONSTRUCTIONS REASON
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77
   Rawls John, 2000, LECT HIST MORAL PHIL
   Sparrow R, 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8
   Wallach W., 2009, MORAL MACHINES TEACH
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0
   2006, US ARMY FUTURE COMBA
NR 32
TC 21
Z9 21
U1 7
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-6495
J9 MIND MACH
JI Minds Mach.
PD AUG
PY 2009
VL 19
IS 3
BP 421
EP 438
DI 10.1007/s11023-009-9159-1
PG 18
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 519FS
UT WOS:000271751000007
DA 2019-03-21
ER

PT J
AU Cotton, M
AF Cotton, Matthew
TI Evaluating the 'Ethical Matrix' as a Radioactive Waste Management
   Deliberative Decision-Support Tool
SO ENVIRONMENTAL VALUES
LA English
DT Article
DE Radioactive waste management; analytic-deliberative methods; public and
   stakeholder engagement; ethical tools; ethical matrix
ID PRINCIPLES; SEARCH; POLICY
AB UK radioactive waste management policy making is currently taking place within a participatory and analytic-deliberative decision-making framework; one that seeks to integrate public and stakeholder values and perspectives with scientific and technical expertise. One important aspect of this socio-technical reframing of the radioactive waste problem is an explicit recognition that legitimate and defensible policy making must take into account important ethical issues if it is to be a success. Thus, there is a need for tools to incorporate adequate assessment of ethical issues in a way that is compatible with this approach. The 'ethical matrix' is one such tool used recently to address a range of agricultural and natural resource issues that shows promise for this field. This paper assesses the strengths and limitations of the matrix and outlines a framework for the development of alternative tools to better satisfy the needs of ethical assessment in radioactive waste management decision-making processes.
C1 Univ Manchester, Sch Environm & Dev, Manchester Architecture Res Ctr, Manchester M13 9PL, Lancs, England.
RP Cotton, M (reprint author), Univ Manchester, Sch Environm & Dev, Manchester Architecture Res Ctr, Manchester M13 9PL, Lancs, England.
EM matthew.cotton@manchester.ac.uk
OI Cotton, Matthew/0000-0002-8877-4822
CR Atherton E, 2001, INTERDISCIPL SCI REV, V26, P296, DOI 10.1179/030801801679548
   Beauchamp TL, 2001, PRINCIPLES BIOMEDICA
   Beekman V, 2007, J AGR ENVIRON ETHIC, V20, P3, DOI 10.1007/s10806-006-9024-7
   BLOWERS A, 2006, ETHICS ANDDECISION M
   Brook A., 1997, CONT MORAL ISSUES
   Burgess J., 2004, DELIBERATE OPTIONS M
   Burgess J, 2007, PUBLIC UNDERST SCI, V16, P299, DOI 10.1177/0963662507077510
   Carter L.J., 1989, NUCL IMPERATIVES PUB
   Chadwick R, 2003, FUNCTIONAL FOODS
   Chilvers J., 2003, SECURING PUBLIC CONF
   Clark J, 2006, INTERFACES SCI SOC
   COTTON M, 2008, THESIS U E ANGLIA
   COTTON M, J RISK RES IN PRESS
   Defra, 2007, MAN RAD WAST SAF FRA
   Department for Environment Food and Rural Affairs (DEFRA), 2001, MAN RAD WAST SAF PRO
   Elmendorf William F., 2001, Journal of Arboriculture, V27, P139
   Fabre Cecile, 2003, POLITICAL STUDIES RE, V1, P4
   FEC, 2005, ETH MATR US
   Florini AM, 1999, ANN WB CONF DEV ECON, P163
   Flueler T., 2006, DECISION MAKING COMP
   Flueler T., 2005, TOOLS LOCAL STAKEHOL
   Flueler T., 2004, RISK DECISION POLICY, V9, P129
   Forsberg E. M., 2002, ETHICAL DECISION MAK
   Forsberg EM, 2007, J AGR ENVIRON ETHIC, V20, P455, DOI 10.1007/s10806-007-9050-0
   FRISCH D, 1993, ORGAN BEHAV HUM DEC, V54, P399, DOI 10.1006/obhd.1993.1017
   Gamborg C, 2002, FOREST POLICY ECON, V4, P175, DOI 10.1016/S1389-9341(02)00007-2
   Goodpaster K. E., 1991, BUSINESS ETHICS Q, V1, P53, DOI DOI 10.2307/3857592
   Grimble R, 1997, AGR SYST, V55, P173, DOI 10.1016/S0308-521X(97)00006-1
   Habermas J, 1980, DISCOURSE ETHICS NOT
   Hadjilambrinos C., 1999, B SCI TECHNOL SOC, V19, P179
   HARPER D, 2002, VISUAL STUDIES, V17, P13, DOI DOI 10.1080/14725860220137345
   HOWARD BJ, 2002, INT C RAD ENV MON, P506
   HUNT J, 2001, FRONT FRONT END MAPP
   Jacobs M., 1997, VALUING NATURE EC ET, P211
   JOHNSON J, 1991, POLIT THEORY, V19, P181, DOI 10.1177/0090591791019002003
   Kaiser M, 2001, J AGR ENVIRON ETHIC, V14, P191, DOI 10.1023/A:1011300811590
   KAISER M, 2004, PRACTICAL ETHICS SEA
   Kaiser M., 2004, EVALUATION ETHICAL B
   Kemp R., 1992, POLITICS RADIOACTIVE
   Latour B., 1998, REMAKING REALITY NAT, P221
   LUQUE E, 2005, ENVIRON POLIT, V14, P221
   McCarthy J, 2003, Med Humanit, V29, P65, DOI 10.1136/mh.29.2.65
   McElroy B., 2000, GOWER HDB PROJECT MA, P757
   Mepham B., 1996, Food ethics., P101
   Mepham B, 2000, J AGR ENVIRON ETHIC, V12, P165, DOI 10.1023/A:1009542714497
   Mepham B., 2000, P NUTR SOC, V59, P609
   MEPHAM B, 2005, BIOETHICS INTRO BIOS
   Mepham B., 2001, CONCISE ENCY ETHICS
   MEPHAM B, 1997, ETHICAL ANAL GENETIC
   MEPHAM B, 2003, ETHICS ANIMAL FARMIN
   MILLAR K, 2002, SCI PUBLIC AFF, V3, P20
   Millar K, 2007, J AGR ENVIRON ETHIC, V20, P53, DOI 10.1007/s10806-006-9022-9
   MOORE CJ, 1996, BIOETHICAL ANAL TRAN
   *NDA, 2007, NUCL DEC AUTH NDA LA
   NOVAK JD, 1990, J RES SCI TEACH, V27, P937, DOI 10.1002/tea.3660271003
   OMAHONY J, 2004, STAKEHOLDER ROUTE CO
   ORIORDAN T, 1999, DELIBERATIVE INCLUSI
   Oughton D, 2004, J ENVIRON RADIOACTIV, V74, P171, DOI 10.1016/j.jenvrad.2004.01.009
   Oughton D., 2003, VALUES DECISIONS RIS
   Oughton D. H., 2003, SOCIAL ETHICAL ASPEC
   Owens S, 2000, ENVIRON PLANN A, V32, P1141, DOI 10.1068/a3330
   Palmer C., 2003, POIESIS PRAXIS, V1, P295
   Rawles K., 2002, COMPENSATION RADIOAC
   Rawles K., 2000, ETHICAL ISSUES DISPO
   Rawls J., 1951, PHILOS REV, V60, P177, DOI DOI 10.2307/2181696
   Rawls J., 1999, THEORY JUSTICE
   Satterfield T, 2001, ENVIRON VALUE, V10, P331, DOI 10.3197/096327101129340868
   Schmidt-Felzmann H, 2003, J MED PHILOS, V28, P581, DOI 10.1076/jmep.28.5.581.18817
   SCOTT WG, 1971, DECISIONS ORG SOC
   Shanahan J, 1999, SOC NATUR RESOUR, V12, P405, DOI 10.1080/089419299279506
   SHRADERFRECHETTE K, 1991, ENVIRON ETHICS, V13, P327, DOI 10.5840/enviroethics199113438
   Sjoberg Lennart, 2001, J RISK RES, V4, P75, DOI DOI 10.1080/136698701456040
   Slovic P., 2000, PERCEPTION RISK
   Stirling A, 2001, ENVIRON PLANN C, V19, P529, DOI 10.1068/c8s
   Stirling A., 2004, SCI CITIZENSHIP GLOB
   Sundqvist G., 2005, STAKEHOLDER INVOLVEM
   Sunstein C., 2003, WHY SOC NEED DISSENT
   Walzer N., 1996, COMMUNITY STRATEGIC
   Weisbord MR, 1996, SYST PRACTICE, V9, P71, DOI 10.1007/BF02173419
   WHITING TL, 2004, CANWEST VET C OCT 2
   Wilson MA, 2002, ECOL ECON, V41, P431, DOI 10.1016/S0921-8009(02)00092-7
NR 81
TC 8
Z9 8
U1 0
U2 10
PU WHITE HORSE PRESS
PI ISLE OF HARRIS
PA 1 STROND, ISLE OF HARRIS HS5 3UD, ENGLAND
SN 0963-2719
EI 1752-7015
J9 ENVIRON VALUE
JI Environ. Values
PD MAY
PY 2009
VL 18
IS 2
BP 153
EP 176
DI 10.3197/096327109X438044
PG 24
WC Ethics; Environmental Studies
SC Social Sciences - Other Topics; Environmental Sciences & Ecology
GA 438PK
UT WOS:000265567500003
DA 2019-03-21
ER

PT J
AU Danielson, P
AF Danielson, Peter
TI Moral Machines: Teaching Robots Right from Wrong
SO NATURE
LA English
DT Book Review
C1 [Danielson, Peter] Univ British Columbia, Ctr Appl Eth, Vancouver, BC V6T 1Z2, Canada.
RP Danielson, P (reprint author), Univ British Columbia, Ctr Appl Eth, Vancouver, BC V6T 1Z2, Canada.
EM pad@ethics.ubc.ca
CR Wallach W., 2008, MORAL MACHINES TEACH
NR 1
TC 2
Z9 2
U1 0
U2 9
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 0028-0836
EI 1476-4687
J9 NATURE
JI Nature
PD JAN 29
PY 2009
VL 457
IS 7229
BP 540
EP 540
DI 10.1038/457540a
PG 1
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA 400FA
UT WOS:000262852200026
OA Bronze
DA 2019-03-21
ER

PT J
AU White, DB
   Katz, MH
   Luce, JM
   Lo, B
AF White, Douglas B.
   Katz, Mitchell H.
   Luce, John M.
   Lo, Bernard
TI Who Should Receive Life Support During a Public Health Emergency? Using
   Ethical Principles to Improve Allocation Decisions
SO ANNALS OF INTERNAL MEDICINE
LA English
DT Article
ID MASS CRITICAL-CARE; PANDEMIC INFLUENZA; FAIR PROCESS; CRITICALLY-ILL;
   MEDICAL-CARE; TRIAGE; DISASTER; LAW
AB A public health emergency, such as an influenza pandemic, will lead to shortages of mechanical ventilators, critical care beds, and other potentially life-saving treatments. Difficult decisions about who will and will not receive these scarce resources will have to be made. Existing recommendations reflect a narrow utilitarian perspective, in which allocation decisions are based primarily on patients' chances of survival to hospital discharge. Certain patient groups, such as the elderly and those with functional impairment, are denied access to potentially life-saving treatments on the basis of additional allocation criteria. We analyze the ethical principles that could guide allocation and propose an allocation strategy that incorporates and balances multiple morally relevant considerations, including saving the most lives, maximizing the number of "life-years" saved, and prioritizing patients who have had the least chance to live through life's stages. We also argue that these principles are relevant to all patients and therefore should be applied to all patients, rather than selectively to the elderly, those with functional impairment, and those with certain chronic conditions. We discuss strategies to engage the public in setting the priorities that will guide allocation of scarce life-sustaining treatments during a public health emergency.
C1 [White, Douglas B.] Univ Calif San Francisco, Program Med Eth, Sch Med, San Francisco, CA 94143 USA.
   San Francisco Dept Publ Hlth, San Francisco, CA USA.
   San Francisco Gen Hosp, San Francisco, CA 94110 USA.
RP White, DB (reprint author), Univ Calif San Francisco, Program Med Eth, Sch Med, 521 Parnassus Ave,Suite C-126,Box 0903, San Francisco, CA 94143 USA.
EM dwhite@medicine.ucsf.edu
FU National Center for Research Resources [KL2 RR024130]; NIH
FX By grant KL2 RR024130 from the National Center for Research Resources, a
   component of the NIH and NIH Roadmap for Medical Research and by the
   Greenwall Foundation.
CR Agency for Healthc.Res.Quality (AHRQ), 2005, AHRQ PUBL, V05-P022
   Barnato AE, 2004, CRIT CARE CLIN, V20, P345, DOI 10.1016/j.ccc.2004.03.002
   Beauchamp TL, 2001, PRINCIPLES BIOMEDICA
   Beigel H, 2005, NEW ENGL J MED, V353, P1374
   Burkle FM, 2002, EMERG MED CLIN N AM, V20, P409, DOI 10.1016/S0733-8627(01)00008-6
   Childress James F, 1970, SOUNDINGS, V53, P339
   Childress JF, 2002, J LAW MED ETHICS, V30, P170, DOI 10.1111/j.1748-720X.2002.tb00384.x
   CHILDRESS JF, 2003, TRIAGE RESPONSE BIOT
   Christian MD, 2006, CAN MED ASSOC J, V175, P1377, DOI 10.1503/cmaj.060911
   Daniels N, 2000, BRIT MED J, V321, P1300, DOI 10.1136/bmj.321.7272.1300
   Daniels N, 2005, LANCET, V366, P169, DOI 10.1016/S0140-6736(05)66518-X
   Daniels N, 1997, PHILOS PUBLIC AFF, V26, P303, DOI 10.1111/j.1088-4963.1997.tb00082.x
   Danis M, 1997, CRIT CARE MED, V25, P887
   *DEP HLTH HUM SERV, 2007, DRAFT GUID IN PRESS
   Devereaux AV, 2008, CHEST, V133, p51S, DOI 10.1378/chest.07-2693
   Egan TM, 2005, CHEST, V128, P407, DOI 10.1378/chest.128.1.407
   Emanuel EJ, 2006, SCIENCE, V312, P854, DOI 10.1126/science.1125347
   Ferreira FL, 2001, JAMA-J AM MED ASSOC, V286, P1754, DOI 10.1001/jama.286.14.1754
   Gostin L, 2006, JAMA-J AM MED ASSOC, V295, P1700, DOI 10.1001/jama.295.14.1700
   Gostin LO, 2006, JAMA-J AM MED ASSOC, V295, P554, DOI 10.1001/jama.295.5.554
   Gostin LO, 2002, JAMA-J AM MED ASSOC, V288, P622, DOI 10.1001/jama.288.5.622
   HARRIS JR, 1985, VALUE LIFE
   Hick JL, 2006, ACAD EMERG MED, V13, P223, DOI 10.1197/j.aem.2005.07.037
   Justice AC, 1999, ANN INTERN MED, V130, P515, DOI 10.7326/0003-4819-130-6-199903160-00016
   LEVINSKY NG, 1984, NEW ENGL J MED, V311, P1573, DOI 10.1056/NEJM198412133112412
   Neuberger J, 1998, BMJ-BRIT MED J, V317, P172, DOI 10.1136/bmj.317.7152.172
   Pesik N, 2001, ANN EMERG MED, V37, P642, DOI 10.1067/mem.2001.114316
   PHILLIPS SJ, 2006, AHRQ PUBLICATION
   Powell T, 2008, DISASTER MED PUBLIC, V2, P20, DOI 10.1097/DMP.0b013e3181620794
   Public Engagement Pilot Project and Pandemic Influenza, 2005, CIT VOIC PAND FLU CH
   Ramsey P., 1970, PATIENT PERSON
   Repine TB, 2005, MIL MED, V170, P505, DOI 10.7205/MILMED.170.6.505
   RESCHER N, 1969, ETHICS, V79, P173, DOI 10.1086/291723
   Rubinson L, 2005, CRIT CARE MED, V33, P2393, DOI 10.1097/01.CCM.0000173411.06574.D5
   SANDERS D, 1968, UCLA LAW REV, V15, P357
   Shortt SED, 1999, CAN MED ASSOC J, V161, P823
   TANNER L, 2008, WASHINGTON POST 0505
   Toner E, 2006, BIOSECUR BIOTERROR, V4, P207, DOI 10.1089/bsp.2006.4.207
   vandenBos K, 1997, J PERS SOC PSYCHOL, V72, P1034, DOI 10.1037/0022-3514.72.5.1034
   Veatch RM, 1997, KENNEDY INST ETHIC J, V7, P391, DOI 10.1353/ken.1997.0041
   Williams A, 1997, HEALTH ECON, V6, P117, DOI 10.1002/(SICI)1099-1050(199703)6:2<117::AID-HEC256>3.0.CO;2-B
NR 41
TC 74
Z9 76
U1 1
U2 9
PU AMER COLL PHYSICIANS
PI PHILADELPHIA
PA INDEPENDENCE MALL WEST 6TH AND RACE ST, PHILADELPHIA, PA 19106-1572 USA
SN 0003-4819
EI 1539-3704
J9 ANN INTERN MED
JI Ann. Intern. Med.
PD JAN 20
PY 2009
VL 150
IS 2
BP 132
EP U94
DI 10.7326/0003-4819-150-2-200901200-00011
PG 8
WC Medicine, General & Internal
SC General & Internal Medicine
GA 397ID
UT WOS:000262655200008
PM 19153413
OA Green Accepted
DA 2019-03-21
ER

PT J
AU Sakura, O
AF Sakura, Osamu
TI Brain-Machine Interface and society: designing a system of ethics and
   governance
SO NEUROSCIENCE RESEARCH
LA English
DT Meeting Abstract
C1 [Sakura, Osamu] Univ Tokyo, Tokyo, Japan.
NR 0
TC 0
Z9 0
U1 0
U2 6
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0168-0102
J9 NEUROSCI RES
JI Neurosci. Res.
PY 2009
VL 65
SU 1
BP S33
EP S33
DI 10.1016/j.neures.2009.09.1687
PG 1
WC Neurosciences
SC Neurosciences & Neurology
GA 528DK
UT WOS:000272421100220
DA 2019-03-21
ER

PT J
AU Armour, L
AF Armour, Leslie
TI Moral Machines: Teaching Robots Right from Wrong
SO LIBRARY JOURNAL
LA English
DT Book Review
C1 [Armour, Leslie] Dominican Univ Coll, Ottawa, ON, Canada.
RP Armour, L (reprint author), Dominican Univ Coll, Ottawa, ON, Canada.
CR Wallach W., 2008, MORAL MACHINES TEACH
NR 1
TC 0
Z9 0
U1 0
U2 1
PU REED BUSINESS INFORMATION
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010 USA
SN 0363-0277
J9 LIBR J
JI Libr. J.
PD OCT 15
PY 2008
VL 133
IS 17
BP 72
EP 72
PG 1
WC Information Science & Library Science
SC Information Science & Library Science
GA 363XP
UT WOS:000260301100131
DA 2019-03-21
ER

PT J
AU England, GCW
   Millar, KM
AF England, G. C. W.
   Millar, K. M.
TI The ethics and role of AI with fresh and frozen semen in dogs
SO REPRODUCTION IN DOMESTIC ANIMALS
LA English
DT Article; Proceedings Paper
CT 16th International Congress on Animal Reproduction
CY JUL 13-17, 2008
CL Budapest, HUNGARY
ID INSEMINATION; BITCH
AB The use of artificial insemination (AI) with fresh semen has resulted in many benefits for the management of dog breeding, but there are disadvantages that can sometimes be overlooked. Furthermore, poorer quality semen arising as a result of cryopreservation necessitates uterine insemination, which raises the potential for surgical insemination. A number of significant ethical concerns have been raised by key stakeholders (such as The Kennel Club and the Royal College of Veterinary Surgeons) about AI per se, but particularly about the use of surgical insemination. This paper discusses the technological development of AI and explores a number of the ethical issues raised by its application to dog breeding. An Ethical Matrix method is used to map the potential ethical issues for key interest groups, namely dogs, breeders, owners, veterinarians and wider society. There are national variations in the way in which institutions have evaluated potential ethical impacts, and this is reflected in the different regulatory frameworks governing the use of AI in dogs. In order to facilitate decision-making and reduce some of the ethical risks associated with this technology, the veterinary research community could take several proactive steps including: (i) clarifying clinical decision-making processes, (ii) enhancing informed choice among clients and (iii) increasing the knowledge-base of potential impacts of AI.
C1 [England, G. C. W.] Univ Nottingham, Sch Vet Med & Sci, Nottingham, England.
   [Millar, K. M.] Univ Nottingham, Sch Biosci, Ctr Appl Bioeth, Nottingham, England.
RP England, GCW (reprint author), Univ Nottingham, Sch Vet Med & Sci, Sutton Bonington Campus, Loughborough LE12 5RD, Leics, England.
EM Gary.England@nottingham.ac.uk
RI England, Gary/G-5432-2011
OI England, Gary/0000-0001-5800-3106; Millar, Kate/0000-0002-7155-7776
CR England GCW, 1996, THERIOGENOLOGY, V46, P1233, DOI 10.1016/S0093-691X(96)00294-4
   Evans EI, 1933, AM J PHYSIOL, V105, P287
   Fontbonne A, 1993, J Reprod Fertil Suppl, V47, P325
   FOUGNER JA, 1973, NORD VET MED, V25, P144
   Linde-Forsberg C, 1993, J Reprod Fertil Suppl, V47, P313
   LINDEFORSBERG C, 2002, P 3 EVSSAR C LIEG BE, P41
   LINDSAY FEF, 1983, J SMALL ANIM PRACT, V24, P1, DOI 10.1111/j.1748-5827.1983.tb00407.x
   Mepham T. B., 2000, J AGR ENVIRON ETHIC, V12, P165
   Millar K, 2007, J AGR ENVIRON ETHIC, V20, P437, DOI 10.1007/s10806-007-9051-z
   OLAR TT, 1984, THESIS COLORADO STAT
   *RCVS, 2005, 8 RCVS
   SEAGER SWJ, 1975, J REPROD FERTIL, V45, P189
   SMITH FO, 1984, THESIS U MINNESOTA
   Takeishi M., 1976, Japanese Journal of Animal Reproduction, V22, P28
   Thomassen R, 2006, THERIOGENOLOGY, V66, P1645, DOI 10.1016/j.theriogenology.2006.01.022
   Tomkins S, 2006, ETHICAL MATRIX MANUA
   WILDT DE, 1986, SMALL ANIMAL REPRODU, P121
   Wilson M S, 1993, J Reprod Fertil Suppl, V47, P307
   Wilson MS, 2001, VET CLIN N AM-SMALL, V31, P291, DOI 10.1016/S0195-5616(01)50206-5
NR 19
TC 17
Z9 17
U1 8
U2 25
PU BLACKWELL PUBLISHING
PI OXFORD
PA 9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND
SN 0936-6768
J9 REPROD DOMEST ANIM
JI Reprod. Domest. Anim.
PD JUL
PY 2008
VL 43
SU 2
BP 165
EP 171
DI 10.1111/j.1439-0531.2008.01157.x
PG 7
WC Agriculture, Dairy & Animal Science; Reproductive Biology; Veterinary
   Sciences
SC Agriculture; Reproductive Biology; Veterinary Sciences
GA 327AH
UT WOS:000257700600022
PM 18638119
DA 2019-03-21
ER

PT J
AU Whitby, B
AF Whitby, Blay
TI Sometimes it's hard to be a robot: A call for action on the ethics of
   abusing artificial agents
SO INTERACTING WITH COMPUTERS
LA English
DT Article
DE robot ethics; abusive interaction; ethical design
AB This is a call for informed debate on the ethical issues raised by the forthcoming widespread use of robots, particularly in domestic settings. Research shows that humans can sometimes become very abusive towards computers and robots particularly when they are seen as human-like and this raises important ethical issues.
   The designers of robotic systems need to take an ethical stance on at least three specific questions. Firstly is it acceptable to treat artefacts - particularly human-like artefacts - in ways that we would consider it morally unacceptable to treat humans? Second, if so, just how much sexual or violent 'abuse' of an artificial agent should we allow before we censure the behaviour of the abuser? Thirdly is it ethical for designers to attempt to 'design out' abusive behaviour by users?
   Conclusions on. these and related issues should be used to modify professional codes as a matter of urgency. (C) 2008 Elsevier B.V. All rights reserved.
C1 Univ Sussex, Dept Informat, Brighton BN1 9QH, E Sussex, England.
RP Whitby, B (reprint author), Univ Sussex, Dept Informat, Brighton BN1 9QH, E Sussex, England.
EM blayw@sussex.ac.uk
CR Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   Anderson CA, 2001, PSYCHOL SCI, V12, P353, DOI 10.1111/1467-9280.00366
   Aristotle, 1968, POETICS
   BODEN MA, 2006, MINDS AMCHINE HIST C, P1094
   DEANGELI A, 2006, P CHI 06, P1650
   du Boulay B, 1999, FR ART INT, V50, P225
   Fogg B. J., 1999, P SIGCHI C HUM FACT, P80, DOI DOI 10.1145/302979.303001
   FRUDE N, 1983, INTIMATE MACHINE CLO
   Galtung Johan, 1969, WASHINGTON POST 0506, V6, P167
   Gates Bill, 2007, SCI AM, P58, DOI DOI 10.1038/SCIENTIFICAMERICAN0107-58
   HOBBES T, 1651, LEVIATHAN, V14, P25
   KANT I, 1988, CRITIQUE PRACTICAL R, V8, P287
   LaChat MR, 1986, AI MAG, V7, P70
   LOVGREN S, 2006, NATL GEOGRAPHIC 0906, P2006
   MILL JS, 1859, SELECTION WORKS, P14
   Picard R., 1998, AFFECTIVE COMPUTING
   Singer P, 1979, PRACTICAL ETHICS
   TORRANCE S, 2000, P AISB 2000 S ART IN, P47
   TURING AM, 1950, COMPUTING MACHINERY, P236
   Weizenbaum J., 1984, COMPUTER POWER HUMAN
   WHITBY BR, 1993, INTELLIGENT TUTORING, V3
   WHITBY BR, 1996, INTELLECT EXETER, P93
   WHITBY BR, 1988, ARTIF INTELL, P152
NR 23
TC 24
Z9 24
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0953-5438
J9 INTERACT COMPUT
JI Interact. Comput.
PD MAY
PY 2008
VL 20
IS 3
BP 326
EP 333
DI 10.1016/j.intcom.2008.02.002
PG 8
WC Computer Science, Cybernetics; Ergonomics
SC Computer Science; Engineering
GA 311VZ
UT WOS:000256629800005
DA 2019-03-21
ER

PT J
AU Dix, A
AF Dix, Alan
TI Response to "Sometimes it's hard to be a robot: A call for action on the
   ethics of abusing artificial agents"
SO INTERACTING WITH COMPUTERS
LA English
DT Editorial Material
C1 Univ Lancaster, Dept Comp, InfoLab21, Lancaster LA1 4WA, England.
RP Dix, A (reprint author), Univ Lancaster, Dept Comp, InfoLab21, South Dr, Lancaster LA1 4WA, England.
EM alan@hcibook.com
CR *BBC, 2007, 2 LIF CHILD AB CLAIM
   BENTHAM J, 1823, INTRO PRINCIPLES MOR, pCH1
   DEANGELI A, 2005, STUPID COMPUTER ABUS
   Dennett DC, 2005, JEAN NICOD LECT, P1
   DIBBELL J, 1999, MY TINY LIFE CRIME P, V38
   *KOL AD CTRJEW LEA, 2007, EXPL PARSH REEH
   NOZICK ROBERT, 1974, ANARCHY STATE UTOPIA
   PEIRIS D, 1997, THESIS U DUNDEE
   Rawls J., 1971, THEORY JUSTICE
   Searle J. R., 1997, MYSTERY CONSCIOUSNES
   Singer Peter, 1975, ANIMAL LIBERATION
   WARD M, 2003, BBC NEWS ONLINE 1222
NR 12
TC 2
Z9 2
U1 1
U2 4
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0953-5438
EI 1873-7951
J9 INTERACT COMPUT
JI Interact. Comput.
PD MAY
PY 2008
VL 20
IS 3
BP 334
EP 337
DI 10.1016/j.intcom.2008.02.003
PG 4
WC Computer Science, Cybernetics; Ergonomics
SC Computer Science; Engineering
GA 311VZ
UT WOS:000256629800006
DA 2019-03-21
ER

PT J
AU Thimbleby, H
AF Thimbleby, Harold
TI Robot ethics? Not yet - A reflection on Whitby's "Sometimes it's hard to
   be a robot"
SO INTERACTING WITH COMPUTERS
LA English
DT Article
DE robot ethics; meta-ethics
AB Science fiction stories seductively portray robots as human. In present reality (early 21st century) robots are machines, even though they can do many things far better than humans (fly, swim, play chess to name a few). Any ethics for or of robots is therefore a seductive mix of fiction and reality. The key issue for rational discourse is to provide a rigorous framework for reasoning about the issues, including identifying flaws in the framework. We find such meta-reasoning in discussion about robot ethics to be ready for improvement.
   This paper takes its inspiration from B. Whitby, "Sometimes it's hard to be a robot: A call for action on the ethics of abusing artificial agents," Interacting with Computers, this issue, 2008. (C) 2008 Published by Elsevier B.V.
C1 Swansea Univ, Future Interact Lab, Dept Comp Sci, Swansea SA2 0SF, W Glam, Wales.
RP Thimbleby, H (reprint author), Swansea Univ, Future Interact Lab, Dept Comp Sci, Singleton Pk, Swansea SA2 0SF, W Glam, Wales.
EM H.Thimbleby@swansea.ac.uk
RI Thimbleby, Harold/D-4389-2013
OI Thimbleby, Harold/0000-0003-2222-4243
CR DANIELSON P, 1992, ARTIFICAL MORALITY V
   FRENCH JW, 2008, MODERN POWER GENERAT
   Moravec H., 1998, ROBOT MERE MACHINE T
   Perry W. G., 1999, FORMS ETHICAL INTELL
   Thimbleby H., 2007, PRESS
   THIMBLEBY HW, 1995, IEEE T SYST MAN CYB, V25, P1166, DOI 10.1109/21.391298
   WHITBY B, INTERACTING COMPUTER
NR 7
TC 5
Z9 5
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0953-5438
J9 INTERACT COMPUT
JI Interact. Comput.
PD MAY
PY 2008
VL 20
IS 3
BP 338
EP 341
DI 10.1016/j.intcom.2008.02.006
PG 4
WC Computer Science, Cybernetics; Ergonomics
SC Computer Science; Engineering
GA 311VZ
UT WOS:000256629800007
DA 2019-03-21
ER

PT J
AU Anderson, M
   Anderson, SL
AF Anderson, Michael
   Anderson, Susan Leigh
TI Machine ethics: Creating an ethical intelligent agent
SO AI MAGAZINE
LA English
DT Article
AB The newly emerging in field of machine ethics (Anderson and Anderson 2006) is concerned with adding an ethical dimension to machines. Unlike computer ethics-which has traditionally focused on ethical issues surrounding humans' use of machines-machine ethics is concerned with ensuring that the behavior of machines toward human users, and perhaps other machines as well, is ethically acceptable. In this article we discuss the importance of machine ethics, the need for machines that represent ethical principles explicitly, and the challenges facing those working on machine ethics. We also give an example of current research in the field that shows that it is possible, at least in a limited domain, for a machine to abstract an ethical principle from examples of correct ethical judgments and use that principle to guide its own behavior.
CR Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   ANDERSON M, 2006, P 8 C INN APPL ART I
   ANDERSON M, 1995, J PHILOSOPHICAL RES, V20, P453
   Anderson M, 2005, FS0506
   ANDERSON M, 2006, IEEE INELLIGENT SYST, V21
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64
   ASIMOV I, 1976, STELLAR SCI FICTION
   Baral C., 2003, KNOWLEDGE REPRESENTA
   Beauchamp TJ, 1979, PRINCIPLES BIOMEDICA
   Bentham Jeremy, 1781, INTRO PRINCIPLES MOR
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82
   Brody B., 1988, LIFE DEATH DECISION
   Buchanan AE, 1989, DECIDING OTHERS ETHI
   CAPEK K, 1921, PHILOS SCI FICTION
   Clarke A.C, 1968, 2001 SPACE ODYSSEY
   Damasio A., 1994, DESCARTES ERROR EMOT
   Dennett D., 2006, INT COMP PHIL C LAV
   DIETRICH E, 2006, 2006 N AM COMP PHIL
   GANASCIA JG, 2007, 7 INT COMP ETH C SAN
   GAZZANIGA M, 2006, ETHICAL BRAIN SCI MO
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76
   Horty JF, 2001, AGENCY DEONTIC LOGIC
NR 22
TC 52
Z9 52
U1 1
U2 17
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
J9 AI MAG
JI AI Mag.
PD WIN
PY 2007
VL 28
IS 4
BP 15
EP 25
PG 11
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 244DS
UT WOS:000251846800001
DA 2019-03-21
ER

PT J
AU Mathieson, K
AF Mathieson, Kieran
TI Towards a design science of ethical decision support
SO JOURNAL OF BUSINESS ETHICS
LA English
DT Review
DE Cognition; decision support systems; design science; emotion; ethics;
   group support systems; philosophy
ID FACE-TO-FACE; INFORMATION-SYSTEMS; PROBLEM FORMULATION; COMMUNICATION
   MODE; VIRTUAL TEAMS; PERFORMANCE; TASK; PERSPECTIVE; PERSONALITY;
   TECHNOLOGY
AB Ethical decision making involves complex emotional, cognitive, social, and philosophical challenges. Even if someone wants to be ethical, he or she may not have clearly articulated what that means, or know how to go about making a decision consistent with his or her values. Information technology may be able to help. A decision support system could offer individuals and groups some guidance, assisting them in making a decision that reflects their underlying values. The first step towards a design science of ethical decision support is to develop a theoretical base on which first-generation systems can be built. This paper brings together work in cognitive, social and moral psychology, information systems, and philosophy relevant to ethical decision making. Attributes of a system that would support ethical decision making are described.
C1 Oakland Univ, Sch Business Adm, Rochester, MI 48309 USA.
RP Mathieson, K (reprint author), Oakland Univ, Sch Business Adm, Rochester, MI 48309 USA.
EM mathieso@oakland.edu
CR ALAVI M, 1994, MIS QUART, V18, P159, DOI 10.2307/249763
   ALBA JW, 1987, J CONSUM RES, V13, P411, DOI 10.1086/209080
   Alonzo M, 2004, DECIS SUPPORT SYST, V36, P205, DOI 10.1016/S0167-9236(02)00190-2
   Armstrong David J., 2002, DISTRIBUTED WORK, P167, DOI [10.1037/10189-007, DOI 10.1037/10189-007]
   ARONSON B, 2002, FIND LAW        0124
   Asch S. E, 1951, GROUPS LEADERSHIP ME, P177
   ASHFORTH BE, 1995, HUM RELAT, V48, P97, DOI 10.1177/001872679504800201
   Baker G., 2002, INFORMATION RESOURCE, V15, P79, DOI [10.4018/irmj.2002100106, DOI 10.4018/IRMJ.2002100106]
   Bandura A., 1990, ORIGINS TERRORISM PS, P161
   Banerjee D, 1998, MIS QUART, V22, P31, DOI 10.2307/249677
   Barkhi R, 2004, DECIS SUPPORT SYST, V37, P287, DOI 10.1016/S0167-9236(03)00023-X
   Barrick MR, 2001, INT J SELECT ASSESS, V9, P9, DOI 10.1111/1468-2389.00160
   BARTON L, 1995, ETHICS ENEMY WORKPLA
   Bass B. M., 1998, ETHICS CHARACTER AUT
   BENBASAT I, 1993, SMALL GR RES, V24, P430, DOI 10.1177/1046496493244002
   BERANEK P, 2005, COMMUNICATIONS ASS I, V6, P247
   Bos N., 2001, P CHI 2001, P291
   Bradner E, 1999, P 6 EUR C COMP SUPP, P139
   Brass D. J., 2002, BLACKWELL COMPANION, P138
   Burke L.A., 2002, J MANAGERIAL PSYCHOL, V17, P712
   Butler BS, 2006, MIS QUART, V30, P211
   Byron M, 1998, ETHICS, V109, P67, DOI 10.1086/233874
   CAMPBELL DJ, 1988, ACAD MANAGE REV, V13, P40, DOI 10.2307/258353
   Cappel JJ, 2000, J BUS ETHICS, V28, P95, DOI 10.1023/A:1006344825235
   Carlson J. R., 1999, J MANAGEMENT ISSUES, V11, P180
   Cawley MJ, 2000, PERS INDIV DIFFER, V28, P997, DOI 10.1016/S0191-8869(99)00207-X
   Chae B, 2005, DECIS SUPPORT SYST, V40, P197, DOI 10.1016/j.dss.2004.02.002
   CHENA MY, 2006, IN PRESS DECISION SU
   CHENAULT B, 1998, CMC MAGAZINE, V5
   Chun R, 2005, J BUS ETHICS, V57, P269, DOI 10.1007/s10551-004-6591-2
   CLINE A, 2006, ETHICS MORALITY PHIL
   Colby A., 1995, MORALITY EVERYDAY LI, P342
   Cramton CD, 2001, ORGAN SCI, V12, P346, DOI 10.1287/orsc.12.3.346.10098
   Culnan M. J., 1987, HDB ORG COMMUNICATIO, P420
   DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554
   Daily B, 1996, INFORM MANAGE, V30, P281, DOI 10.1016/S0378-7206(96)01062-2
   Damasio  A., 2003, LOOKING SPINOZA JOY
   DARLEY JM, 1973, J PERS SOC PSYCHOL, V27, P100, DOI 10.1037/h0034449
   Dennis A. R., 1999, P 32 HAW INT C SYST, V10
   Dennis AR, 2004, MIS QUART, V28, P1
   Dennis AR, 1999, MIS QUART, V23, P95, DOI 10.2307/249411
   DERRYBERRY D, 1992, J CONSULT CLIN PSYCH, V60, P329, DOI 10.1037/0022-006X.60.3.329
   DESANCTIS G, 1994, ORGAN SCI, V5, P121, DOI 10.1287/orsc.5.2.121
   Donath J., 2002, P C DES INT SYST PRO, P359
   EAGLY AH, 1991, PSYCHOL BULL, V110, P109, DOI 10.1037//0033-2909.110.1.109
   EKEHAMMAR B, 2002, 11 EUR C PERS JEN
   EKMAN P, 1991, AM PSYCHOL, V46, P913, DOI 10.1037//0003-066X.46.9.913
   ERICKSON T, 1999, P CHI 99, P15
   Ethics Resource Center, 2005, NAT BUS ETH SURV 200
   Farnham S., 2001, P INT C TOK JAP
   Fiol CM, 2005, ORGAN SCI, V16, P19, DOI 10.1287/orsc.1040.0101
   Flynn FJ, 2005, J PERS SOC PSYCHOL, V88, P816, DOI 10.1037/0022-3514.88.5.816
   FRIEDMAN M, 1970, NY TIMES        0913
   Gibbs J. C, 2003, MORAL DEV REALITY
   Gilbert G M, 1947, NUREMBERG DIARY, P278
   Gilligan C, 1982, DIFFERENT VOICE
   GOLDIN IM, 2001, P 8 INT C ART INT LA, P94
   GROHOWSKI R, 1990, MIS QUART, V14, P369, DOI 10.2307/249785
   Haidt J, 2003, J APPL SOC PSYCHOL, V33, P1, DOI 10.1111/j.1559-1816.2003.tb02071.x
   Haidt J., 2000, PREVENTION TREATMENT, V3
   HAIDT J, 1994, HDB EMOTIONS, P637
   Haney Craig, 1973, INT J CRIMINOLOGY PE, V1, P69
   Harvey J. B., 1988, ABILENE PARADOX OTHE
   Hevner AR, 2004, MIS QUART, V28, P75
   Hinds PJ, 2003, ORGAN SCI, V14, P615, DOI 10.1287/orsc.14.6.615.24872
   Hoffman M. L, 2000, EMPATHY MORAL DEV
   HOGAN R, 1973, PSYCHOL BULL, V79, P217, DOI 10.1037/h0033956
   Hollingshead AB, 1996, HUM COMMUN RES, V23, P193, DOI 10.1111/j.1468-2958.1996.tb00392.x
   Huang W, 1999, INFORM MANAGE, V35, P195, DOI 10.1016/S0378-7206(98)00083-4
   IBRAHIM NA, 1991, J BUS ETHICS, V10, P123, DOI 10.1007/BF00383615
   Jarvenpaa SL, 2004, INFORM SYST RES, V15, P250, DOI 10.1287/isre.1040.0028
   JESSUP LM, 1990, MIS QUART, V14, P313, DOI 10.2307/248893
   John O. P., 1999, HDB PERSONALITY THEO, V2, P102, DOI DOI 10.1525/FQ.1998.51.4.04A00260
   Jones E. E., 1972, ATTRIBUTION PERCEIV, P79
   JONES MD, 1998, THINKERS TOOLKIT
   JONES TM, 1991, ACAD MANAGE REV, V16, P366, DOI 10.2307/258867
   KAPLAN MF, 1987, J PERS SOC PSYCHOL, V53, P306, DOI 10.1037/0022-3514.53.2.306
   KEGAN R, 1994, OVER OUR HEADS MENTA
   Kellaris J., 1994, MARKET LETT, V5, P69, DOI 10.1007/BF00993959
   Keltner D, 2003, COGNITION EMOTION, V17, P297, DOI 10.1080/02699930244000318
   Kidder R. M., 1996, GOOD PEOPLE MAKE TOU
   Kohlberg L., 1976, MORAL DEV BEHAV THEO, P31
   KOHLI F, 2000, J ASSOC INF SYST, V1, P1
   Kramer R. M, 1991, RES ORGAN BEHAV, P191
   Kraut R., 1992, Human-Computer Interaction, V7, P375, DOI 10.1207/s15327051hci0704_2
   KRAUTHAMMER C, 2005, WEEKLY STANDARD 1205
   Kunda Z, 1999, SOCIAL COGNITION
   LACZNIAK GR, 1987, J BUS ETHICS, V6, P297, DOI 10.1007/BF00382939
   Langer E. J, 1989, MINDFULNESS
   Lapsley D. K., 2006, HDB CHILD PSYCHOL, VFour, P248
   Laughlin P. R., 1980, PROGR SOCIAL PSYCHOL, V1, P127
   LeDoux J., 1996, EMOTIONAL BRAIN
   LEVENTHAL H, 1965, J PERS SOC PSYCHOL, V2, P20, DOI 10.1037/h0022089
   LISZK JJ, 2002, MORAL COMPETENCE
   Mancherjee K, 2004, ACM COMPUTER SOC SIG, V34, P1
   MANER W, 1999, AICE00 MELB AUSTR
   MAOZ Z, 1990, WORLD POLIT, V43, P77, DOI 10.2307/2010552
   Mason R., 1981, CHALLENGING STRATEGI
   Mayer J. D., 1990, IMAGINATION COGNITIO, V9, P185, DOI DOI 10.2190/DUGG-P24E-52WK-6CDG
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   Maznevski ML, 2000, ORGAN SCI, V11, P473, DOI 10.1287/orsc.11.5.473.15200
   McCullough ME, 2001, PERS SOC PSYCHOL B, V27, P601, DOI 10.1177/0146167201275008
   MCGRATH JE, 1991, SMALL GR RES, V22, P147, DOI 10.1177/1046496491222001
   MCLAUGHLIN S, 2003, PUBLIC RELATIONS STR, V9
   Milgram S, 1974, OBEDIENCE AUTHORITY
   MITROFF IL, 1997, SMART THINKING CARZY
   Mostert M. P., 2002, J SPEC EDUC, V36, P157
   Mount MK, 1998, HUM PERFORM, V11, P145, DOI 10.1207/s15327043hup1102&3_3
   Murthy US, 2003, INFORM MANAGE-AMSTER, V40, P351, DOI 10.1016/S0378-7206(02)00017-4
   Nardi B.A., 2002, DISTRIBUTED WORK, P83
   NARVAEZ D, 2002, INCORPORATING COGNIT
   Niederman F, 1996, MIS QUART, V20, P1, DOI 10.2307/249540
   NUCCI LP, 2001, ED MORAL DOMAIN
   NUNAMAKER JF, 1991, COMMUN ACM, V34, P4062
   O'Fallon MJ, 2005, J BUS ETHICS, V59, P375, DOI 10.1007/s10551-005-2929-7
   O'Neill O., 1991, COMPANION ETHICS, P175
   OLSON GM, 2002, HUMAN COMPUTER INTER, V15, P139
   OLSON GM, 1995, P COMP HUM INT ASS C, P362
   Pascarella E. T., 1991, COLL AFFECTS STUDENT
   Paul S, 2004, DECIS SUPPORT SYST, V36, P261, DOI 10.1016/S0167-9236(02)00144-6
   Pence G., 1991, COMPANION ETHICS, P249
   Pettit P., 1991, COMPANION ETHICS, P230
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   POULIN JS, 1993, IBM SYST J, V32, P567, DOI 10.1147/sj.324.0567
   Raven B., 1960, GROUP DYNAMICS, P607
   Rest J., 1999, POSTCONVENTIONAL MOR
   ROBBINS RW, 2004, P 2004 SIGMIS C COMP, P134
   Robertson DC, 2001, BUS ETHICS Q, V11, P455, DOI 10.2307/3857849
   Robinson James H., 1921, MIND MAKING
   ROSS L, 1996, VALUES KNOWLEDGE, P305
   ROSSITER J, 2004, EVENING STANDARD, V11
   ROVERS AF, 2004, P EUR MUN GERM
   Schwartz M. S., 2004, J BUS ETHICS, V55, P321
   SEARING DR, 1998, HARPS ETHICAL ANAL M
   Senge P. M., 1990, 5 DISCIPLINE
   Shaw M. E., 1981, GROUP DYNAMICS
   Short J., 1976, SOCIAL PSYCHOL TELEC
   SIBULKIN M, 1996, PHILOS DISCUSSION BA
   SILVER MS, 1991, MIS QUART, V15, P105, DOI 10.2307/249441
   SIMON S, 1978, VALUES CLARIFICATION
   Simons T, 2002, ORGAN SCI, V13, P18, DOI 10.1287/orsc.13.1.18.543
   Skyrme P., 2005, APPL HRM RES, V10, P89
   SNAREY JR, 1985, CHILD DEV, V56, P899, DOI 10.2307/1130102
   SPROULL L, 1986, MANAGE SCI, V32, P1492, DOI 10.1287/mnsc.32.11.1492
   Stys Y., 2004, REV EMOTIONAL INTELL
   Sutton RI, 1996, ADMIN SCI QUART, V41, P685, DOI 10.2307/2393872
   Teasdale JD, 2003, CLIN PSYCHOL-SCI PR, V10, P157, DOI 10.1093/clipsy/bpg017
   Thong J. Y. L., 1998, Journal of Management Information Systems, V15, P213
   TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9
   *US CENS BUR STAT, 2005, US CENS BUR STAT ABS
   Walker SA, 2004, J COMPUT ASSIST LEAR, V20, P172, DOI 10.1111/j.1365-2729.2004.00082.x
   Weisband S., 2002, DISTRIBUTED WORK, P311
   WEISBAND SP, 1995, ACAD MANAGE J, V38, P1124, DOI 10.2307/256623
   Wilson J. Q., 1993, MORAL SENSE
   YORK B, 2004, NATL REV ONLINE 0924
   Zigurs I, 1998, MIS QUART, V22, P313, DOI 10.2307/249668
   Zimbardo P. G., 1969, NEBRASKA S MOTIVATIO, P237
   2006, BUSINESS WEEK   0213
   2004, FORBES          0412
NR 159
TC 11
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0167-4544
J9 J BUS ETHICS
JI J. Bus. Ethics
PD DEC
PY 2007
VL 76
IS 3
BP 269
EP 292
DI 10.1007/s10551-006-9281-4
PG 24
WC Business; Ethics
SC Business & Economics; Social Sciences - Other Topics
GA 223XA
UT WOS:000250407700003
DA 2019-03-21
ER

PT J
AU Sawyer, RJ
AF Sawyer, Robert J.
TI Robot ethics
SO SCIENCE
LA English
DT Editorial Material
EM sawyer@sfwriter.com
NR 0
TC 7
Z9 7
U1 0
U2 2
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 0036-8075
J9 SCIENCE
JI Science
PD NOV 16
PY 2007
VL 318
IS 5853
BP 1037
EP 1037
DI 10.1126/science.1151606
PG 1
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA 231OC
UT WOS:000250957900001
PM 18006710
OA Bronze
DA 2019-03-21
ER

PT J
AU Lepecki, A
AF Lepecki, Andre
TI Machines, faces, neurons - Towards an ethics of dance
SO TDR-THE DRAMA REVIEW-THE JOURNAL OF PERFORMANCE STUDIES
LA English
DT Article
C1 NYU, Dept Performance Studies, New York, NY 10011 USA.
RP Lepecki, A (reprint author), NYU, Dept Performance Studies, New York, NY 10011 USA.
CR BADIOU A, 1999, DELEZE CLAMOR BEING
   Deleuze G, 1994, WHAT IS PHILOS
   Deleuze G., 2006, 2 REGIMES MADNESS TE
   Deleuze Giles, 1987, 1000 PLATEAUS CAPITA
   Deleuze Gilles, 1988, SPINOZA PRACTICAL PH
   Goldman D, 2007, TDR-DRAMA REV-J PERF, V51, P157, DOI 10.1162/dram.2007.51.2.157
NR 6
TC 6
Z9 6
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 1054-2043
EI 1531-4715
J9 TDR-DRAMA REV-J PERF
JI TDR-Drama Rev.-J. Perform. Stud.
PD FAL
PY 2007
VL 51
IS 3
BP 118
EP 123
DI 10.1162/dram.2007.51.3.118
PG 6
WC Theater
SC Theater
GA 206JJ
UT WOS:000249179400009
DA 2019-03-21
ER

PT J
AU Robbins, RW
   Wallace, WA
AF Robbins, Russell W.
   Wallace, William A.
TI Decision support for ethical problem solving: A multi-agent approach
SO DECISION SUPPORT SYSTEMS
LA English
DT Article; Proceedings Paper
CT 15th Mini-EURO Conference on Managing Uncertainty in Decision Support
   Models
CY SEP 22-24, 2004
CL Univ Coimbra, Coimbra, PORTUGAL
SP EURO Assoc European Operat Res Soc
HO Univ Coimbra
DE ethical problem solving; decision support; multi-agent systems
ID PLANNED BEHAVIOR; BUSINESS ETHICS; REASONED ACTION; MODEL; VALUES;
   PERSONALITY; JUDGMENTS; ISSUES
AB This paper suggests that a multi-agent based decision aid can help individuals and groups consider ethical perspectives in the performance of their tasks. Normative and descriptive theories of ethical problem solving are reviewed. Normative theories are postulated as criteria used with practical reasoning during the problem solving process. Four decision aid roles are proposed: advisor, group facilitator, interaction coach, and forecaster. The research describes how the Theory of Planned Behavior from psychology can inform agent processing. The Belief-Desire-Intention model from artificial intelligence is discussed as a method to support user interaction, simulate problem solving, and predict future outcomes. (c) 2006 Elsevier B.V. All rights reserved.
C1 Marist Coll, Comp Sci & Math, Poughkeepsie, NY 12601 USA.
   Rensselaer Polytech Inst, Decis Sci & Engn Syst, Troy, NY 12181 USA.
RP Robbins, RW (reprint author), Marist Coll, Comp Sci & Math, 3399 N Rd, Poughkeepsie, NY 12601 USA.
EM russ.robbins@marist.edu
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   ALBRIGHT L, 1988, J PERS SOC PSYCHOL, V55, P387, DOI 10.1037/0022-3514.55.3.387
   Allison H. E., 1995, OXFORD COMPANION PHI, P435
   *ARISTOTLE, NICHOMACHEON ETHICS
   Bartlett D, 2003, BRIT J MANAGE, V14, P223, DOI 10.1111/1467-8551.00376
   BAUMEISTER RF, 2004, INT ENCY SOCIAL BEHA, P11276
   Bentham J, 1789, INTRO PRINCIPLES MOR
   BOND MH, 1987, SMALL GR RES, V28, P265
   Bonner BL, 2000, SMALL GR RES, V31, P225, DOI 10.1177/104649640003100205
   Bratman M. E, 1987, INTENTIONS PLANS PRA
   Brim O. G., 1962, PERSONALITY DECISION
   Chang MK, 1998, J BUS ETHICS, V17, P1825, DOI 10.1023/A:1005721401993
   CHEE E, 1998, BRIT COLUMBIAS PHARM
   Connor PE, 2003, PUBLIC PERS MANAGE, V32, P155, DOI 10.1177/009102600303200109
   CRISP R, 1995, OXFORD COMPANION PHI, P187
   D'Inverno M, 2004, AUTON AGENT MULTI-AG, V9, P5, DOI 10.1023/B:AGNT.0000019688.11109.19
   Davis MA, 2001, J BUS ETHICS, V32, P35, DOI 10.1023/A:1010701417165
   Feather N. T., 1999, VALUES ACHIEVEMENT J
   FORD RC, 1994, J BUS ETHICS, V13, P205, DOI 10.1007/BF02074820
   FORSYTH DR, 1980, J PERS SOC PSYCHOL, V39, P175, DOI 10.1037/0022-3514.39.1.175
   FRITZSCHE DJ, 1991, J BUS ETHICS, V10, P841, DOI 10.1007/BF00383700
   Funder DC, 2001, ANNU REV PSYCHOL, V52, P197, DOI 10.1146/annurev.psych.52.1.197
   Gaudine A, 2001, J BUS ETHICS, V31, P175, DOI 10.1023/A:1010711413444
   Gert B., 1988, MORALITY NEW JUSTIFI
   GILLIGAN C, 1977, HARVARD EDUC REV, V47, P481, DOI 10.17763/haer.47.4.g6167429416hg5l0
   Glover SH, 1997, J BUS ETHICS, V16, P1319, DOI 10.1023/A:1005758402861
   GOLDIN IM, 2001, INTRO PETE COMPUTER
   Griffin J., 1995, OXFORD COMPANION PHI, P154
   HASTIE R, 1993, CAMBRIDGE SERIES JUD
   Hayes J. R., 1989, COMPLETE PROBLEM SOL
   HEPBURN RW, OXFORD COMPANION PHI, P709
   Honderich Ted, 1995, OXFORD COMPANION PHI
   Hooker J, 1996, 3 KINDS ETHICS
   HOOKER JN, 1989, CAN I BE TRANSPLANTE
   Kant I., 1785, GROUNDING METAPHYSIC
   Kohlberg L., 1969, HDB SOCIALIZATION TH
   Laughlin PR, 1999, ORGAN BEHAV HUM DEC, V80, P50, DOI 10.1006/obhd.1999.2854
   Leonard LNK, 2004, INFORM MANAGE-AMSTER, V42, P143, DOI 10.1016/j.im.2003.12.008
   Lin CP, 2003, J BUS ETHICS, V48, P335, DOI 10.1023/B:BUSI.0000005745.63324.79
   Lipshitz R, 1996, ORGAN BEHAV HUM DEC, V65, P48, DOI 10.1006/obhd.1996.0004
   LITTLE JDC, 2004, ETHICS MODELING, P167
   Loch KD, 1996, COMMUN ACM, V39, P74, DOI 10.1145/233977.233999
   Loe TW, 2000, J BUS ETHICS, V25, P185, DOI 10.1023/A:1006083612239
   LUCAS RE, 2001, INT ENCY SOCIAL BEHA, P5202
   MASON RO, 1986, MIS QUART, V10, P5, DOI 10.2307/248873
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8
   OATLEY K, 2001, EMOTION COGNITION IN, P4440
   Peace AG, 2003, J MANAGE INFORM SYST, V20, P153
   Polya G, 1957, SOLVE IT
   POUNDS WF, 1969, IMR-IND MANAG REV, V11, P1
   PUKA B, 2003, 5 ANN COMP ETH PHIL
   Rand A., 1964, VIRTUE SELFISHNESS
   *RAND HOUS INC, 1987, WEBST UN DICT ENGL L
   RAO AS, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P473
   Rawls J., 1971, THEORY JUSTICE
   Rest J. R., 1986, MORAL DEV ADV RES TH
   ROBBINS RW, 2004, P ASS COMP MACH SIGM
   Rokeach M, 1973, NATURE HUMAN VALUES
   Ross WD, 1930, RIGHT GOOD
   Ross WT, 2003, J BUS ETHICS, V46, P213, DOI 10.1023/A:1025563624696
   SCHNEBERGER S, 1999, BRIT COLUMBIAS PHARM
   Schwartz S. H., 1996, PSYCHOL VALUES ONTAR, V8, P1
   SIMON H. A., 1999, MIT ENCY COGNITIVE S, P674
   Simon H. A, 1999, MIT ENCY COGNITIVE S, P676
   SINGHAPAKDI A, 1993, J BUS ETHICS, V12, P525, DOI 10.1007/BF00872374
   SLOTE M, 1995, OXFORD COMPANION PHI, P900
   Snyder M., 1998, HDB SOCIAL PSYCHOL, V1, P635
   Solomon R. C., 1999, MORALITY GOOD LIFE I
   Sowa John F., 2000, KNOWLEDGE REPRESENTA
   STEINER ID, 1976, CONT TOPICS SOCIAL P, P393
   Sternberg RJ, 1998, ANNU REV PSYCHOL, V49, P479, DOI 10.1146/annurev.psych.49.1.479
   WAGMAN M, 2002, PROBLEM SOLVING PROC
   WAGNER DG, 1993, STUDIES GROWTH THEOR, P24
   WALLACE RJ, 2001, INT ENCY SOCIAL BEHA, P11939
   Wallace WA, 1994, ETHICS IN MODELING
   Walzer Michael, 1983, SPHERES JUSTICE DEFE
   Watson D, 2001, INT ENCY SOCIAL BEHA, P10609, DOI DOI 10.1016/B0-08-043076-7/01771-X
   WELLMAN MP, 1999, MIT ENCY COGINITIVES, P573
   Wittenbaum GM, 2004, SMALL GR RES, V35, P17, DOI 10.1177/1046496403259459
NR 80
TC 16
Z9 16
U1 4
U2 22
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-9236
J9 DECIS SUPPORT SYST
JI Decis. Support Syst.
PD AUG
PY 2007
VL 43
IS 4
BP 1571
EP 1587
DI 10.1016/j.dss.2006.03.003
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Operations Research & Management Science
SC Computer Science; Operations Research & Management Science
GA 210VD
UT WOS:000249482800037
DA 2019-03-21
ER

PT J
AU Davoudi, S
AF Davoudi, Salamander
TI Scientists call for robot ethics debate.
SO AI MAGAZINE
LA English
DT News Item
NR 0
TC 0
Z9 0
U1 0
U2 0
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
J9 AI MAG
JI AI Mag.
PD SUM
PY 2007
VL 28
IS 2
BP 144
EP 144
PG 1
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 183PH
UT WOS:000247584200019
DA 2019-03-21
ER

PT J
AU Kim, YM
AF Kim, Yoon-mi
TI Korea drafts "Robot ethics charter."
SO AI MAGAZINE
LA English
DT News Item
NR 0
TC 0
Z9 0
U1 0
U2 0
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
J9 AI MAG
JI AI Mag.
PD SUM
PY 2007
VL 28
IS 2
BP 144
EP 144
PG 1
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 183PH
UT WOS:000247584200018
DA 2019-03-21
ER

PT J
AU Mcgee, G
AF McGee, Glenn
TI A robot code of ethics
SO SCIENTIST
LA English
DT Editorial Material
C1 Albany Med Coll, Alden March Bioeth Inst, Albany, NY 12208 USA.
RP Mcgee, G (reprint author), Albany Med Coll, Alden March Bioeth Inst, Albany, NY 12208 USA.
EM gmcgee@the-scientist.com
NR 0
TC 0
Z9 0
U1 0
U2 6
PU SCIENTIST INC
PI PHILADELPHIA
PA 3535 MARKET ST, SUITE 200, PHILADELPHIA, PA 19104-3385 USA
SN 0890-3670
J9 SCIENTIST
JI Scientist
PD MAY
PY 2007
VL 21
IS 5
BP 30
EP 30
PG 1
WC Information Science & Library Science; Multidisciplinary Sciences
SC Information Science & Library Science; Science & Technology - Other
   Topics
GA 161EY
UT WOS:000245998500013
DA 2019-03-21
ER

PT J
AU Petersen, S
AF Petersen, Stephen
TI The ethics of robot servitude
SO JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE robot ethics; robot rights; robot labour; robotics; intelligence;
   artificial intelligence; servitude; slavery; population ethics; computer
   ethics
AB Assume we could someday create artificial creatures with intelligence comparable to our own. Could it be ethical use them as unpaid labor? There is very little philosophical literature on this topic, but the consensus so far has been that such robot servitude would merely be a new form of slavery. Against this consensus I defend the permissibility of robot servitude, and in particular the controversial case of designing robots so that they want to serve ( more or less particular) human ends. A typical objection to this case draws an analogy to the genetic engineering of humans: if designing eager robot servants is permissible, it should also be permissible to design eager human servants. Few ethical views can easily explain even the wrongness of such human engineering, however, and those few explanations that are available break the analogy with engineering robots. The case turns out to be illustrative of profound problems in the field of population ethics.
C1 Niagara Univ, Niagara, NY 14109 USA.
RP Petersen, S (reprint author), Niagara Univ, Niagara, NY 14109 USA.
EM steve@stevepetersen.net
CR Adams D., 1980, RESTAURANT END UNIVE
   ASIMOV I, 1970, I ROBOT
   BLOCK R, KOREA TEST 1000 REMO
   Clark A., 2001, MINDWARE
   DENENTT DC, 1994, WHAT IS INTELLIGENCE, P161
   Huxley A., 1998, BRAVE NEW WORLD
   ICWIN T, 1985, NICOMACHEAN ETHICS
   Kant Immanuel, 1989, FDN METAPHYSICS MORA
   Kant Immanuel, 1963, LECT ETHICS
   LaChat MR, 1986, AI MAG, V7, P70
   Luca S, 2001, FOCUS STRUCT BIOLOGY, V1, P33
   Lycan W. G., 1995, CONSCIOUSNESS
   MILL JS, 1993, LIBERTY UTILITARIANI, P131
   Parfit Derek, 1987, REASONS PERSONS
   RYBERG J, STANFORD ENCY PHILOS
   WALKER M, M POPPINS 3000S WORL
   Zunt Dominik, WHO DID ACTUALLY INV
NR 17
TC 12
Z9 12
U1 3
U2 31
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0952-813X
EI 1362-3079
J9 J EXP THEOR ARTIF IN
JI J. Exp. Theor. Artif. Intell.
PD MAR
PY 2007
VL 19
IS 1
BP 43
EP 54
DI 10.1080/09528130601116139
PG 12
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 148EB
UT WOS:000245056200004
DA 2019-03-21
ER

PT J
AU Anderson, M
   Anderson, SL
AF Anderson, Michael
   Anderson, Susan Leigh
TI The status of machine ethics: a report from the AAAI Symposium
SO MINDS AND MACHINES
LA English
DT Editorial Material
DE artificial intelligence; machine ethics
AB This paper is a summary and evaluation of work presented at the AAAI 2005 Fall Symposium on Machine Ethics that brought together participants from the fields of Computer Science and Philosophy to the end of clarifying the nature of this newly emerging field and discussing different approaches one could take towards realizing the ultimate goal of creating an ethical machine.
C1 Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
   Univ Connecticut, Dept Philosophy, Stanford, CA USA.
RP Anderson, M (reprint author), Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
EM anderson@hartford.edu; susan.anderson@uconn.edu
CR Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   ANDERSON M, 2005, AAAI FALL S MENL PAR
   Anderson M, 2006, P 18 C INN APPL ART
   ANDERSON S, 2005, MACHINE ETHICS
   ARKOUDAS K, 2004, MACHINE ETHICS
   ASIMOV I, 1976, BIOCENTENNIAL MAN OT
   GRAU C, 2005, MACHINE ETHICS PAPER
   GUARINI M, 2005, MACHINE ETHICS
   MCLAREN B, 2005, MACHINE ETHICS
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80
   Powers TM, 2005, MACHINE ETHICS
   RZEPKA R, 2005, MAHCINE ETHICS
   WALLACH W, 2005, MACHINE ETHICS
NR 13
TC 8
Z9 8
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-6495
J9 MIND MACH
JI Minds Mach.
PD MAR
PY 2007
VL 17
IS 1
BP 1
EP 10
DI 10.1007/s11023-007-9053-7
PG 10
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 193VV
UT WOS:000248304200001
DA 2019-03-21
ER

PT J
AU Kaiser, M
   Millar, K
   Thorstensen, E
   Tomkins, S
AF Kaiser, Matthias
   Millar, Kate
   Thorstensen, Erik
   Tomkins, Sandy
TI Developing the ethical matrix as a decision support framework: GM fish
   as a case study
SO JOURNAL OF AGRICULTURAL & ENVIRONMENTAL ETHICS
LA English
DT Article
DE biotechnology; decision support; ethical frameworks; Ethical Matrix; GM
   fish
AB The Ethical Matrix was developed to help decision-makers explore the ethical issues raised by agri-food biotechnologies. Over the decade since its inception the Ethical Matrix has been used by a number of organizations and the philosophical basis of the framework has been discussed and analyzed extensively. The role of tools such as the Ethical Matrix in public policy decision-making has received increasing attention. In order to further develop the methodological aspects of the Ethical Matrix method, work was carried out to study the potential role of the Ethical Matrix as a decision support framework. When considering which frameworks to apply when analyzing the ethical dimensions of the application of agri-food biotechnologies, it is important to clarify the substantive nature of any prospective framework. In order to further investigate this issue, reflections on the neologism "ethical soundness'' of an ethical framework are presented here. This concept is introduced in order to provide more structured evaluations of a range of ethical tools, including ethical frameworks such as the Ethical Matrix. As well as examining the philosophical dimensions of the method, theoretical analysis and literature studies were combined with stakeholder engagement exercises and consultations in order to review the Ethical Matrix from a user perspective. This work resulted in the development of an Ethical Matrix Manual, which is intended to act as a guide for potential user groups.
C1 Natl Comm Res Eth Sci & Technol, N-0105 Oslo, Norway.
RP Kaiser, M (reprint author), Natl Comm Res Eth Sci & Technol, POB 522 Sentrum,Prinsensgate 18, N-0105 Oslo, Norway.
EM matthias.kaiser@etikkom.no; kate.millar@nottingham.ac.uk;
   sandy.tomkins@nottingham.ac.uk
OI Thorstensen, Erik/0000-0003-4497-6577; Millar, Kate/0000-0002-7155-7776
CR Beauchamp T., 2002, PRINCIPLES BIOMEDICA
   Chadwick R, 2003, FUNCTIONAL FOODS
   *FAO WHO, 2003, FAO WHO EXP CONS SAF, P17
   FOLLESDAL D, 1986, RATIONALE ARGUMENTAT
   FORSBERG EM, 2007, J AGR ENVIRON ETHIC, V20, DOI DOI 10.1007/S10806-006-9017-16
   Kaiser M, 2001, J AGR ENVIRON ETHIC, V14, P191, DOI 10.1023/A:1011300811590
   Kaiser M, 2004, ACTA VET SCAND, V45, P65
   Mepham B., 1996, Food ethics., P101
   Mepham B, 2000, J AGR ENVIRON ETHIC, V12, P165, DOI 10.1023/A:1009542714497
   MEPHAM B, 2005, BIOETHICS INTRO BIOS
   Mepham B., 2001, CONCISE ENCY ETHICS, P300
   Mepham B., 2006, ETHICAL MATRIX USER
   MEPHAM B, 2003, ETHICS ANIMAL FARMIN
   MILLAR K, 2002, SCI PUBLIC AFF, V3, P20
   MOORE CJ, 1996, THESIS U NOTTINGHAM
   Palmer C., 2003, POIESIS PRAXIS, V1, P295
NR 16
TC 28
Z9 31
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1187-7863
EI 1573-322X
J9 J AGR ENVIRON ETHIC
JI J. Agric. Environ. Ethics
PD FEB
PY 2007
VL 20
IS 1
BP 65
EP 80
DI 10.1007/s10806-006-9023-8
PG 16
WC Agriculture, Multidisciplinary; Ethics; Environmental Sciences; History
   & Philosophy Of Science
SC Agriculture; Social Sciences - Other Topics; Environmental Sciences &
   Ecology; History & Philosophy of Science
GA 137RG
UT WOS:000244309100006
DA 2019-03-21
ER

PT J
AU Anderson, M
   Anderson, SL
AF Anderson, Michael
   Anderson, Susan Leigh
TI Machine ethics
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Editorial Material
C1 Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
   Univ Connecticut, Dept Philosophy, Stamford, CT 06901 USA.
RP Anderson, M (reprint author), Univ Hartford, Dept Comp Sci, 200 Bloomfield Ave, Hartford, CT 06117 USA.
EM anderson@hartford.edu; susan.anderson@uconn.edu
NR 0
TC 7
Z9 7
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD JUL-AUG
PY 2006
VL 21
IS 4
BP 10
EP 11
DI 10.1109/MIS.2006.70
PG 2
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA 068PE
UT WOS:000239386100005
DA 2019-03-21
ER

PT J
AU Allen, C
   Wallach, W
   Smit, I
AF Allen, Colin
   Wallach, Wendell
   Smit, Iva
TI Why machine ethics?
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Article
C1 Indiana Univ, Dept Hist & Philosophy Sci, Bloomington, IN 47405 USA.
   Yale Univ, Yale Inst Social & Policy Studies, Interdisciplinary Ctr Bioeth, New Haven, CT 06520 USA.
   E&E Consultants, NL-6561 AM Groesbeek, Netherlands.
RP Allen, C (reprint author), Indiana Univ, Dept Hist & Philosophy Sci, 1011 E 3rd St,Goodbody Hall 130, Bloomington, IN 47405 USA.
EM colallen@indiana.edu; wwallach@comcast.net; iva.smit@chello.nl
CR Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428
   ALLEN C, 2006, IN PRESS ETHICS INFO, V7, P149
   Anderson M., 2005, AAAI FALL S
   Damasio A, 1994, DESCARTES ERROR
   Danielson P., 1992, ARTIFICIAL MORALITY
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d
   Foot P., 1967, OXFORD REV, V5, P5
   Gips J., 1995, ANDROID EPISTEMOLOGY, P243
   KNUTTON M, 2002, INT RAILWAY J   0601
   Kurzweil R., 2005, SINGULARITY IS NEAR
   Moravec H., 2000, ROBOT MERE MACHINE T
   Nissenbaum H, 2001, COMPUTER, V34, P120, DOI 10.1109/2.910905
   Nissenbaum H, 2001, COMPUTER, V34, P118
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00005756
NR 14
TC 46
Z9 46
U1 5
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD JUL-AUG
PY 2006
VL 21
IS 4
BP 12
EP 17
DI 10.1109/MIS.2006.83
PG 6
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA 068PE
UT WOS:000239386100006
DA 2019-03-21
ER

PT J
AU Moor, JH
AF Moor, James H.
TI The nature, importance, and difficulty of machine ethics
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Article
C1 Dartmouth Coll, Dept Philosophy, Hanover, NH 03755 USA.
RP Moor, JH (reprint author), Dartmouth Coll, Dept Philosophy, Hanover, NH 03755 USA.
EM james.moor@dartmouth.edu
CR Anderson M., 2005, MACHINE ETHICS, P17
   GIPS J, AAAI FALL 2005 S MAC
   LEWIS J, 2005, WIRED, V13, P188
   Lokhorst G. J. C., 2002, CYBERPHILOSOPHY INTE, P280
   Moor J, 1979, NATURE SYSTEM, V1, P217
   MOOR JH, 1995, METAPHILOSOPHY, V26, P1, DOI 10.1111/j.1467-9973.1995.tb00553.x
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00005756
   SIMON H, 1999, DARTM SEM 1956
   WALLACH W, 2005, MACHINE ETHICS, P94
   WIEGEL V, 2005, ETHICS NEW INFORMATI, P419
NR 10
TC 80
Z9 80
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD JUL-AUG
PY 2006
VL 21
IS 4
BP 18
EP 21
DI 10.1109/MIS.2006.80
PG 4
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA 068PE
UT WOS:000239386100007
DA 2019-03-21
ER

PT J
AU McLaren, BM
AF McLaren, Bruce M.
TI Computational models of ethical reasoning: Challenges, initial steps,
   and future directions
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Article
C1 Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15213 USA.
   Pittsburgh Sci Learning Ctr, Pittsburgh, PA USA.
RP McLaren, BM (reprint author), Carnegie Mellon Univ, Human Comp Interact Inst, 2617 Newell Simon Hall,5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM bmclaren@cs.cmu.edu
CR Anderson J., 1993, RULES MIND
   ANDERSON M, 2005, P AAAI 2005 FALL S M, P1
   ANDERSON M, 2005, P AAAI 2005 FALL S C, P9
   ANDERSON SL, 2005, P AAAI 2005 FALL S M, P1
   Ashley K, 1990, MODELING LEGAL ARGUM
   ASHLEY KD, 1995, P 1 INT C CAS BAS RE, P133
   Ashley Kevin D., 1995, P 17 ANN C COGN SCI, P72
   Beauchamp TJ, 1979, PRINCIPLES BIOMEDICA
   Bentham Jeremy, 1948, INTRO PRINCIPLES MOR
   Bok S, 1989, LYING MORAL CHOICE P
   Brody BA, 2003, TAKING ISSUE PLURALI
   CAVALIER R, 1996, RIGHT DIE DAX COWART
   GOLDNER V, 2000, STUDIES GENDER SEXUA, V1, P1
   Harris Jr CE, 1995, ENG ETHICS CONCEPTS
   Jonsen Albert R., 1988, ABUSE CASUISTRY HIST
   Kant Immanuel, 1996, PRACTICAL PHILOS
   LEWIS D, 1996, P 19 ANN INT ACM SIG, P29
   McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8
   MCLAREN BM, 2006, 8 INT C INT TUT SYST
   MCLAREN BM, 2005, P C COMP SUPP COLL L
   MILLS JS, 1979, UTILITARIANISM
   *NSPE, 1996, NSPE ETH REF GUID
   Rawls J., 1999, THEORY JUSTICE
   ROBBINS RW, 2004, P 2004 ACM SIGMIS C, P22
   ROBBINS RW, 2006, DECISION SUPPORT SYS
   Ross WD, 1930, RIGHT GOOD
   ROSS WD, 1924, NICOMACHEAN ETHICS
   SEARING DR, 1998, HARPS ETHICAL ANAL M
   STRONG C, 1988, MORAL THEORY MORAL J, P193
   Toulmin S, 1958, USES ARGUMENT
   van Rijsbergen C. J., 1979, INFORMATION RETRIEVA
   von der Lieth Gardner A., 1987, ARTIFICIAL INTELLIGE
NR 32
TC 23
Z9 23
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD JUL-AUG
PY 2006
VL 21
IS 4
BP 29
EP 37
DI 10.1109/MIS.2006.67
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA 068PE
UT WOS:000239386100009
DA 2019-03-21
ER

PT J
AU Chae, B
   Paradice, D
   Courtney, JF
   Cagle, CJ
AF Chae, B
   Paradice, D
   Courtney, JF
   Cagle, CJ
TI Incorporating an ethical perspective into problem formulation:
   implications for decision support systems design
SO DECISION SUPPORT SYSTEMS
LA English
DT Article
DE ethics; problem formulation; DSS; information systems design
ID LONDON AMBULANCE SERVICE; MODEL; ORGANIZATIONS; TECHNOLOGY; KNOWLEDGE;
   BUSINESS; ISSUE; DSS
AB As organizations become ever larger and increasingly complex, they become more reliant on information systems and decision support systems (DSS), and their decisions and operations affect a growing number of stakeholders. This paper argues that DSS design and problem formulation in such a context raises ethical issues, as DSS development and use puts one party, the designers, in the position of imposing order on the behavior of others. Thus, decision support systems are more than technical artifacts and their implications for affected parties should be considered in their design and development. The paper integrates Jones' model [Acad. Manage. Rev. 16 (1991) 366] of moral intensity with Mitroff's five strategies for avoiding Type III errors [I.I. Mitroff, Smart Thinking for Crazy Times: The Art of Solving the Right Problems, Barrett-Koehler Publishers, San Francisco, 1997], solving the wrong problem [H. Raiffa, Decision Analysis, Addison-Wesley, Reading, 1968], and proposes a model for incorporating ethical issues into DSS design and problem formulation. A survey of managers is used to assess the current situation regarding use of elements of the integrated model. The results are somewhat encouraging in that 40% of the respondents felt that their organizations did follow the model reasonably well, yet 23% felt their organizations did not. (c) 2004 Elsevier B.V. All rights reserved.
C1 Florida State Univ, Coll Business, Dept Management Informat Syst, Tallahassee, FL 32306 USA.
   Kansas State Univ, Coll Business Adm, Dept Management, Manhattan, KS 66506 USA.
   Univ Cent Florida, Coll Business Adm, Dept Management Informat Syst, Orlando, FL 32816 USA.
   Cagle & Co LLC, Houston, TX USA.
RP Paradice, D (reprint author), Florida State Univ, Coll Business, Dept Management Informat Syst, Tallahassee, FL 32306 USA.
EM bchae@ksu.edu; paradice@cob.fsu.edu; Jim.Courtney@bus.ucf.edu;
   cjcagle@earthlink.net
CR ABUALSAMH RA, 1990, ORGAN BEHAV HUM DEC, V45, P159, DOI 10.1016/0749-5978(90)90009-X
   Ackoff R. L, 1999, RECREATING CORPORATI
   BASADUR M, 1994, OMEGA-INT J MANAGE S, V22, P627, DOI 10.1016/0305-0483(94)90053-1
   Beynon-Davies P, 1999, INTERACT COMPUT, V11, P699, DOI 10.1016/S0953-5438(98)00050-2
   BOLAND R, 1987, WILEY SERIES INFORM, P132
   BOLAND RJ, 1995, ORGAN SCI, V6, P350, DOI 10.1287/orsc.6.4.350
   Carlson J. R., 1999, J MANAGEMENT ISSUES, V11, P180
   Carrier H. D., 1994, ETHICS MODELING ELSE, P37
   Churchman C. V., 1967, MANAGE SCI, V14, P141, DOI DOI 10.2307/2628678
   Churchman C. West, 1971, DESIGN INQUIRING SYS
   Churchman C. West, 1982, THOUGHT WISDOM
   Courtney J., 1998, AUSTR J INFORM SYSTE, V6
   Courtney J.F., 2002, INTERNET MANAGEMENT, P165
   COURTNEY JF, 1993, DECIS SUPPORT SYST, V9, P413, DOI 10.1016/0167-9236(93)90050-D
   Courtney JF, 2001, DECIS SUPPORT SYST, V31, P17, DOI 10.1016/S0167-9236(00)00117-2
   COURTNEY JF, IN PRESS HDB SUSTAIN
   COWAN DA, 1986, ACAD MANAGE REV, V11, P763, DOI 10.2307/258395
   DEWEY J, 1910, HOW WE THINK
   Douglas M., 1987, HOW I THINK
   Feynman RP, 1999, PLEASURE FINDING THI, P151
   Galliers RD, 1998, J STRATEGIC INF SYST, V7, P271, DOI 10.1016/S0963-8687(99)00002-5
   Giddens A, 1984, CONSTITUTION SOC OUT
   HANDY C, 1994, AGE PARADOX
   Introna L. D., 2002, Information and Organization, V12, P71, DOI 10.1016/S1471-7727(01)00008-2
   JONES TM, 1991, ACAD MANAGE REV, V16, P366, DOI 10.2307/258867
   LAVE J, 1991, SITUATED LEARNING
   LYLES MA, 1980, ADMIN SCI QUART, V25, P102, DOI 10.2307/2392229
   LYLES MA, 1981, STRATEGIC MANAGE J, V2, P61, DOI 10.1002/smj.4250020106
   MACDONALD JE, 1994, J BUS ETHICS, V13, P615, DOI 10.1007/BF00871809
   Mason R. O., 1988, SYSTEMS PRACTICE, V1, P367
   MASON RO, 1995, COMMUN ACM, V38, P55, DOI 10.1145/219663.219681
   MASON RO, 1995, ETHICS INFORM AGE
   McGrath K, 2002, EUR J INFORM SYST, V11, P251, DOI 10.1057/palgrave.ejis.3000436
   MITROFF I, 1997, SMART THINKING CRAZY
   Mitroff I. I., 1993, UNBOUNDED MIND BREAK
   Mitroff II, 1999, SLOAN MANAGE REV, V40, P83
   NUTT PC, 1993, ORGAN SCI, V4, P226, DOI 10.1287/orsc.4.2.226
   O'Harrow Jr Robert, 2002, WASH POST       0201, pA1
   PARADICE DB, 1991, J BUS ETHICS, V10, P1, DOI 10.1007/BF00383688
   PARADICE DB, 1990, INFORM MANAGE, V18, P143, DOI 10.1016/0378-7206(90)90068-S
   PARADICE DB, 2002, 3 ANN GLOB INF TECHN
   PARKER DB, 1979, ETHICAL CONFLICTS CO
   POUNDS WF, 1969, IMR-IND MANAG REV, V11, P1
   PRACHT WE, 1988, DECISION SCI, V19, P598, DOI 10.1111/j.1540-5915.1988.tb00289.x
   PRIMEAUX P, 1994, J BUS ETHICS, V13, P287, DOI 10.1007/BF00871675
   Raiffa H, 1968, DECISION ANAL
   Rest J. R., 1986, MORAL DEV ADV RES TH
   RICHARDSON SM, 2001, INFORM SYSTEMS FRONT, V4, P43
   RITTEL HWJ, 1973, POLICY SCI, V4, P155, DOI 10.1007/BF01405730
   Robin DP, 1996, J BUS RES, V35, P17, DOI 10.1016/0148-2963(94)00080-8
   Schaef A. W., 1988, ADDICTIVE ORG
   SCHMINKE MJ, 2002, EFFECTS LEADER MORAL
   SENGE P, 1995, EXECUTRIVE EXCELLENC, V12, P18
   Singhapakdi A, 1996, J BUS RES, V36, P245, DOI 10.1016/0148-2963(95)00155-7
   Stead JG, 2000, J BUS ETHICS, V24, P313, DOI 10.1023/A:1006188725928
   ULRICH W, 1988, SYST PRACTICE, V1, P341
   Ulrich W., 1988, SYSTEMS PRACTICE, V1, P415
   Verschoor CC, 1998, J BUS ETHICS, V17, P1509, DOI 10.1023/A:1006020402881
   Vickers G, 1995, ART JUDGMENT STUDY P
   VOLKEMA RJ, 1995, INTERFACES, V25, P81, DOI 10.1287/inte.25.3.81
   VOLKEMA RJ, 1997, HUM SYST MANAGE, V16, P27
   WALSHAM G, 1993, ETHICAL ISSUES INFOR
   WASTELL D, 1996, ACCOUNTING MANAGEMEN, V6, P283, DOI DOI 10.1016/S0959-8022(96)90017-X
   Weaver G. R., 1999, BUSINESS ETHICS Q, V9, P315, DOI [DOI 10.1177/0149206307308913, DOI 10.2307/3857477]
   Weick K. E., 1993, GROUP SUPPORT SYSTEM, P230
   Whetstone JT, 2001, J BUS ETHICS, V33, P101, DOI 10.1023/A:1017554318867
   2003, WALL STREET J, pD2
NR 67
TC 20
Z9 21
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-9236
J9 DECIS SUPPORT SYST
JI Decis. Support Syst.
PD AUG
PY 2005
VL 40
IS 2
BP 197
EP 212
DI 10.1016/j.dss.2004.02.002
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Operations Research & Management Science
SC Computer Science; Operations Research & Management Science
GA 973LM
UT WOS:000232524100004
DA 2019-03-21
ER

PT J
AU Frize, M
   Yang, L
   Walker, RC
   O'Connor, AM
AF Frize, M
   Yang, L
   Walker, RC
   O'Connor, AM
TI Conceptual framework of knowledge management for ethical decision-making
   support in neonatal intensive care
SO IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE
LA English
DT Article
DE decision-support system; knowledge-based system; knowledge transfer and
   exchange; neonatal medicine; parent-physician decision-aid system
AB This research is built on the belief that artificial intelligence estimations need to be integrated into clinical social context to create value for health-care decisions. In sophisticated neonatal intensive care units (NICUs), decisions to continue or discontinue aggressive treatment are an integral part of clinical practice. High-quality evidence supports clinical decision-making, and a decision-aid tool based on specific outcome information for individual NICU patients will provide significant support for parents and caregivers in making difficult "ethical" treatment decisions. In our approach, information on a newborn patient's likely outcomes is integrated with the physician's interpretation and parents' perspectives into codified knowledge. Context-sensitive content adaptation delivers personalized and customized information to a variety of users, from physicians to parents. The system provides structuralized knowledge translation and exchange between all participants in the decision, facilitating collaborative decision-making that involves parents at every stage on whether to initiate, continue, limit, or terminate intensive care for their infant.
C1 Carleton Univ, Syst & Comp Engn, Ottawa, ON K1S 5B6, Canada.
RP Frize, M (reprint author), Carleton Univ, Syst & Comp Engn, Ottawa, ON K1S 5B6, Canada.
EM mfrize@connect.carleton.ca
CR Alberdi E, 2000, J CLIN MONITOR COMP, V16, P85, DOI 10.1023/A:1009954623304
   Ambalavanan N, 2001, EARLY HUM DEV, V65, P123, DOI 10.1016/S0378-3782(01)00228-6
   CARTER BS, 2003, E MED
   Chen JQ, 2003, DECIS SUPPORT SYST, V36, P147, DOI 10.1016/S0167-9236(02)00139-2
   DEBORAH EC, 2001, A M J PERINATOL, P117
   DWIVEDI AN, 2003, 25 ANN INT C IEEE EN
   ENNETT CM, 2001, MEDINFO 1, V10, P449
   EWING G, 2003, IN PRESS J BIOMED IN
   Frize M, 2001, MED ENG PHYS, V23, P217, DOI 10.1016/S1350-4533(01)00041-8
   FRIZE M, 2001, MEDINFO 2001 LONDON, P2
   Larcher V, 2002, CURRENT PAEDIAT, V12, P470
   LUM WY, 2002, PERVASICE COMPUT, V2, P41
   Machiavelli Nicolo, PRINCE
   O'Connell JE, 2002, AGE AGEING, V31, P5, DOI 10.1093/ageing/31.suppl_3.5
   Safran C, 2003, INT J MED INFORM, V69, P185, DOI 10.1016/S1386-5056(02)00130-2
   TYSON J, 2003, FUTURE CHILDREN PUB
   WALKER RC, 2001, MEDINFO 2001
   WYATT JS, 1999, BAIL CLIN OBST BYN, V4, P503
   Zernikow B, 1998, ARCH DIS CHILD, V79, pF129, DOI 10.1136/fn.79.2.F129
NR 19
TC 16
Z9 16
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855 USA
SN 1089-7771
J9 IEEE T INF TECHNOL B
JI IEEE T. Inf. Technol. Biomed.
PD JUN
PY 2005
VL 9
IS 2
BP 205
EP 215
DI 10.1109/TITB.2005.847187
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 933QY
UT WOS:000229649200007
PM 16138537
DA 2019-03-21
ER

PT J
AU van Vuuren, LJ
   Crous, F
AF van Vuuren, LJ
   Crous, F
TI Utilising appreciative inquiry (AI) in creating a shared meaning of
   ethics in organisations
SO JOURNAL OF BUSINESS ETHICS
LA English
DT Article
DE appreciative inquiry (AI); compliance; culture; ethics; ethics
   management; ethical risk; governance; intervention; vision
ID MANAGING ETHICS
AB The management of ethics within organisations typically occurs within a problem-solving frame of reference. This often results in a reactive, problem-based and externally induced approach to managing ethics. Although basing ethics management interventions on dealing with and preventing current and possible future unethical behaviour are often effective in that it ensures compliance with rules and regulations, the approach is not necessarily conducive to the creation of sustained ethical cultures. Nor does the approach afford (mainly internal) stakeholders the opportunity to be co-designers of the organisations ethical future. The aim of this paper is to present Appreciative Inquiry (AI) as an alternative approach for developing a shared meaning of ethics within an organisation with a view to embrace and entrench ethics, thereby creating a foundation for the development of an ethical cul- ture over time. A descriptive case study based on an application of AI is used to illustrate the utility of AI as a way of thinking and doing to precede and complement problem-based ethics management systems and interventions.
C1 Univ Johannesburg, Dept Human Resource Management, ZA-2006 Johannesburg, South Africa.
RP van Vuuren, LJ (reprint author), Univ Johannesburg, Dept Human Resource Management, POB 524,Auckland Pk, ZA-2006 Johannesburg, South Africa.
EM leonvv@vujhb.ac.za; freddiec@ujhb.ac.za
CR Cooperrider D., 2000, APPRECIATIVE INQUIRY
   Cooperrider D. L., 2003, APPRECIATIVE INQUIRY
   Cooperrider D. L, 1999, APPRECIATIVE INQUIRY
   Cragg W, 1997, J BUS ETHICS, V16, P231, DOI 10.1023/A:1017974908203
   Driscoll D. N., 2000, ETHICS MATTERS IMPLE
   Freeman E., 1984, STRATEGIC MANAGEMENT
   *FTSE JSE, 2004, FTSE JOH STOCK EXCH
   Garratt B., 2003, THIN TOP WHY CORPORA
   Gergen K. J., 1999, ORG DIMENSIONS GLOBA
   Handelsman M. M., 2002, HDB POSITIVE PSYCHOL
   IoD, 2002, 2 KING REP CORP GOV
   Ludema J. D., 2001, HDB ACTION RES PARTI
   Ludema J. D, 2003, APPRECIATIVE INQUIRY
   MALACHOWSKI A, 1990, LEADERSHIP ORG DEV J, V11, P22
   PORRAS JI, 1991, ANNU REV PSYCHOL, V42, P51
   Post J. E., 1996, BUSINESS SOC CORPORA
   Pruzan P, 2001, J BUS ETHICS, V29, P271, DOI 10.1023/A:1026577604845
   Rossouw G. J., 2004, BUSINESS ETHICS
   Rossouw GJ, 2003, J BUS ETHICS, V46, P389, DOI 10.1023/A:1025645402328
   Schweitzer A., 1969, TEACHING REVERENCE L
   SHARPPAINE L, 2002, PERSPECTIVES BUSINES
   Trevino LK, 1999, CALIF MANAGE REV, V41, P131, DOI 10.2307/41165990
   WATERS JA, 1987, J BUS ETHICS, V6, P15, DOI 10.1007/BF00382944
   WATKINS J. M., 2001, APPRECIATIVE INQUIRY
   Weick K. E., 2001, MAKING SENSE ORG
   Whitney D., 2003, POWER APPRECIATIVE I
   Yin R. K., 2003, APPL CASE STUDY RES
NR 27
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0167-4544
EI 1573-0697
J9 J BUS ETHICS
JI J. Bus. Ethics
PD APR
PY 2005
VL 57
IS 4
BP 399
EP 412
DI 10.1007/s10551-004-7307-3
PG 14
WC Business; Ethics
SC Business & Economics; Social Sciences - Other Topics
GA 917XH
UT WOS:000228502100007
DA 2019-03-21
ER

PT J
AU Walker, RC
   Frize, M
   Yang, L
AF Walker, RC
   Frize, M
   Yang, L
TI An evidence-based ethical decision-support tool for physicians and
   parents in the neonatal intensive care unit (NICU)
SO PEDIATRIC RESEARCH
LA English
DT Meeting Abstract
CT Annual Meeting of the Pediatric-Academic-Societies
CY MAY   04, 2004
CL San Francisco, CA
SP Pediatr Acad Soc
C1 Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada.
   Carleton Univ, Ottawa, ON K1S 5B6, Canada.
NR 0
TC 0
Z9 0
U1 0
U2 1
PU INT PEDIATRIC RESEARCH FOUNDATION, INC
PI BALTIMORE
PA 351 WEST CAMDEN ST, BALTIMORE, MD 21201-2436 USA
SN 0031-3998
J9 PEDIATR RES
JI Pediatr. Res.
PD APR
PY 2004
VL 55
IS 4
SU S
MA 315
BP 56A
EP 56A
PN 2
PG 1
WC Pediatrics
SC Pediatrics
GA 808TJ
UT WOS:000220591100332
DA 2019-03-21
ER

PT J
AU Brans, JP
   Coppin, G
   Lenca, P
   Jelassi, T
   Roubens, M
   Zarate, P
AF Brans, JP
   Coppin, G
   Lenca, P
   Jelassi, T
   Roubens, M
   Zarate, P
TI 12th Mini Euro Conference: Decision support systems; Electronic and
   mobile commerce; Multicriteria decision aid; Human centered processes;
   Ethical dilemmas in decision making
SO EUROPEAN JOURNAL OF OPERATIONAL RESEARCH
LA English
DT Editorial Material
C1 Free Univ Brussels, Ctr V Stat Oper Onderz, B-1050 Brussels, Belgium.
   ENST Bretagne, Brest, France.
   ENPC, Paris, France.
   Ulg, Liege, Belgium.
   IRIT, Toulouse, France.
RP Brans, JP (reprint author), Free Univ Brussels, Ctr V Stat Oper Onderz, Pl Laan 2, B-1050 Brussels, Belgium.
EM jpbrans@vub.ac.be; gilles.coppin@enst.bretagne.fr;
   philippe.lenca@enst.bretagne.fr; jelassit@mall.enpc.fr;
   m.roubens@ulg.ac.be; zarate@irit.fr
NR 0
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0377-2217
EI 1872-6860
J9 EUR J OPER RES
JI Eur. J. Oper. Res.
PD MAR 1
PY 2004
VL 153
IS 2
BP 267
EP 270
DI 10.1016/s0377-2217(03)00149-8
PG 4
WC Management; Operations Research & Management Science
SC Business & Economics; Operations Research & Management Science
GA 748HM
UT WOS:000186856500001
DA 2019-03-21
ER

PT J
AU Mellor, DJ
   Littin, KE
AF Mellor, DJ
   Littin, KE
TI Using science to support ethical decisions promoting humane livestock
   slaughter and vertebrate pest control
SO ANIMAL WELFARE
LA English
DT Article; Proceedings Paper
CT UFAW International Symposium on Science in the Service of Animal Welfare
CY APR 02-04, 2003
CL Edinburgh, SCOTLAND
SP Univ Federat Anim Welfare
DE animal welfare; ethics; humane pest control; humane slaughter;
   minimising harm; scientific assessment of harm
ID ANIMAL-WELFARE; CALVES; INSENSIBILITY; BEHAVIOR; POSSUMS; SEIZURE; ONSET
AB Ethical principles guide decisions about what we consider to be right or wrong proposals and actions, so that when value judgements are made these engage us in ethics. Ethical thinking is clearly relevant to decisions about the way we treat animals, and such thinking has led to the commonly held view that animal use by people is acceptable provided that such use is humane. The ethical requirement that we treat animals humanely means that we must minimise the harms we do to all animals in our care or under our control. Accordingly, we must assess what harms are done to the animals, how bad each harm is in terms of its intensity and duration, what methods are available or can be developed to minimise each harm, and the relative effectiveness of those methods of harm minimisation. We must also seek to use the most humane methods currently available that can be practically applied Ethically driven scientific evaluations of this sort have improved the humaneness of livestock slaughter and vertebrate pest control. For instance, detailed studies of different pre-slaughter stunning methods have validated their use to pre-empt the pain and distress that otherwise conscious animals would experience during the fatal neck cut and the short period of consciousness (sensibility) that follows it. Likewise, reducing injuries caused by restraint traps has improved the humaneness of this vertebrate pest control method, and comparing the effects of different poisons has allowed the least humane ones to be identified. Difficult questions nevertheless remain at the problematic interface between quantitative scientific observations and their interpretation regarding the suffering that animals may experience, as well as questions about the relativities of different types of suffering.
C1 Massey Univ, Anim Welf Sci & Bioeth Ctr, Palmerston North, New Zealand.
RP Mellor, DJ (reprint author), Massey Univ, Anim Welf Sci & Bioeth Ctr, Palmerston North, New Zealand.
EM D.J.Mellor@massey.ac.nz
CR BAGER F, 1990, MEAT SCI, V27, P211, DOI 10.1016/0309-1740(90)90052-8
   BAGER F, 1992, RES VET SCI, V52, P162, DOI 10.1016/0034-5288(92)90005-M
   BANNER M, 1995, COMMITTEE CONSIDER E
   BATTYE J, 1998, ETHICAL APPROACHES A, P11
   BLACKMORE DK, 1993, NEW ZEAL VET J, V41, P126, DOI 10.1080/00480169.1993.35750
   COOK CJ, 1995, MEAT SCI, V40, P137, DOI 10.1016/0309-1740(94)00043-7
   Cook CJ, 1998, NEW ZEAL VET J, V46, P76, DOI 10.1080/00480169.1998.36061
   COOK CJ, 2002, P 12 WORLD BUIAT C 1
   Eason C., 1998, Ethical approaches to animal-based science. Proceedings of the Joint ANZCCART/NAEAC Conference held in Auckland, New Zealand, 19-20 September 1997., P125
   Fisher M, 1998, ETHICAL APPROACHES A, P33
   Fraser D, 1997, ANIM WELFARE, V6, P187
   FRASER D, 2003, P 2 INT WORKSH ASS A, V12, P433
   Gregory N. G., 1987, Humane slaughter of animals for food. Proceedings of a symposium at the Zoological Society of London, 18th September 1986., P3
   Gregory NG, 1998, NEW ZEAL VET J, V46, P60, DOI 10.1080/00480169.1998.36057
   GREGORY NG, 1998, ANIMAL WELF MEAT SCI
   GREGORY NG, 1989, VET HIST, V6, P73
   GREGORY NG, 1998, ETHICAL APPROACHES A, P121
   HEISS H, 1904, HUMANE SLAUGHTERING
   KIN GCM, 1990, HDB NZ MAMMALS
   KING CM, 1977, NEW ZEAL J ZOOL, V4, P193, DOI 10.1080/03014223.1977.9517953
   Lambooy E., 1987, Humane slaughter of animals for food. Proceedings of a symposium at the Zoological Society of London, 18th September 1986., P21
   Levinger I. M., 1995, SHECHITA LIGHT YEAR
   LITTIN K, 1999, USE WILDLIFE RES, P108
   Littin KE, 2002, WILDLIFE RES, V29, P259, DOI 10.1071/WR01068
   LITTIN KE, 2002, LC012006 LANDC RES L
   LITTIN KE, IN PRESS NZ VET J
   *MAFF, 1997, EV FULL APPR PROV AP
   MARKS CA, 1996, HUMANENESS VERTEBRAT, P50
   MARKS CA, 1999, USE WILDLIFE RES, P78
   Mason G, 2003, ANIM WELFARE, V12, P1
   Mellor D. J., 2003, Surveillance (Wellington), V30, P26
   Mellor DJ, 2003, NEW ZEAL VET J, V51, P2, DOI 10.1080/00480169.2003.36323
   MELLOR DJ, 1998, ETHICAL APPROACHES A, P19
   MELLOR DJ, 1999, HE KORERO PAIHAMA PO, V12, P3
   MELLOR DJ, 2000, DEV ANIMAL VET SCI, P65
   *NAWAC, 2001, DISC PAP AN WELF STA
   NEWHOOK JC, 1982, MEAT SCI, V6, P295, DOI 10.1016/0309-1740(82)90040-7
   OCONNER CE, 2003, LC0203158 LANDC RES
   OOGJES G, 1996, HUMANENESS VERTEBRAT, P9
   Rowsell HD, 1979, P CAN ASS LAB AN SCI, P159
   Sandoe P, 2003, ANIM WELFARE, V12, P469
   Sandoe P, 1999, ANIM WELFARE, V8, P313
   *UFAW, 1987, HUM SLAUGHT AN FOOD
   Warburton B., 1998, Ethical approaches to animal-based science. Proceedings of the Joint ANZCCART/NAEAC Conference held in Auckland, New Zealand, 19-20 September 1997., P131
   WARBURTON B, 2002, P 4 WORLD C ALT AN U
   Warburton B, 1999, USE WILDLIFE RES, P90
   WARRING R, 1974, VET B, V46, P617
NR 47
TC 11
Z9 12
U1 3
U2 18
PU UNIV FEDERATION ANIMAL WELFARE
PI WHEATHAMPSTEAD
PA OLD SCHOOL, BREWHOUSE HILL, WHEATHAMPSTEAD AL4 8AN, HERTS, ENGLAND
SN 0962-7286
J9 ANIM WELFARE
JI Anim. Welf.
PD FEB
PY 2004
VL 13
SU S
BP S127
EP S132
PG 6
WC Veterinary Sciences; Zoology
SC Veterinary Sciences; Zoology
GA 811RX
UT WOS:000220790100018
DA 2019-03-21
ER

PT J
AU Porzsolt, F
   Schlotz-Gorton, N
   Biller-Andorno, N
   Thim, A
   Meissner, K
   Roeckl-Wiedmann, I
   Herzberger, B
   Ziegler, R
   Gaus, W
   Poppel, E
AF Porzsolt, F
   Schlotz-Gorton, N
   Biller-Andorno, N
   Thim, A
   Meissner, K
   Roeckl-Wiedmann, I
   Herzberger, B
   Ziegler, R
   Gaus, W
   Poppel, E
TI Applying evidence to support ethical decisions: Is the placebo really
   powerless?
SO SCIENCE AND ENGINEERING ETHICS
LA English
DT Article; Proceedings Paper
CT International Conference on Placebo - Its Action and Place in Health
   Research Today
CY APR 12-13, 2003
CL WARSAW, POLAND
DE placebo; knowledge framing; ethics; informed consent; patient's
   information; confidence
ID RANDOMIZED CLINICAL-TRIALS; MYOCARDIAL-INFARCTION; PATIENT
   COMMUNICATION; ALTERNATIVE MEDICINE; TREATMENT ADHERENCE; HEALTH
   OUTCOMES; PREFERENCES; THERAPY; DEATH; RISK
AB Using placebos in day-to-day practice is an ethical problem. This paper summarises the available epidemiological evidence to support this difficult decision. Based on these data we propose to differentiate between placebo and "knowledge framing". While the use of placebo should be confined to experimental settings in clinical trials, knowledge framing - which is only conceptually different from placebo - is a desired, expected and necessary component of any doctor-patient encounter. Examples from daily practice demonstrate both, the need to investigate the effects of knowledge framing and its impact on ethical, medical, economical and legal decisions.
C1 Univ Hosp Ulm, Clin Econ, D-89075 Ulm, Germany.
   Univ Munich, Human Sci Ctr, D-80336 Munich, Germany.
   Univ Gottingen, Dept Med Eth & Hist Med, D-37973 Gottingen, Germany.
   Univ Munich, Inst Biostat & Epidemiol, D-80336 Munich, Germany.
   Hiscia Res Inst, CH-4144 Arlesheim, Switzerland.
   Univ Ulm, Dept Biometr & Med Documentat, D-89075 Ulm, Germany.
RP Porzsolt, F (reprint author), Univ Hosp Ulm, Clin Econ, Steinhoevelstr 9, D-89075 Ulm, Germany.
EM franz.porzsolt@medizin.uni-ulm.de
CR ADLER HM, 1973, ANN INTERN MED, V78, P595, DOI 10.7326/0003-4819-78-4-595
   Biller N, 1999, PERSPECT BIOL MED, V42, P398
   BREWIN CR, 1989, BRIT MED J, V299, P313, DOI 10.1136/bmj.299.6694.313
   BUTLER C, 1986, BRIT J CLIN PSYCHOL, V25, P173, DOI 10.1111/j.2044-8260.1986.tb00693.x
   CANNER PL, 1980, NEW ENGL J MED, V303, P1038
   Chvetzoff G, 2003, J NATL CANCER I, V95, P19, DOI 10.1093/jnci/95.1.19
   COPPIN C, 2002, COCHRANE LIB
   Crow R, 1999, Health Technol Assess, V3, P1
   de Craen AJM, 2000, J NEUROL, V247, P183, DOI 10.1007/s004150050560
   de Craen AJM, 1999, BRIT J CLIN PHARMACO, V48, P853, DOI 10.1046/j.1365-2125.1999.00094.x
   de la Fuente-Fernandez- R, 2002, TRENDS NEUROSCI, V25, P302, DOI 10.1016/S0166-2236(02)02181-1
   Di Blasi Z, 2001, LANCET, V357, P757, DOI 10.1016/S0140-6736(00)04169-6
   Eccles R, 2002, PULM PHARMACOL THER, V15, P303, DOI 10.1006/pupt.2002.0364
   ERNST E, 1995, BMJ-BRIT MED J, V311, P551, DOI 10.1136/bmj.311.7004.551
   GALLAGHER EJ, 1993, JAMA-J AM MED ASSOC, V270, P742, DOI 10.1001/jama.270.6.742
   GRACELY RH, 1985, LANCET, V1, P43
   GREEN LW, 1977, AM J PUBLIC HEALTH, V67, P155, DOI 10.2105/AJPH.67.2.155
   GRUNDY SM, 1990, J LIPID RES, V31, P1149
   Harrington A, 1997, PLACEBO EFFECT INTER
   HORWITZ RI, 1990, LANCET, V336, P542, DOI 10.1016/0140-6736(90)92095-Y
   Hrobjartsson A, 2001, NEW ENGL J MED, V344, P1594, DOI 10.1056/NEJM200105243442106
   KAPLAN SH, 1989, MED CARE, V27, pS110, DOI 10.1097/00005650-198903001-00010
   Kaptchuk TJ, 2000, J CLIN EPIDEMIOL, V53, P786, DOI 10.1016/S0895-4356(00)00206-7
   Kaptchuk TJ, 2002, ANN INTERN MED, V136, P817, DOI 10.7326/0003-4819-136-11-200206040-00011
   Kaptchuk TJ, 1998, ANN INTERN MED, V129, P1061, DOI 10.7326/0003-4819-129-12-199812150-00011
   KOES BW, 1992, SPINE, V17, P28, DOI 10.1097/00007632-199201000-00005
   LUPARELLO TJ, 1970, PSYCHOSOM MED, V32, P509, DOI 10.1097/00006842-197009000-00009
   McPherson K, 1997, J ROY SOC MED, V90, P652, DOI 10.1177/014107689709001205
   MEISSNER K, 2002, GIBT ORGANSPEZIFISCH
   ONG LML, 1995, SOC SCI MED, V40, P903, DOI 10.1016/0277-9536(94)00155-M
   PORZOLT F, 2003, KLINISCHE OKONOMIK
   PORZOLT F, 2002, EVIDENCE BASED ONCOL
   RIETHMULLER G, 1994, LANCET, V343, P1177, DOI 10.1016/S0140-6736(94)92398-1
   Sacca Luigi, 2002, Ann Ital Med Int, V17, P215
   SHAPIRO AP, 1954, PSYCHOSOM MED, V16, P478, DOI 10.1097/00006842-195411000-00002
   SODEGREN SC, 1999, EXPECTANCIES SHAPE E
   Spiro HM, 1986, DOCTORS PATIENTS PLA
   STERNBACH RA, 1964, PSYCHOPHYSIOLOGY, V1, P67
   STEWART MA, 1995, CAN MED ASSOC J, V152, P1423
   THOMAS KB, 1994, LANCET, V344, P1066, DOI 10.1016/S0140-6736(94)91716-7
   THOMAS M, 1991, AM J CHINESE MED, V19, P95, DOI 10.1142/S0192415X91000156
   Walach H, 2002, PSYCHOTHER PSYCH MED, V52, P332, DOI 10.1055/s-2002-33077
   Walsh BT, 2002, JAMA-J AM MED ASSOC, V287, P1840, DOI 10.1001/jama.287.14.1840
   WENNBERG JE, 1990, MODERN METHODS CLIN
   ZELEN M, 1979, NEW ENGL J MED, V300, P1242, DOI 10.1056/NEJM197905313002203
   Zeller A, 2002, Praxis (Bern 1994), V91, P1986
   1981, BMJ, V4, P775
NR 47
TC 11
Z9 11
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1353-3452
EI 1471-5546
J9 SCI ENG ETHICS
JI Sci. Eng. Ethics
PD JAN
PY 2004
VL 10
IS 1
BP 119
EP 132
DI 10.1007/s11948-004-0069-6
PG 14
WC Ethics; Engineering, Multidisciplinary; History & Philosophy Of Science;
   Multidisciplinary Sciences; Philosophy
SC Social Sciences - Other Topics; Engineering; History & Philosophy of
   Science; Science & Technology - Other Topics; Philosophy
GA 772PP
UT WOS:000188850700016
PM 14986778
DA 2019-03-21
ER

PT J
AU McLaren, BM
AF McLaren, BM
TI Extensionally defining principles and cases in ethics: An AI model
SO ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE interpretive case-based reasoning; engineering ethics; ethical
   principles; operationalization; extensional definitions; analogy; A*
   search; structural mapping
AB Principles are abstract rules intended to guide decision-makers in making normative judgments in domains like the law, politics, and ethics. It is difficult, however, if not impossible to define principles in an intensional manner so that they may be applied deductively. The problem is the gap between the abstract, open-textured principles and concrete facts. On the other hand, when expert decision-makers rationalize their conclusions in specific cases, they often link principles to the specific facts of the cases. In effect, these expert-defined associations between principles and facts provide extensional definitions of the principles. The experts operationalize the abstract principles by linking them to the facts.
   This paper discusses research in which the following hypothesis was empirically tested: extensionally defined principles, as well as cited past cases, can help in predicting the principles and cases that might be relevant in the analysis of new cases. To investigate this phenomenon computationally, a large set of professional ethics cases was analyzed and a computational model called SIROCCO, a system for retrieving principles and past cases, was constructed. Empirical evidence is presented that the operationalization information contained in extensionally defined principles can be leveraged to predict the principles and past cases that are relevant to new problem situations. This is shown through an ablation experiment, comparing SIROCCO to a version of itself that does not employ operationalization information. Further, it is shown that SIROCCO's extensionally defined principles and case citations help it to outperform a full-text retrieval program that does not employ such information. (C) 2003 Elsevier B.V. All rights reserved.
C1 Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15213 USA.
RP McLaren, BM (reprint author), Carnegie Mellon Univ, Human Comp Interact Inst, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM bmclaren@cs.cmu.edu
CR Aleven Vincent, 1997, THESIS U PITTSBURGH
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   ARRAS JD, 1994, INDIANA LAW J, V983, P1006
   Ashley K, 1990, MODELING LEGAL ARGUM
   ASHLEY KD, 1995, P 1 INT C CAS BAS RE
   ASHLEY KD, 1997, P 15 INT JOINT C ART, P335
   BERMAN DH, 1986, COMPUTER POWER LEGAL, P185
   BONISSONE P, 1992, P 1992 IEEE INT C TO
   Branting L. K., 2000, REASONING RULES PREC
   BRANTING LK, 1991, INT J MAN MACH STUD, V34, P797, DOI 10.1016/0020-7373(91)90012-V
   Bruninghaus S, 1999, LECT NOTES ARTIF INT, V1650, P59
   BRUNINGHAUS S, 2001, P 4 INT C CAS BAS RE, P74
   Davison AC, 1997, BOOTSTRAP METHODS TH
   FORBUS KD, 1995, COGNITIVE SCI, V19, P141, DOI 10.1207/s15516709cog1902_1
   GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1016/S0364-0213(83)80009-3
   Ginsberg M. L., 1993, ESSENTIALS ARTIFICIA
   GOLDIN IM, 2001, P 8 INT C ART INT LA, P94
   Harris C., 1999, ENG ETHICS CONCEPTS
   Horty John, 1999, P 7 INT C ART INT LA, P63
   Jonsen Albert R., 1988, ABUSE CASUISTRY HIST
   KETTLER BP, 1994, IEEE EXPERT, V9, P8, DOI 10.1109/64.295138
   Kolodner J., 1993, CASE BASED REASONING
   KOOMEN JAG, 1989, 231 U ROCH COMP SCI
   LEAKE DB, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P10
   LEWIS D, 1996, P 19 ANN INT ACM SIG
   McLaren B, 1999, LECT NOTES ARTIF INT, V1650, P248
   McLaren B.M., 1999, THESIS U PITTSBURGH
   McLaren BM, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P316
   McLaren BM, 1995, P 17 ANN C COGN SCI
   MCLAREN BM, 2001, P 4 INT C CAS BAS RE, P377
   MOSTOW J, 1983, MACH LEARN, V1, P367
   *NSPE, 1996, NSPE ETH REF GUID
   *NSPE, 1958, OP BOARD ETH REV, V1
   PINKUS R, 1997, 9720341 NSF
   RESNICK R, 1967, PHYSICS
   Rissland E. L., 1997, Artificial Intelligence and Law, V5, P1, DOI 10.1023/A:1008215000938
   Rissland E. L., 1996, Artificial Intelligence and Law, V4, P1, DOI 10.1007/BF00123994
   RISSLAND EL, 1991, INT J MAN MACH STUD, V34, P839, DOI 10.1016/0020-7373(91)90013-W
   RISSLAND EL, 1990, 41 CSL PRINC U
   Toulmin S, 1958, USES ARGUMENT
   TWINING W, 1976, DO THINGS RULES
   van Rijsbergen C. J., 1979, INFORMATION RETRIEVA
   von der Lieth Gardner A., 1987, ARTIFICIAL INTELLIGE
   Witten IH, 1999, MANAGING GIGABYTES C
NR 44
TC 31
Z9 31
U1 2
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0004-3702
EI 1872-7921
J9 ARTIF INTELL
JI Artif. Intell.
PD NOV
PY 2003
VL 150
IS 1-2
BP 145
EP 181
DI 10.1016/S0004-3702(03)00135-8
PG 37
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 741PZ
UT WOS:000186467600005
OA Bronze
DA 2019-03-21
ER

PT J
AU Davion, V
AF Davion, V
TI Anthropocentrism, artificial intelligence, and moral network theory: An
   ecofeminist perspective
SO ENVIRONMENTAL VALUES
LA English
DT Article
DE ecofeminism; artificial intelligence; intelligence; moral theory
AB This paper critiques a conception of intelligence central in AI, and a related concept of reason central in moral philosophy, from an ecological feminist perspective. I argue that ecofeminist critique of human/nature dualisms offers insight into the durability of both problematic conceptions, and into the direction of research programmes. I conclude by arguing for the importance of keeping political analysis in the forefront of science and environmental ethics.
C1 Univ Georgia, Coll Arts & Sci, Dept Philosophy, Athens, GA 30602 USA.
RP Davion, V (reprint author), Univ Georgia, Coll Arts & Sci, Dept Philosophy, 107 Peabody Hall, Athens, GA 30602 USA.
CR BARR A, 1981, HDB ARTIFICIAL INTEL, V1
   Charniak Eugene, 1985, INTRO ARTIFICIAL INT
   CHURCHLAND PM, 1996, MIND MORALS ESSAYS E
   Code Lorraine, 1991, WHAT CAN SHE KNOW FE
   Dobson A., 1990, GREEN POLITICAL THOU
   FLANAGAN O, 1996, MIND MORALS ESSAYS E
   Griffin Susan, 1978, WOMAN NATURE ROARING
   Harding Sandra, 1986, SCI QUESTION FEMINIS
   MASON JM, 1995, WHEN ELEPHANTS WEEP
   Merchant C., 1983, DEATH NATURE WOMEN E
   MINSKY M, 1968, SEMANTIC INFORMATION
   NAESS A, 1973, INQUIRY, V16, P95, DOI 10.1080/00201747308601682
   Norton Bryan, 1987, WHY PRESERVE NATURAL
   Plumwood V, 1993, FEMINISM MASTERY NAT
   Preston B., 1991, Minds and Machines, V1, P259, DOI 10.1007/BF00351181
   Schutzer D., 1987, ARTIFICIAL INTELLIGE
   TANIMOTO SL, 1990, ELEMENTS ARTIFICIAL
   WARREN KJ, 1990, ENVIRON ETHICS, V12, P125, DOI 10.5840/enviroethics199012221
   Weston A, 1992, BETTER PROBLEMS
   Winston P. H, 1984, ARTIFICIAL INTELLIGE
NR 20
TC 1
Z9 1
U1 3
U2 7
PU WHITE HORSE PRESS
PI CAMBRIDGE
PA 10 HIGH ST, KNAPWELL, CAMBRIDGE CB3 8NR, ENGLAND
SN 0963-2719
J9 ENVIRON VALUE
JI Environ. Values
PD MAY
PY 2002
VL 11
IS 2
BP 163
EP 176
DI 10.3197/096327102129341037
PG 14
WC Ethics; Environmental Studies
SC Social Sciences - Other Topics; Environmental Sciences & Ecology
GA 570BP
UT WOS:000176638400004
DA 2019-03-21
ER

PT J
AU Cappel, JJ
   Windsor, JC
AF Cappel, JJ
   Windsor, JC
TI Ethical decision making: A comparison of computer-supported and
   face-to-face group
SO JOURNAL OF BUSINESS ETHICS
LA English
DT Article
DE group ethical decision making; group support systems; information
   systems; laboratory experiment
ID MEDIA RICHNESS; SOCIETY COURSE; POLARIZATION; TECHNOLOGY; BUSINESS;
   ADVOCACY
AB This study compares computer-supported groups, i.e., groups using group support systems (GSS), and face-to-face groups using ethical decision-making tasks. A laboratory experiment was conducted using five-person groups of information systems professionals. Face-to- face (FTF) and GSS groups were compared in terms of their decision outcomes and group members' reactions. The results revealed that computer-supported and face-to-face groups showed no significant difference in terms of the decision outcomes of choice shift and decision polarity. However, FTF groups reached their decisions more quickly and they were more successful in attaining group consensus than GSS groups. Subjects evaluated face-to-face communication more favorably than GSS interaction on most post-group measures related to perceived group processes and satisfaction. Despite these outcomes, some possibilities for using GSS technology in an ethical decision making context are examined.
C1 Cent Michigan Univ, Coll Business Adm, Dept Business Informat Syst, Mt Pleasant, MI 48859 USA.
   Univ N Texas, Coll Business Adm, Business Comp Informat Syst Dept, Denton, TX 76203 USA.
RP Cappel, JJ (reprint author), Cent Michigan Univ, Coll Business Adm, Dept Business Informat Syst, Mt Pleasant, MI 48859 USA.
CR ANSON R, 1990, THESIS INDIANA U
   Bordia P., 1997, J BUS COMMUN, V34, P99, DOI DOI 10.1177/002194369703400106
   BUTLER JK, 1992, ORGAN BEHAV HUM DEC, V53, P14, DOI 10.1016/0749-5978(92)90052-9
   CHANEY LH, 1994, J COMPUT INFORM SYST, V35, P19
   Cole BC, 1996, J BUS ETHICS, V15, P889, DOI 10.1007/BF00381856
   DAFT RL, 1986, MANAGE SCI, V32, P554, DOI 10.1287/mnsc.32.5.554
   DAFT RL, 1987, MIS Q, V11, P354, DOI DOI 10.2307/248682
   Dennis A. R., 1993, GROUP SUPPORT SYSTEM, P59
   DENNIS AR, 1988, MIS QUART, V12, P591, DOI 10.2307/249135
   DESANCTIS G, 1987, MANAGE SCI, V33, P589, DOI 10.1287/mnsc.33.5.589
   Dubrovsk V. J., 1991, Human-Computer Interaction, V6, P119, DOI 10.1207/s15327051hci0602_2
   DUKERICH JM, 1990, HUM RELAT, V43, P473, DOI 10.1177/001872679004300505
   El-Shinnawy M, 1998, MIS QUART, V22, P165, DOI 10.2307/249394
   George JF, 1990, INFORM SYST RES, V1, P394, DOI 10.1287/isre.1.4.394
   GLENN JR, 1992, J BUS ETHICS, V11, P217, DOI 10.1007/BF00871969
   HARRIS JR, 1995, J BUS ETHICS, V14, P805, DOI 10.1007/BF00872347
   HOLLINGSHEAD AB, 1993, THESIS U ILLINOIS
   HOLLINGSHEAD AB, 1995, TEAM EFFECTIVENESS D
   KERR NL, 1992, GROUP PROCESS PRODUC
   KIESLER S, 1992, ORGAN BEHAV HUM DEC, V52, P96, DOI 10.1016/0749-5978(92)90047-B
   KRAEMER KL, 1990, INTELLECTUAL TEAMWOR
   LAM SSK, 1997, J MANAGE INFORM SYST, V13, P193, DOI DOI 10.1057/EJIS.2009.22
   LEE AS, 1994, MIS QUART, V18, P143, DOI 10.2307/249762
   McGrath J. E, 1994, GROUPS INTERACTING T
   McGrath J. E., 1993, GROUP SUPPORT SYSTEM, P78
   MIRANDA SM, 1991, THESIS U GEORGIA
   MYERS DG, 1976, PSYCHOL BULL, V83, P602, DOI 10.1037/0033-2909.83.4.602
   PARKER D, 1990, ETHICAL CONFLICTS IN
   RICE RE, 1992, ORGAN SCI, V3, P475, DOI 10.1287/orsc.3.4.475
   ROBERTSON DC, 1993, J BUS ETHICS, V12, P585, DOI 10.1007/BF01845895
   SIEGEL J, 1986, ORGAN BEHAV HUM DEC, V37, P157, DOI 10.1016/0749-5978(86)90050-6
   STRAUS SG, 1994, J APPL PSYCHOL, V79, P87, DOI 10.1037//0021-9010.79.1.87
   THORNTON C, 1994, J SYST MANAGE, P10
   TYRAN CK, 1992, MIS QUART, V16, P313, DOI 10.2307/249531
   Valacich JS, 1995, DECISION SCI, V26, P369, DOI 10.1111/j.1540-5915.1995.tb01433.x
   WEISBAND SP, 1992, ORGAN BEHAV HUM DEC, V53, P352, DOI 10.1016/0749-5978(92)90070-N
   WYND WR, 1989, J BUS ETHICS, V8, P487, DOI 10.1007/BF00381815
NR 37
TC 19
Z9 20
U1 1
U2 9
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 0167-4544
J9 J BUS ETHICS
JI J. Bus. Ethics
PD NOV
PY 2000
VL 28
IS 2
BP 95
EP 107
DI 10.1023/A:1006344825235
PG 13
WC Business; Ethics
SC Business & Economics; Social Sciences - Other Topics
GA 360VX
UT WOS:000089689000001
DA 2019-03-21
ER

PT J
AU [Anonymous]
AF [Anonymous]
TI Morals for robots and cyborgs
SO IEE REVIEW
LA English
DT News Item
NR 0
TC 0
Z9 0
U1 0
U2 0
PU INST ENGINEERING TECHNOLOGY-IET
PI HERTFORD
PA MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND
SN 0013-5127
J9 IEE REVIEW
JI IEE Rev.
PD JAN
PY 2000
VL 46
IS 1
BP 7
EP 7
PG 1
WC Engineering, Electrical & Electronic
SC Engineering
GA 279NL
UT WOS:000085051000018
DA 2019-03-21
ER

PT J
AU Collste, G
   Shahsavar, N
   Gill, H
AF Collste, G
   Shahsavar, N
   Gill, H
TI A decision support system for diabetes care: Ethical aspects
SO METHODS OF INFORMATION IN MEDICINE
LA English
DT Article; Proceedings Paper
CT 1st International Working Conference on Electronic Patient Records in
   Medical Practice (EPRiMP)
CY OCT 08-10, 1998
CL ROTTERDAM, NETHERLANDS
DE medical informatics; decision support systems; computer ethics; medical
   ethics
AB In this paper the design and implementation of a decision support system for diabetes care is examined from an ethical perspective. It is noted that the system creates potential for enhancing the realization of the principle of autonomy through improved information to patients a nd participation by patients. However, there is also potential for using the system in a way that is contrary to good health care. It may provide patients with information they are unable to interpret and handle, and it may be used by healthcare authorities for controlling their personnel in ways contrary to good quality working conditions. In order for a decision support system to function as a well-integrated element, in ethically based health care, different ethical aspects have to be taken into account during the design of the system. The ethical aspects also constitute one perspective of a systematic re-evaluation and re-design process.
C1 Linkoping Univ, Ctr Appl Eth, S-58183 Linkoping, Sweden.
   Linkoping Univ Hosp, Ctr Oncol, S-58185 Linkoping, Sweden.
   Linkoping Univ, Dept Med Informat, Linkoping, Sweden.
RP Collste, G (reprint author), Linkoping Univ, Ctr Appl Eth, S-58183 Linkoping, Sweden.
CR Beauchamp TL, 1978, PRINCIPLES BIOMEDICA
   Lucas J. R., 1995, RESPONSIBILITY
   Reiser Stanley Joel, 1978, MED REIGN TECHNOLOGY
   WINKLER E, 1993, APPL ETHICS
   Winner L., 1986, WHALE REACTOR SEARCH
NR 5
TC 3
Z9 3
U1 0
U2 0
PU F K SCHATTAUER VERLAG GMBH
PI STUTTGART
PA P O BOX 10 45 43, LENZHALDE 3, D-70040 STUTTGART, GERMANY
SN 0026-1270
J9 METHOD INFORM MED
JI Methods Inf. Med.
PD DEC
PY 1999
VL 38
IS 4-5
BP 313
EP 316
PG 4
WC Computer Science, Information Systems; Health Care Sciences & Services;
   Medical Informatics
SC Computer Science; Health Care Sciences & Services; Medical Informatics
GA 272EP
UT WOS:000084637800015
PM 10805020
DA 2019-03-21
ER

PT J
AU Stafleu, FR
   Tramper, R
   Vorstenbosch, J
   Joles, JA
AF Stafleu, FR
   Tramper, R
   Vorstenbosch, J
   Joles, JA
TI The ethical acceptability of animal experiments: a proposal for a system
   to support decision-making
SO LABORATORY ANIMALS
LA English
DT Article
DE animal experiments; ethics; ethical theory; decision system
AB We describe a system to support decision-making on the ethical acceptability of animal experiments for scientific researchers and others responsible for ethical decision-making in animal experiments. The system consists of eight steps. Each step contains a number of substantive questions or a computational rule, leading to a well-articulated moral judgment on specific animal experiments. The system comprises a number of moral assumptions and pre-emptive norms, but leaves enough room for moral discretion and personal responsibility. The general ethical ideas behind the moral choices and assumptions are sketched and potential objections to the overall approach are discussed.
C1 Univ Utrecht, Ctr Bioeth & Hlth Law, NL-3584 CS Utrecht, Netherlands.
   Univ Utrecht, Fac Med, Dept Nephrol, Utrecht, Netherlands.
RP Stafleu, FR (reprint author), Univ Utrecht, Ctr Bioeth & Hlth Law, Heidelberglaan 2, NL-3584 CS Utrecht, Netherlands.
CR BUNING TJD, 1993, ANIM WELFARE, V3, P107
   Daniels N, 1985, JUST HLTH CARE
   DEDEYN PD, 1994, ETHICS ANIMAL HUMAN
   Mellor DJ, 1994, IMPROVING WELL BEING
   Orlans F. B, 1993, NAME SCI ISSUES RESP
   PORTER DG, 1992, NATURE, V356, P101, DOI 10.1038/356101a0
   Rawls J., 1972, THEORY JUSTICE
   Regan T., 1983, CASE ANIMAL RIGHTS
   Russell W. M., 1959, PRINCIPLES HUMANE EX
   Ryder R. D, 1975, VICTIMS SCI USE ANIM
   SEN A, 1985, WELL BEING AGENCY FR
   Singer P., 1995, PRACTICAL ETHICS
   Singer Peter, 1975, ANIMAL LIBERATION
   SMITH JA, 1991, LIVES BALANCE ETHICS
   STAFLEU FR, 1994, THESIS UTRECHT U
   Taylor P., 1986, RESPECT NATURE THEOR
   THEUNE EP, 1993, SCI HUMAN ANIMAL REL, P143
   TRAMPER R, 1997, UNPUB WEIGHING ANIMA
   van Zutphen L. F. M., 1997, ANIMAL ALTERNATIVES
   VANDEVEER D, 1979, INQUIRY, V22, P55, DOI 10.1080/00201747908601866
NR 20
TC 26
Z9 29
U1 1
U2 4
PU ROYAL SOC MEDICINE PRESS LTD
PI LONDON
PA 1 WIMPOLE STREET, LONDON W1M 8AE, ENGLAND
SN 0023-6772
J9 LAB ANIM
JI Lab. Anim.
PD JUL
PY 1999
VL 33
IS 3
BP 295
EP 303
DI 10.1258/002367799780578255
PG 9
WC Veterinary Sciences; Zoology
SC Veterinary Sciences; Zoology
GA 232EN
UT WOS:000082357200014
PM 10780850
OA Bronze
DA 2019-03-21
ER

PT J
AU Zych, JM
AF Zych, JM
TI Integrating ethical issues with managerial decision making in the
   classroom: Product support program decisions
SO JOURNAL OF BUSINESS ETHICS
LA English
DT Article
DE competition; ethics; experiment; product support programs; profit levels
ID TEACHING BUSINESS ETHICS; CURRICULUM
AB Literature on the teaching of ethics points to the need for realistic business problems in which students deal with ethical dilemmas. This paper presents the results of an experiment in which students take on the role of a Brand Manager who must decide on the level of support to allocate: to four distinct business problems. The problems were presented as business problems including realistic profit and cost considerations, rather than being posed as "ethics cases". Students were able to select from a range of product support levels for each problem. The experiment isolated the factor effects which included level of realism, degree of competition, company situation in terms of fault and profit level, and problem type relative to damage and visibility. Company fault was the most important factor in determining the level of product support allocations. Allocations generally increased when there was an increase in profit level from low to medium. However, there was no additional increase in allocations above the medium profit level. The paper concludes with suggestions on how the results call be used as a spring-board for discussion of the integration of ethical considerations in managerial decision making.
C1 Univ Scranton, Sch Management, Dept Management & Mkt, Scranton, PA 18510 USA.
RP Zych, JM (reprint author), Univ Scranton, Sch Management, Dept Management & Mkt, Scranton, PA 18510 USA.
CR BISHOP TR, 1992, J BUS ETHICS, V11, P291, DOI 10.1007/BF00872171
   BROWN KM, 1994, J BUS ETHICS, V13, P105, DOI 10.1007/BF00881579
   BYRNE JA, 1992, BUSINESS WEEK   0413, P34
   DUNFEE TW, 1988, J BUS ETHICS, V7, P847, DOI 10.1007/BF00383048
   GANDZ J, 1988, J BUS ETHICS, V7, P657, DOI 10.1007/BF00382975
   KULBERG D, 1988, MANAGE REV, V77, P54
   MATHISON DL, 1988, J BUS ETHICS, V7, P777, DOI 10.1007/BF00411025
   MURRAY TJ, 1987, BUSINESS MONTH, V129, P24
   PAMENTAL GL, 1989, J BUS ETHICS, V8, P547, DOI 10.1007/BF00382930
   STRONG VK, 1990, J BUS ETHICS, V9, P603, DOI 10.1007/BF00383216
NR 10
TC 8
Z9 8
U1 0
U2 1
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 0167-4544
J9 J BUS ETHICS
JI J. Bus. Ethics
PD FEB
PY 1999
VL 18
IS 3
BP 255
EP 266
DI 10.1023/A:1005871423821
PG 12
WC Business; Ethics
SC Business & Economics; Social Sciences - Other Topics
GA 179LE
UT WOS:000079328100002
DA 2019-03-21
ER

PT J
AU de Casterle, BD
AF de Casterle, BD
TI Supporting nurses in ethical decision making
SO NURSING CLINICS OF NORTH AMERICA
LA English
DT Article
ID NURSING-STUDENTS; PRACTICING NURSES; MORAL JUDGMENT; HONG-KONG;
   DILEMMAS; BEHAVIOR
AB In their clinical practice, nurses are confronted continuously with ethical issues. There is a growing concern about the capacity of nurses to perform ethically. This article explores the process of ethical decision-making in nursing, including the process of ethical reasoning and the implementation of ethical decisions in clinical practice. This article begins with a reflection on the essence of nursing and on nurses' ethical responsibility. Problems as well as determinants related to nurses' ethical decision-making, are described.. Based on the research in this area, some strategies to support ethical decision-making by nurses are proposed.
C1 Katholieke Univ Leuven, Ctr Hlth Serv & Nursing Res, B-3000 Louvain, Belgium.
RP de Casterle, BD (reprint author), Katholieke Univ Leuven, Ctr Hlth Serv & Nursing Res, Kapucijnenvoer 35-4, B-3000 Louvain, Belgium.
CR AKERLUND BM, 1985, INT J NURS STUD, V22, P207, DOI 10.1016/0020-7489(85)90004-5
   ALLERT G, 1994, HASTINGS CENT REP, V24, P11, DOI 10.2307/3563490
   Berger M C, 1991, West J Nurs Res, V13, P514, DOI 10.1177/019394599101300407
   Bishop A.H., 1990, PRACTICAL MORAL PERS
   BURNARD P, 1985, LEARNING HUMAN SKILL
   CALLAHAN D, 1995, WORLD GROWING OLD
   CASSELLS JM, 1989, NURS CLIN N AM, V24, P463
   Cassidy V R, 1988, J Nurs Educ, V27, P405
   COPP LA, 1986, J ADV NURS, V11, P255
   Copstead LC, 1983, DISS ABSTR INT, V45, p84A
   Corley M C, 1994, Dimens Crit Care Nurs, V13, P96, DOI 10.1097/00003465-199403000-00007
   Corley M C, 1992, West J Nurs Res, V14, P380, DOI 10.1177/019394599201400308
   COX JL, 1985, DISS ABSTR INT, V47, pA131
   CRISHAM P, 1981, NURS RES, V30, P104
   DAVIDSON B, 1990, CANCER NURS, V13, P286
   Davis A J, 1981, West J Nurs Res, V3, P397, DOI 10.1177/019394598100300409
   deCasterle BD, 1996, WESTERN J NURS RES, V18, P330, DOI 10.1177/019394599601800308
   deCasterle BD, 1997, NURS ETHICS, V4, P12, DOI 10.1177/096973309700400103
   DECASTERLE BD, 1997, J NURSING MEASUREMEN, V5, P87
   deJong AF, 1984, DISSERT ABSTR, V46, p792B
   EDWARDS BJ, 1988, J NURS ADMIN, V18, P30
   Erlen J A, 1993, Orthop Nurs, V12, P69, DOI 10.1097/00006416-199303000-00012
   Erlen J A, 1991, West J Nurs Res, V13, P397, DOI 10.1177/019394599101300309
   Felton G M, 1987, J Nurs Educ, V26, P7
   FELTON GM, 1984, DISS ABSTR INT, V46, pA474
   FRENCH P, 1994, NURSING ED INT PERSP
   Frisch N C, 1987, J Nurs Educ, V26, P328
   GASTMANS C, 1992, SOINS, V137, P40
   Gaul A L, 1987, J Nurs Educ, V26, P113
   GAUL AL, 1986, DISS ABSTR INT, V47, pA4113
   GOLD C, 1995, NURS ETHICS, V2, P131, DOI 10.1177/096973309500200205
   Holly C M, 1993, J Prof Nurs, V9, P110, DOI 10.1016/8755-7223(93)90027-A
   HOLLY CM, 1986, DISS ABSTR INT, V47, pB2372
   KELLY B, 1991, J ADV NURS, V16, P867, DOI 10.1111/j.1365-2648.1991.tb01769.x
   KETEFIAN S, 1981, NURS RES, V30, P171
   KETEFIAN S, 1981, NURS RES, V30, P98
   KETEFIAN S, 1989, NURS CLIN N AM, V24, P509
   KETEFIAN S, 1985, NURS RES, V34, P248
   Kohlberg L., 1976, MORAL DEV BEHAV THEO, P31
   Krawczyk RM, 1997, NURS ETHICS, V4, P57, DOI 10.1177/096973309700400107
   LACHMAN VD, 1991, PADONA J, V4, P4
   LAWRENCE JA, 1987, J MORAL EDUC, V16, P167, DOI 10.1080/0305724870160302
   Leners D, 1997, NURS ETHICS, V4, P361, DOI 10.1177/096973309700400502
   Millette B E, 1994, West J Nurs Res, V16, P660, DOI 10.1177/019394599401600605
   Munhall Patricia, 1980, Image (IN), V12, P57
   MURPHY CP, 1976, DISS ABSTR INT B, V38, P593
   Mustapha S L, 1989, J Nurs Educ, V28, P107
   Mysak S, 1997, J Gerontol Nurs, V23, P25
   Pinch W J, 1985, J Nurs Educ, V24, P372
   Roth P A, 1994, J Prof Nurs, V10, P271, DOI 10.1016/8755-7223(94)90052-3
   Smith KV, 1996, NURS ETHICS, V3, P17, DOI 10.1177/096973309600300104
   STEPHENSON PM, 1984, J ADV NURS, V9, P283, DOI 10.1111/j.1365-2648.1984.tb00372.x
   SWIDER SM, 1985, NURS RES, V34, P108
   WELLARD S, 1992, J ADV NURS, V17, P951, DOI 10.1111/j.1365-2648.1992.tb02023.x
   WILKINSON JM, 1988, NURS FORUM, V12, P16
   WURZBACH ME, 1995, J ADV NURS, V21, P1059, DOI 10.1046/j.1365-2648.1995.21061059.x
   Yung HHP, 1997, NURS ETHICS, V4, P99, DOI 10.1177/096973309700400202
   Yung HHP, 1997, INT J NURS STUD, V34, P128, DOI 10.1016/S0020-7489(96)00046-6
NR 58
TC 2
Z9 2
U1 1
U2 1
PU W B SAUNDERS CO
PI PHILADELPHIA
PA INDEPENDENCE SQUARE WEST CURTIS CENTER, STE 300, PHILADELPHIA, PA
   19106-3399 USA
SN 0029-6465
J9 NURS CLIN N AM
JI Nurs. Clin. North Am.
PD SEP
PY 1998
VL 33
IS 3
BP 543
EP +
PG 14
WC Nursing
SC Nursing
GA 123GX
UT WOS:000076118400013
PM 9719697
DA 2019-03-21
ER

PT J
AU Thomson, AJ
AF Thomson, AJ
TI Artificial intelligence and environmental ethics
SO AI APPLICATIONS
LA English
DT Article
ID MANAGEMENT
AB AI systems have the potential to address ethical issues. Case-based reasoning systems may be the most promising approach to environmental ethics. Power issues, considered in applied ethics, are a fundamental feature of issues arising from landscape-level management, and may be studied using stakeholder modeling techniques, while rule-based systems may be appropriate for deontological ethical issues (based on duties or obligations). Semantic networks may be used to study and summarize the views of individuals in groups. Conflict between individual advantage and the common good can be explored through Game Theory.
RP Thomson, AJ (reprint author), FORESTRY CANADA, PACIFIC FORESTRY CTR, CANADIAN FOREST SERV, 506 W BURNSIDE RD, VICTORIA, BC V8Z 1M5, CANADA.
CR Akenhead S. A., 1996, Proceedings of Eco-Informa '96. Global Networks for Environmental Information, P399
   ALLEN GM, 1986, J FOREST, V84, P20
   Armstrong S. J., 1993, ENV ETHICS DIVERGENC
   ASHLEY KD, 1988, IEEE EXPERT, V3, P70, DOI 10.1109/64.21892
   BAREISS R, 1989, PERSPECTIVES ARTIFIC, V2
   BERRY JK, 1993, P 1993 SOC AM FOR NA, P63
   Beyerstein Dale, 1993, APPL ETHICS READER, P416
   BOWYER JL, 1991, FOREST PERSPECTIVES, V1, P12
   COLFER CJP, 1989, AI APPL NAT RES MAN, V3, P31
   CORNETT ZJ, 1994, J FOREST, V92, P6
   Cortner H. J, 1996, PNWGTR354 USDA FOR S
   DANIELSON P, 1993, APPL ETHICS READER, P329
   Danielson P., 1992, ARTIFICIAL MORALITY
   DANIELSON PA, 1995, VANCOUVER COGNITIVE, V7
   EBERLE M, 1992, 199 FRDA FOR CAN
   FLYBJERG B, 1993, APPL ETHICS, P11
   GORDON TF, 1994, GMD STUDIEN      SEP, P25
   GREIDER T, 1994, RURAL SOCIOL, V59, P1, DOI 10.1111/j.1549-0831.1994.tb00519.x
   Jaggar A, 1993, APPL ETHICS READER, P69
   JAMIESON D, 1993, APPL ETHICS READER, P313
   Kettner M., 1993, APPL ETHICS READER, P28
   Leopold A, 1949, SAND COUNTY ALMANAC
   PRIETULA M, 1993, AAAI WORKSH JUL 11 1
   Proctor JD, 1996, J FOREST, V94, P39
   RALSTON H, 1993, APPL ETHICS READER, P271
   REEVES GH, 1992, PNWGTR288 USDA FOR S
   Robbins S. P., 1993, ORG BEHAV CONCEPTS C
   Shindler B, 1996, J FOREST, V94, P4
   SOUTH DB, 1994, J FOREST, V92, P7
   Thomson AJ, 1996, AI APPLICATIONS, V10, P1
   THOMSON AJ, 1993, AI APPLICATIONS, V7, P61
   Thomson SJ, 1996, AI APPLICATIONS, V10, P57
   WINKLER E. R, 1993, APPL ETHICS READER
NR 33
TC 7
Z9 7
U1 2
U2 8
PU AI APPLICATIONS
PI MOSCOW
PA PO BOX 3066, UNIV STATION, MOSCOW, ID 83843 USA
SN 1051-8266
J9 AI APPLICATIONS
JI AI Appl.
PY 1997
VL 11
IS 1
BP 69
EP 73
PG 5
WC Agronomy; Computer Science, Artificial Intelligence; Environmental
   Sciences; Forestry
SC Agriculture; Computer Science; Environmental Sciences & Ecology;
   Forestry
GA XV566
UT WOS:A1997XV56600007
DA 2019-03-21
ER

PT J
AU HASTEDT, H
AF HASTEDT, H
TI EFFECTIVENESS AND MORALS + ARTIFICIAL-INTELLIGENCE AND COMPUTERS
   CREATIVITY IN PHILOSOPHICAL PERSPECTIVE
SO DU-DIE ZEITSCHRIFT DER KULTUR
LA German
DT Article
RP HASTEDT, H (reprint author), UNIV ULM,HUMBOLDT STUDIENZENTRUM,W-7900 ULM,GERMANY.
CR Dreyfus Hubert, 1972, WHAT COMPUTERS CANT
   SEARLE JR, 1980, BEHAVIORAL BRAIN SCI
   WEIZENBAUM J, 1976, MACHT COMPUTER OHNMA
NR 3
TC 0
Z9 0
U1 0
U2 1
PU DU-VERLAG
PI ZURICH
PA MORGARTENSTRASSE 29, CH-8021 ZURICH, SWITZERLAND
SN 0012-6837
J9 DU-Z KULTUR
JI Du-Die Z. Kult.
PD MAR
PY 1992
IS 3
BP 23
EP 26
PG 4
WC Art
SC Art
GA HH452
UT WOS:A1992HH45200008
DA 2019-03-21
ER

PT J
AU CHILD, JW
AF CHILD, JW
TI RIGHTS IN MORAL LIVES - MELDEN,AI
SO PHILOSOPHICAL QUARTERLY
LA English
DT Book Review
RP CHILD, JW (reprint author), BOWLING GREEN STATE UNIV,BOWLING GREEN,OH 43403, USA.
CR MELDIN AI, 1988, RIGHTS MORAL LIVES
NR 1
TC 0
Z9 0
U1 0
U2 0
PU BLACKWELL PUBL LTD
PI OXFORD
PA 108 COWLEY RD, OXFORD, OXON, ENGLAND OX4 1JF
SN 0031-8094
J9 PHILOS QUART
JI Philos. Q.
PD JAN
PY 1990
VL 40
IS 158
BP 112
EP 116
DI 10.2307/2219974
PG 5
WC Philosophy
SC Philosophy
GA CJ373
UT WOS:A1990CJ37300012
DA 2019-03-21
ER

PT J
AU WELLMAN, C
AF WELLMAN, C
TI RIGHTS IN MORAL LIVES - A HISTORICAL-PHILOSOPHICAL ESSAY - MELDEN,AI
SO ETHICS
LA English
DT Book Review
RP WELLMAN, C (reprint author), WASHINGTON UNIV,ST LOUIS,MO 63130, USA.
CR Melden A.I., 1988, RIGHTS MORAL LIVES H
NR 1
TC 0
Z9 0
U1 0
U2 0
PU UNIV CHICAGO PRESS
PI CHICAGO
PA 5720 S WOODLAWN AVE, CHICAGO, IL 60637
SN 0014-1704
J9 ETHICS
JI Ethics
PD OCT
PY 1989
VL 100
IS 1
BP 182
EP 182
DI 10.1086/293158
PG 1
WC Ethics; Philosophy
SC Social Sciences - Other Topics; Philosophy
GA AT599
UT WOS:A1989AT59900018
DA 2019-03-21
ER

PT J
AU SCHUTTPELZ, P
AF SCHUTTPELZ, P
TI THE MAN-MACHINE DIALOG FROM THE VIEWPOINT OF ETHICS
SO DEUTSCHE ZEITSCHRIFT FUR PHILOSOPHIE
LA German
DT Article
RP SCHUTTPELZ, P (reprint author), TECH UNIV KARL MARX STADT,SEKT MARXISMUS LENINISMUS,PSF 964,DDR-9010 KARL MARX STADT,GER DEM REP.
CR CLAUSS G, 1976, WORTERBUCH PSYCHOL, P280
   EICHHORN I, 1988, DZFPH, P17
   FRENTZEL R, RECHNERGESTUTZTES AR, P35
   GROSS W, 1987, KOMMUNIKATION VERKEH, P30
   HACKER W, 1988, DZFPH, P299
   HONECKER E, 1986, BER ZENTR KOM SOZ, P30
   HONECKER E, 1988, VOLK VOLK REALISIERE, P99
   KLAUS G, 1968, WORTERBUCH KYBERNETI, P305
   LEONTJEW AA, 1980, SOWJETWISSENSCHAFT G, P526
   MARX K, MARX ENGELS WERKE, V23, P192
   ROSEMANN R, 1986, WISSENSCHAFTLICHE BE, P181
   STRIEBING L, 1987, DZFPH, P617
   STRIEBING L, 1987, KOPF COMPUTER, P58
   VAHRENKAMP R, 1985, GESAMTHOCHSCHULE KAS, P11
   ZSCHALER B, 1986, THESIS DRESDEN, P104
   1984, LEXIKON TECHNIK, P459
NR 16
TC 0
Z9 0
U1 1
U2 2
PU AKADEMIE VERLAG GMBH
PI BERLIN
PA MUHLENSTRASSE 33-34, D-13187 BERLIN, GERMANY
SN 0012-1045
J9 DEUT Z PHILOS
JI Dtsch. Z. Philos.
PY 1988
VL 36
IS 9
BP 797
EP 806
PG 10
WC Philosophy
SC Philosophy
GA Q8012
UT WOS:A1988Q801200004
DA 2019-03-21
ER

PT J
AU KOBLYAKOV, VP
   SHCHERBAK, FN
AF KOBLYAKOV, VP
   SHCHERBAK, FN
TI THE MORAL LIFE OF MAN, QUESTS, POSITION, ACTS - RUSSIAN -
   SAGATOVSKII,VN, RAZIN,AV, SOGOMONOV,YV, LANDESMAN,PA, TITARENKO,AI,
   GANZHIN,VT, ANISIMOV,SF, KISELEV,VP, BAKSHTANOVSKII,VI, LUTOSHKIN,GD
SO VOPROSY FILOSOFII
LA Russian
DT Book Review
CR SAGATOVSKII VN, 1982, NRAVSTVENNAYA ZHIZN
NR 1
TC 0
Z9 0
U1 0
U2 0
PU MEZHDUNARODNAYA KNIGA
PI MOSCOW
PA 39 DIMITROVA UL., 113095 MOSCOW, RUSSIA
SN 0042-8744
J9 VOP FILOS
JI Vopr. Filos.
PY 1984
IS 4
BP 167
EP 168
PG 2
WC Philosophy
SC Philosophy
GA SR960
UT WOS:A1984SR96000022
DA 2019-03-21
ER

PT J
AU CHRISTIANSEN, O
   WEIDLER, J
AF CHRISTIANSEN, O
   WEIDLER, J
TI SOCIAL BASIS OF MORALS - GERMAN - GUSEINOV,AA, TITARENKO,AI
SO DEUTSCHE ZEITSCHRIFT FUR PHILOSOPHIE
LA German
DT Book Review
RP CHRISTIANSEN, O (reprint author), HUMBOLDT UNIV,SEKT MARXIST LENINIST PHILOSOPHIE,DDR-1080 BERLIN,GER DEM REP.
CR GUSEINOV AA, 1979, SOZIALE GRUNDLAGEN M
   MARX K, 1969, WERKE, V3, P417
NR 2
TC 0
Z9 0
U1 0
U2 0
PU AKADEMIE VERLAG GMBH
PI BERLIN
PA MUHLENSTRASSE 33-34, D-13187 BERLIN, GERMANY
SN 0012-1045
J9 DEUT Z PHILOS
JI Dtsch. Z. Philos.
PY 1981
VL 29
IS 9
BP 1099
EP 1102
PG 4
WC Philosophy
SC Philosophy
GA MP181
UT WOS:A1981MP18100011
DA 2019-03-21
ER

PT J
AU DENT, NJH
AF DENT, NJH
TI VALUES AND MORALS - GOLDMAN,AI, KIM,J
SO MIND
LA English
DT Book Review
RP DENT, NJH (reprint author), UNIV BIRMINGHAM,BIRMINGHAM B15 2TH,W MIDLANDS,ENGLAND.
CR GOLDMAN AI, 1978, VALUES MORALS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD, ENGLAND OX2 6DP
SN 0026-4423
J9 MIND
JI Mind
PY 1981
VL 90
IS 357
BP 144
EP 147
PG 4
WC Philosophy
SC Philosophy
GA KZ154
UT WOS:A1981KZ15400017
DA 2019-03-21
ER

PT J
AU WALLACE, G
AF WALLACE, G
TI VALUES AND MORALS - GOLDMAN,AI, KIM,J
SO PHILOSOPHICAL QUARTERLY
LA English
DT Book Review
CR GOLDMAN AI, 1979, VALUES MORALS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU BLACKWELL PUBL LTD
PI OXFORD
PA 108 COWLEY RD, OXFORD, OXON, ENGLAND OX4 1JF
SN 0031-8094
J9 PHILOS QUART
JI Philos. Q.
PY 1981
VL 31
IS 122
BP 81
EP 82
DI 10.2307/2218686
PG 2
WC Philosophy
SC Philosophy
GA KZ161
UT WOS:A1981KZ16100013
DA 2019-03-21
ER

PT J
AU STEEL, C
AF STEEL, C
TI VALUES AND MORALS - ESSAYS IN HONOR OF FRANKENA,WILLIAM,
   STEVENSON,CHARLES AND BRANDT,RICHARD - GOLDMAN,AI, EDITOR, KIM,J, EDITOR
SO TIJDSCHRIFT VOOR FILOSOFIE
LA Dutch
DT Book Review
CR GOLDMAN AI, 1978, VALUES MORALS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU TIJDSCHRIFT VOOR FILOSOFIE
PI LOUVAIN
PA KARDINAAL MERCIERPLEIN 2, B-3000 LOUVAIN, BELGIUM
SN 0040-750X
J9 TIJDSCHR FILOS
JI Tijdschr. Filos.
PY 1981
VL 43
IS 4
BP 787
EP 787
PG 1
WC Philosophy
SC Philosophy
GA MX373
UT WOS:A1981MX37300059
DA 2019-03-21
ER

PT J
AU VACEK, E
AF VACEK, E
TI VALUES AND MORALS - ESSAYS IN HONOR OF FRANKENA,WILLIAM,
   STEVENSON,CHARLES, AND BRANDT,RICHARD - GOLDMAN,AI, KIM,J
SO MODERN SCHOOLMAN
LA English
DT Book Review
RP VACEK, E (reprint author), JESUIT SCH THEOL,CHICAGO,IL, USA.
CR Goldman Alvin I., 1978, VALUES MORALS ESSAYS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU ST LOUIS UNIV
PI ST LOUIS
PA 221 NORTH GRAND BLVD, ST LOUIS, MO 63103-2097
SN 0026-8402
J9 MOD SCHOOLMAN
JI Mod. Schoolman
PY 1980
VL 57
IS 3
BP 288
EP 288
DI 10.5840/schoolman198057358
PG 1
WC Philosophy
SC Philosophy
GA KP061
UT WOS:A1980KP06100027
DA 2019-03-21
ER

PT J
AU SMART, JJC
AF SMART, JJC
TI VALUES AND MORALS - ESSAYS IN HONOR OF FRANKENA,WILLIAM,
   STEVENSON,CHARLES, AND BRANDT,RICHARD - GOLDMAN,AI, KIM,J
SO PHILOSOPHY
LA English
DT Book Review
CR GOLDMAN AI, 1978, VALUES MORALS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 40 WEST 20TH STREET, NEW YORK, NY 10011-4211
SN 0031-8191
J9 PHILOSOPHY
JI Philosophy
PY 1980
VL 55
IS 214
BP 557
EP 559
DI 10.1017/S0031819100049615
PG 3
WC Philosophy
SC Philosophy
GA LA240
UT WOS:A1980LA24000017
DA 2019-03-21
ER

PT J
AU LANGE, W
AF LANGE, W
TI MARXS ETHICS - GERMAN - TITARENKO,AI
SO DEUTSCHE ZEITSCHRIFT FUR PHILOSOPHIE
LA German
DT Book Review
CR TITARENKO AI, 1976, MARXISTSKAJA ETIKA
NR 1
TC 0
Z9 0
U1 0
U2 0
PU AKADEMIE VERLAG GMBH
PI BERLIN
PA MUHLENSTRASSE 33-34, D-13187 BERLIN, GERMANY
SN 0012-1045
J9 DEUT Z PHILOS
JI Dtsch. Z. Philos.
PY 1977
VL 25
IS 8
BP 1016
EP 1019
PG 4
WC Philosophy
SC Philosophy
GA DV381
UT WOS:A1977DV38100017
DA 2019-03-21
ER

PT B
AU ZELIKOWA, OP
AF ZELIKOWA, OP
TI STRUCTURES OF MORAL CONSCIOUSNESS - ESSAY ON ETHICAL PHILOSPHICAL STUDY
   - GERMAN - TITARENKO,AI
SO SOWJETWISSENSCHAFT GESELLSCHAFTS WISSENSCHAFTLICHE BEITRAGE
LA German
DT Book Review
CR TITARENKO AI, 1974, STRUKTUREN MORALBEWU
NR 1
TC 0
Z9 0
U1 0
U2 0
PU VERLAG KULTUR AND FORTSCHRITT
PI BERLIN
PA GLINKASTRASSE 13-15, O-108 BERLIN, GERMANY
J9 SOWJETWISS GESELLSCH
PY 1977
VL 30
IS 1
BP 101
EP 104
PG 4
WC History & Philosophy Of Science; Political Science
SC History & Philosophy of Science; Government & Law
GA CV991
UT WOS:A1977CV99100012
DA 2019-03-21
ER

PT J
AU VERSENYI, L
AF VERSENYI, L
TI CAN ROBOTS BE MORAL
SO ETHICS
LA English
DT Editorial Material
C1 WILLIAMS COLL,WILLIAMSTOWN,MA 01267.
CR ARBIB M, 1970, COGNITION MULTIPLE V
   Ashby W. R., 1952, DESIGN BRAIN
   ASHBY WR, 1963, GENERAL SYSTEMS YB S, V8
   GUNDERSON K, 1968, BRIT J PHILOSOPHY SC, V19, P190
   Kant, 1964, GROUNDWORK METAPHYSI
   LACEY AR, 1960, PHILOS QUART, V10, P61
   Mackay D. M., 1951, BRIT J PHILOS SCI, VII, P105
   PASK G, 1972, METAPHORICAL BRAIN
   PUCETTI R, 1967, BRIT J PHILOSOPHY SC, V18, P39
   PUTNAM H, 1964, J PHILOS        1112, P668
   Putnam H, 1960, DIMENSIONS OF MIND
   Rosenblueth A., 1943, PHILOS SCI, V10, P18, DOI DOI 10.1086/286788
   Turing A.M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433
   UTTLEY AM, 1956, AUTOMATA STUDIES
   Wiener Norbert, 1964, GOD AND GOLEM
NR 15
TC 4
Z9 4
U1 0
U2 1
PU UNIV CHICAGO PRESS
PI CHICAGO
PA 5720 S WOODLAWN AVE, CHICAGO, IL 60637
SN 0014-1704
J9 ETHICS
JI Ethics
PY 1974
VL 84
IS 3
BP 248
EP 259
DI 10.1086/291922
PG 12
WC Ethics; Philosophy
SC Social Sciences - Other Topics; Philosophy
GA T0766
UT WOS:A1974T076600006
DA 2019-03-21
ER

PT J
AU GRIFFITHS, AP
AF GRIFFITHS, AP
TI ESSAYS IN MORAL-PHILOSOPHY - MELDEN,AI
SO PHILOSOPHY
LA English
DT Book Review
CR Melden A. I., 1958, ESSAYS MORAL PHILOS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 40 WEST 20TH STREET, NEW YORK, NY 10011-4211
SN 0031-8191
J9 PHILOSOPHY
JI Philosophy
PY 1961
VL 36
IS 137
BP 237
EP 238
DI 10.1017/S0031819100058150
PG 2
WC Philosophy
SC Philosophy
GA CDK33
UT WOS:A1961CDK3300019
DA 2019-03-21
ER

PT J
AU HANDY, R
AF HANDY, R
TI ESSAYS IN MORAL-PHILOSOPHY - MELDEN,AI
SO PHILOSOPHY AND PHENOMENOLOGICAL RESEARCH
LA English
DT Book Review
CR Melden A. I., 1958, ESSAYS MORAL PHILOS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU PHILOSOPHY PHENOMENOLOGICAL RES
PI PROVIDENCE
PA BROWN UNIV BOX 1947, PROVIDENCE, RI 02912
SN 0031-8205
J9 PHILOS PHENOMEN RES
JI Philos. Phenomenol. Res.
PY 1960
VL 20
IS 4
BP 567
EP 568
DI 10.2307/2104200
PG 2
WC Philosophy
SC Philosophy
GA CEY05
UT WOS:A1960CEY0500031
DA 2019-03-21
ER

PT J
AU SCHNEIDER, HW
AF SCHNEIDER, HW
TI ESSAYS IN MORAL-PHILOSOPHY - MELDEN,AI
SO JOURNAL OF PHILOSOPHY
LA English
DT Book Review
CR Melden A. I., 1958, ESSAYS MORAL PHILOS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU J PHILOSOPHY INC
PI NEW YORK
PA COLUMBIA UNIV 709 PHILOSOPHY HALL, NEW YORK, NY 10027
SN 0022-362X
J9 J PHILOS
JI J. Philos.
PY 1959
VL 56
IS 17
BP 704
EP 708
DI 10.2307/2022050
PG 5
WC Philosophy
SC Philosophy
GA CET28
UT WOS:A1959CET2800002
DA 2019-03-21
ER

PT J
AU NOWELLSMITH, PH
AF NOWELLSMITH, PH
TI ESSAYS IN MORAL-PHILOSOPHY - MELDEN,AI
SO MIND
LA English
DT Book Review
CR Melden A. I., 1958, ESSAYS MORAL PHILOS
NR 1
TC 0
Z9 0
U1 0
U2 0
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0026-4423
J9 MIND
JI Mind
PY 1959
VL 68
IS 272
BP 567
EP 570
PG 4
WC Philosophy
SC Philosophy
GA CGZ99
UT WOS:A1959CGZ9900023
DA 2019-03-21
ER

EF